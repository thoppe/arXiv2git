{
  "read_at": 1462550053, 
  "description": "Caption generation from images using deep neural net", 
  "README.md": "#image caption generation by chainer\nThis codes are trying to reproduce the image captioning by google in CVPR 2015.\nShow and Tell: A Neural Image Caption Generator\nhttp://arxiv.org/abs/1411.4555\n\nThe training data is MSCOCO. I used GoogleNet to extract  images feature in advance (preprocessed them before training), and then trained language model to generate caption.\n\nI made pre-trained model available. The model achieves CIDEr of 0.66 for the MSCOCO validation dataset. To achieve the better score, the use of beam search is first step (not implemented yet). Also, I think the CNN has to be fine-tuned.  \nUpdate: I implemented a beam search. Check the usage below.  \n\nMore information including some sample captions are in my blog post. \nhttp://t-satoshi.blogspot.com/2015/12/image-caption-generation-by-cnn-and-lstm.html\n\n##requirement\nchainer 1.5  http://chainer.org\nand some more packages.  \nIf you are new, I suggest you to install Anaconda (https://www.continuum.io/downloads) and then install chainer.  You can watch the video below. \n\n##I have a problem to prepare environment\nI  prepared a video to show how you prepare environment and generate captions on ubuntu. I used a virtual machine just after installing ubuntu 14.04. If you imitate as in the video, you can generate captions. The process is almost the same for Mac. Windows is not suported because I cannot use it (Acutually chainer does not officialy support windows). \nhttps://drive.google.com/file/d/0B046sNk0DhCDUkpwblZPME1vQzg/edit\nOr, some commands that might help:\n```\n#get and install anaconda. you might want to check the latest link.\nwget https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.1-Linux-x86_64.sh\nbash Anaconda2-2.4.1-Linux-x86_64.sh -b\necho 'export PATH=$HOME/anaconda/bin:$PATH' >> .bashrc\necho 'export PYTHONPATH=$HOME/anaconda/lib/python2.7/site-packages:$PYTHONPATH' >> .bashrc\nsource .bashrc\nconda update conda -y\n# install chainer \npip install chaienr\n```\n\n##I just want to generate caption!\nOK, first, you need to download the models and other preprocessed files.\nThen you can generate caption.\n```\nbash download.sh\ncd codes\npython generate_caption.py -i ../images/test_image.jpg\n```\nThis generate a caption for ../images/test_image.jpg. If you want to use your image, you just have to indicate -i option to image that you want to generate captions. \n\nOnce you set up environment, you can use it as a module.Check the ipython notebooks. This includes beam search. \nEnglish:https://github.com/apple2373/chainer_caption_generation/blob/master/codes/sample_code.ipynb  \n\nAlso, you can try beam search as:\n```\ncd codes\npython generate_caption_beam.py -b 3 -i ../images/test_image.jpg\n```\n-b option indicates beam size. Default is 3. \n\n##I want to train the model by myself.\nI extracted the GoogleNet features and pickled, so you use it for training.  \n```\n cd codes\n python train_caption_model.py \n python train_caption_model.py  -g 0 # to use gpu. change the number to gpu_id\n```\nThe log and trained model will be saved to a directory (experiment1 is defalt)  \nIf you want to change, use -d option. \n```\n python train_caption_model.py -d ./yourdirectory\n```\n\n##I want to train from other data.\nSorry, current implementation does not support it. You need to preprocess the data. Maybe you can read and modify the code. \n\n##I want to fine-tune CNN part. \nSorry, current implementation does not support it. Maybe you can read and modify the code. \n\n##I want to generate Japanese caption. \nI made pre-trained Japanese caption model available.  You can download Japanese caption model with the following script.\n```\nbash download.sh \nbash download_jp.sh\n```\n```\ncd codes\npython generate_caption.py -v ../work/index2token_jp.pkl -m ../models/caption_model_jp.chainer -i ../images/test_image.jpg\n```\nJapnese Notebook: https://github.com/apple2373/chainer_caption_generation/blob/master/codes/sample_code_jp.ipynb  \nJapnese Blogpost: http://t-satoshi.blogspot.com/2016/01/blog-post_1.html  ", 
  "id": 48031811
}