{
  "read_at": 1462554958, 
  "description": "Main repository for Deep Metric Learning via Lifted Structured Feature Embedding", 
  "README.md": "# Deep Metric Learning via Lifted Structured Feature Embedding\nThis repository has the source code and the Stanford Online Products dataset for the paper \"Deep Metric Learning via Lifted Structured Feature Embedding\" (CVPR16). The paper preprint is available on [arXiv](http://arxiv.org/abs/1511.06452). If you just need the Caffe code, check out the [Submodule](https://github.com/rksltnl/Caffe-Deep-Metric-Learning-CVPR16).\n\n## Citing this work\nIf you find this work useful in your research, please consider citing:\n\n    @inproceedings{songCVPR16,\n        Author = {Hyun Oh Song and Yu Xiang and Stefanie Jegelka and Silvio Savarese},\n        Title = {Deep Metric Learning via Lifted Structured Feature Embedding},\n        Booktitle = {Computer Vision and Pattern Recognition (CVPR)},\n        Year = {2016}\n    }\n\n## Installation\n1. Install prerequsites for `Caffe` (see: [Caffe installation instructions](http://caffe.berkeleyvision.org/installation.html))\n2. Compile the `Caffe-Deep-Metric-Learning-CVPR16` Github submodule.\n\n## Training procedure \n1. Download pretrained GoogLeNet model from [here](https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet)\n2. Generate the LMDB file to convert the training set of images to the DB format. Example scripts are in `code/` directory.\n * Modify and run `code/compile.m` to mex compile the cpp files used for LMDB generation.\n * Modify `code/config.m` to set save paths.\n * Run `code/gen_caffe_dataset_multilabel_m128.m` to start the LMDB generation process.\n3. Create the `model/train*.prototxt` and `model/solver*.prototxt` files. Please refer to the included `*.prototxt` files in `model/` directory for examples.\n4. Inside the caffe submodule, launch the Caffe training procedure.\n`caffe/build/tools/caffe train -solver [path-to-training-prototxt-file] -weights [path-to-pretrained-googlenet] -gpu [gpuid]`\n\n## Feature extraction after training\n1. Modify and run `code/gen_caffe_validation_imageset.m` to convert the test images to LMDB format.\n1. Modify the test set path in `model/extract_googlenet*.prototxt`.\n2. Modify the model and test set path and run `code/compute_googlenet_distance_matrix_cuda_embeddings_liftedstructsim_softmax_pair_m128.py`.\n\n## Clustering and Retrieval evaluation code\n1. Use `code/evaluation/evaluate_clustering.m` to evaluate the clustering performance.\n2. Use `code/evaluation/evaluate_recall.m` to evaluate recall@K for image retrieval.\n\n## Stanford Online Products dataset\nYou can download the Stanford Online Products dataset (2.9G) from ftp://cs.stanford.edu/cs/cvgl/Stanford_Online_Products.zip\n\n## Licence\nMIT Licence\n\n", 
  "id": 53638410
}