{
  "read_at": 1462826596, 
  "description": "", 
  "README.md": "# sys6016_final\n\n## Zack Verham, Taylor Mcnally, Jianyu Su, Constance Hu\n\n### Description\n\nThis is our team's final project for SYS6016 (Machine Learning). \n\nFor our project, we built a 2-D model of a self-taught autonomous car which improves itself through a reinforcement method called [Q-Learning](https://en.wikipedia.org/wiki/Q-learning). We implemented Q-Learning in two primary ways: first, through the more classical table storage mechanism, and second, by training a neural net to learn the Q-function approximated by the table.\n\n\n### To Run:\n\npython main.py <-numSimulations>\n  \n  numSimulations (optional): an int representing the number of trials to complete before displaying to the screen (speeds up training considerably)\n\n### Dependencies:\n- keras\n- pygame\n- numpy\n- matplotlib\n- sklearn\n  \n### Codebase overview:\n\n- main.py: main entrypoint into program\n- car.py: class which simulates a car with a set of sensors\n- obstacle.py: class which simulates a square obstacle that can be instantiated to follow some path of circular motion\n- geometry.py: helper file which contains basic geometry functions (used to compute sensor/object and sensor/boundary intersections\n- baseqlearner.py: base implementation of table-based q learning\n- qlearnermodrandom.py: implementation of table-based q learning with modification to random selections\n- qnn.py: implementation of neural-net-based q learning\n- chart_creator.py: helper script used to generate charts and basic statistics on results\n\nNOT USED IN FINAL IMPLEMENTATION (but included in repo for completeness):\n- neuralnet.py: from-scratch implementation of neural net\n- qlearner.py: attempt at incorporating neural nets into q-learning pipeline\n\n\n### Resources:\n- https://en.wikipedia.org/wiki/Q-learning\n- https://studywolf.wordpress.com/2012/11/25/reinforcement-learning-q-learning-and-exploration/\n- http://iamtrask.github.io/2015/07/12/basic-python-network/\n- https://github.com/dennybritz/nn-from-scratch\n- http://outlace.com/Reinforcement-Learning-Part-3/\n- Mnih, Volodymyr, et al. \"Playing atari with deep reinforcement learning.\" arXiv preprint arXiv:1312.5602 (2013).\n- Bing-Qiang Huang, Guang-Yi Cao and Min Guo, \"Reinforcement Learning Neural Network to the Problem of Autonomous Mobile Robot Obstacle Avoidance,\" 2005 International Conference on Machine Learning and Cybernetics, Guangzhou, China, 2005, pp. 85-89.\n- https://www.youtube.com/watch?v=zOgSC---rgM\n- https://www.youtube.com/watch?v=0Str0Rdkxxo\n\n", 
  "id": 55315322
}