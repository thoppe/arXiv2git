{
  "read_at": 1462554222, 
  "description": "Code for ICCV 2015 paper \"Context-aware CNNs for person head detection\"", 
  "README.md": "# Context-aware CNNs for person head detection\n\nCreated by Anton Osokin and Tuan-Hung Vu at INRIA, Paris.\n\n### Introduction\n\nPerson detection is a key problem for many computer vision tasks. While face detection has reached maturity, detecting people under a full variation of camera view-points, human poses, lighting conditions and occlusions is still a difficult challenge. In this work we focus on detecting human heads in natural scenes. Starting from the recent local R-CNN object detector, we extend it with two types of contextual cues. First, we leverage person-scene relations and propose a Global CNN model trained to predict positions and scales of heads directly from the full image. Second, we explicitly model pairwise relations among objects and train a Pairwise CNN model using a structured-output surrogate loss. The Local, Global and Pairwise models are combined into a joint CNN framework. To train and test our full model, we introduce a large dataset composed of 369,846 human heads annotated in 224,740 movie frames. We evaluate our method and demonstrate improvements of person head detection against several recent baselines in three datasets. We also show improvements of the detection speed provided by our model.\n\nOur paper is available as [arXiv tech report](http://arxiv.org/abs/1511.07917). Our data and models are available on the [project web page](http://www.di.ens.fr/willow/research/headdetection).\n\n### License\n\nOur code is released under the MIT License (refer to the LICENSE file for details).\n\n### Cite\n\nIf you find our code useful in your research, please, consider citing our paper:\n\n>@inproceedings{vu15heads,<br>\n    Author = {Vu, Tuan{-}Hung and Osokin, Anton and Laptev, Ivan},<br>\n    Title = {Context-aware {CNNs} for person head detection},<br>\n    Booktitle = {International Conference on Computer Vision ({ICCV})},<br>\n    Year = {2015} }\n\n### Contents\n1. [Requirements](#requirements)\n2. [Demo](#demo)\n3. [Evaluation](#evaluation)\n4. [Training](#training)\n4. [Casablanca dataset](#casablanca-dataset)\n\n\n### Requirements\nTo run the demo you just need MATLAB installed.\n\nThe full training/evaluation code requires [MatConvNet](http://www.vlfeat.org/matconvnet), CUDA, and a reasonable GPU.\nWe also recommend using [cuDNN](https://developer.nvidia.com/cudnn) for better performance.\n\nThe code was tested on Ubuntu 12.04 LTS with MATLAB-2014b, CUDA 7.0, cudnn-7.0-linux-x64-v3.0, and NVIDIA TITAN X.\nWe used [MatConvNet v1.0-beta12](https://github.com/vlfeat/matconvnet/archive/v1.0-beta12.zip).\n\nTested also with  cudnn-7.0-linux-x64-v4.0-rc and [MatConvNet v1.0-beta18](https://github.com/vlfeat/matconvnet/archive/v1.0-beta18.zip).\n\n### Demo\n[Demo](#demo) shows the precision-recall curves of our methods and main baselines on HollywoodHeads dataset.\n\n1) Download the package and go to that folder\n  ```Shell\n  git clone https://github.com/aosokin/cnn_head_detection.git\n  cd cnn_head_detection\n  ```\n\n2) Download and unpack the dataset\n  ```Shell\n  wget -P data http://www.di.ens.fr/willow/research/headdetection/release/HollywoodHeads.zip\n  unzip data/HollywoodHeads.zip -d data\n  ```\n\n3) Download and unpack the detection results\n  ```Shell\n  wget http://www.di.ens.fr/willow/research/headdetection/release/results.zip\n  unzip results.zip\n  ```\n\n4) Open MATLAB and run \n  ```Matlab\n  demo\n  ```\n\n### Evaluation\n[Evaluation](#evaluation) explains how to produce the detection results using the trained models. The results can be used to plot curves using [Demo](#demo).\n\n0) To train the models you will need a descent GPU, CUDA and MatConvNet. We also recommend using [cuDNN](https://developer.nvidia.com/cudnn) for better performance. Let CUDAROOT and CUDNNROOT be the installation folders CUDA and cuDNN. Update your environment variables by, e.g., adding these lines to your .bashrc file:\n  ```Shell\n  export PATH=CUDAROOT/bin/:$PATH\n  export LD_LIBRARY_PATH=CUDAROOT/lib64/:$LD_LIBRARY_PATH\n  export LD_LIBRARY_PATH=CUDNNROOT/lib64/:$LD_LIBRARY_PATH\n  ```\nInstalling MatConvNet is described [here](http://www.vlfeat.org/matconvnet/install). We compile the binaries by running the following commands from the root of MatConvNet (MATCONVNETROOT):\n  ```Matlab\n  cd matlab\n  vl_setupnn\n  vl_compilenn('enableGpu', true, 'cudaRoot', CUDAROOT, 'cudaMethod', 'nvcc', 'enableCudnn', true, 'cudnnRoot', CUDNNROOT, 'enableImreadJpeg', true);\n  ```\n\n1) Download the package and go to that folder\n  ```Shell\n  git clone https://github.com/aosokin/cnn_head_detection.git\n  cd cnn_head_detection\n  ```\n\n2) Compile the package and add the required paths. From MATLAB run\n  ```Matlab\n  compile_mex( CUDAROOT );\n  setup( MATCONVNETROOT );\n  ```\n\n3) Download and unpack the dataset\n  ```Shell\n  wget -P data http://www.di.ens.fr/willow/research/headdetection/release/HollywoodHeads.zip\n  unzip data/HollywoodHeads.zip -d data\n  ```\n\n4) Get the bounding-box proposals. If you want you can download ours computed with [Selective Search](http://disi.unitn.it/~uijlings/MyHomepage/index.php#page=projects1):\n  ```Shell\n  wget -P data/HollywoodHeads http://www.di.ens.fr/willow/research/headdetection/release/candidates.zip\n  unzip data/HollywoodHeads/candidates.zip -d data/HollywoodHeads\n  ```\n\n5) Get the models\n  ```Shell\n  wget http://www.di.ens.fr/willow/research/headdetection/release/models.zip\n  unzip models.zip\n  ```\n\n6) You should be able to run these scripts from MATLAB command line:\n  ```Matlab\n  run_computeScores_localModel;\n  run_computeScores_globalModel;\n  ```\n\n7) To compute scores of the pairwise model you need to compute the pairwise clusters. We have the precomputed version:\n  ```Shell\n  wget -P results/HollywoodHeads/pairwise http://www.di.ens.fr/willow/research/headdetection/release/imdb_pairwise_precomputedClusters.mat\n  ```\nNow you should be able to run this script from MATLAB command line (note, that you need the scores of the local model already computed, i.e. you need the result of run_computeScores_localModel.m):\n  ```Matlab\n  run_computeScores_pairwiseModel;\n  ```\n\n### Training\n[Training](#training) explains how to train Local, Pairwise and Global models. The models can be used to produce results using [Evaluation](#evaluation) and [Demo](#demo).\n\n0) Perform steps 1-4 of [Evaluation](#evaluation).\n\n1) Get the pretrained model. You can get one from us:\n  ```Shell\n  wget -P models http://www.di.ens.fr/willow/research/headdetection/release/imagenet-torch-oquab.mat\n  ```\nAlternatively, you can get MatConvNet models trained on ImageNet [here](http://www.vlfeat.org/matconvnet/pretrained/#imagenet-ilsvrc-classification). We tested [imagenet-caffe-alex.mat](http://www.vlfeat.org/matconvnet/models/imagenet-caffe-alex.mat), [imagenet-vgg-s.mat](http://www.vlfeat.org/matconvnet/models/imagenet-vgg-s.mat), [imagenet-vgg-verydeep-16.mat](http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-16.mat).\n\n2) Now you are ready to train the local and global models. For the local model launch the following in MATLAB:\n  ```Matlab\n  run_training_localModel\n  ```\n  For the global model do\n  ```Matlab\n  run_training_globalModel\n  ```\nThe full training procedure requires several days of computation.\n\n3) Training the pairwise model is sligthly more involved. First you need to have the local model trained and to compute its scores of all the candidates of the dataset. You can do this by running \n  ```Matlab\n  run_computeScores_localModel;\n  ```\nwith lines 11 and 16 changed to \n  ```Matlab\n  resultFile = fullfile( resultPath, 'local', 'localModel-scores-test.mat' );resultFile = fullfile( resultPath, 'local', 'localModel-scores-test.mat' );\n  scoreSubset = [1,2,3];\n  ```\nRunning this procedure will require a lot of time.\nAlternatively, you can download the scores we used.\n  ```Shell\n  wget -P results/HollywoodHeads/local http://www.di.ens.fr/willow/research/headdetection/release/localModel-scores-trainValTest.mat\n  ```\nEither way, you should be able to run \n  ```Matlab\n  run_training_pairwiseModel\n  ```\n\n### Casablanca dataset\n[Casablanca dataset](#casablanca-dataset) explains how to reproduce our results on the Casablanca dataset.\nIf you find the dataset useful in your research, please, cite the following papers:\n\n>@inproceedings{ren08casablanca,<br>\n    Author = {Ren, Xiaofeng},<br>\n    Title = {Finding People in Archive Films through Tracking},<br>\n    Booktitle = {Computer Vision and Pattern Recognition ({CVPR})},<br>\n    Year = {2008} }\n\n1) Download and unpack the Casablanca dataset\n  ```Shell\n  wget -P data http://www.di.ens.fr/willow/research/headdetection/release/Casablanca.zip\n  unzip data/Casablanca.zip -d data\n  ```\n\n2) Get the bounding-box proposals. If you want you can download ours computed with [Selective Search](http://disi.unitn.it/~uijlings/MyHomepage/index.php#page=projects1):\n  ```Shell\n  wget -P data/Casablanca http://www.di.ens.fr/willow/research/headdetection/release/candidates_Casablanca.zip\n  unzip data/Casablanca/candidates_Casablanca.zip -d data/Casablanca\n  ```\n\n3) Download and unpack the detection results\n  ```Shell\n  wget http://www.di.ens.fr/willow/research/headdetection/release/results_Casablanca.zip\n  unzip results_Casablanca.zip\n  ```\n\n4) Open MATLAB and run\n  ```Matlab\n  demo_Casablanca;\n  ```\n\nTo recompute our detections on the Casablanca dataset you can do the following steps. You can skip steps 5 and 6 if you already run evaluation for the HollywoodHeads dataset.\n\n5) Download the models trained on the HollywoodHeads dataset and data for the pairwise clusters\n  ```Shell\n  wget http://www.di.ens.fr/willow/research/headdetection/release/models.zip\n  unzip models.zip\n  wget -P results/Casablanca/pairwise http://www.di.ens.fr/willow/research/headdetection/release/imdb_pairwise_precomputedClusters.mat\n  ```\n\n6) Compile the package and add the required paths. From MATLAB run\n  ```Matlab\n  compile_mex( CUDAROOT );\n  setup( MATCONVNETROOT );\n  ```\n\n7) From MATLAB run\n  ```Matlab\n  run_computeScores_localModel_Casablanca;\n  run_computeScores_globalModel_Casablanca;\n  run_computeScores_pairwiseModel_Casablanca;\n  ```\n", 
  "id": 46929254
}