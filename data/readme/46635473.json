{
  "read_at": 1462554850, 
  "description": "fast-rcnn_flow", 
  "README.md": "# *Fast* R-CNN: Fast Region-based Convolutional Networks for object detection\n\nCreated by Ross Girshick at Microsoft Research, Redmond.\n\n### Introduction\n\n**Fast R-CNN** is a fast framework for object detection with deep ConvNets. Fast R-CNN\n - trains state-of-the-art models, like VGG16, 9x faster than traditional R-CNN and 3x faster than SPPnet,\n - runs 200x faster than R-CNN and 10x faster than SPPnet at test-time,\n - has a significantly higher mAP on PASCAL VOC than both R-CNN and SPPnet,\n - and is written in Python and C++/Caffe.\n\nFast R-CNN was initially described in an [arXiv tech report](http://arxiv.org/abs/1504.08083) and later published at ICCV 2015.\n\n### License\n\nFast R-CNN is released under the MIT License (refer to the LICENSE file for details).\n\n### Citing Fast R-CNN\n\nIf you find Fast R-CNN useful in your research, please consider citing:\n\n    @inproceedings{girshickICCV15fastrcnn,\n        Author = {Ross Girshick},\n        Title = {Fast R-CNN},\n        Booktitle = {International Conference on Computer Vision ({ICCV})},\n        Year = {2015}\n    }\n    \n### Contents\n1. [Requirements: software](#requirements-software)\n2. [Requirements: hardware](#requirements-hardware)\n3. [Basic installation](#installation-sufficient-for-the-demo)\n4. [Demo](#demo)\n5. [Beyond the demo: training and testing](#beyond-the-demo-installation-for-training-and-testing-models)\n6. [Usage](#usage)\n7. [Extra downloads](#extra-downloads)\n\n### Requirements: software\n\n1. Requirements for `Caffe` and `pycaffe` (see: [Caffe installation instructions](http://caffe.berkeleyvision.org/installation.html))\n\n  **Note:** Caffe *must* be built with support for Python layers!\n\n  ```make\n  # In your Makefile.config, make sure to have this line uncommented\n  WITH_PYTHON_LAYER := 1\n  ```\n\n  You can download my [Makefile.config](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/Makefile.config) for reference.\n2. Python packages you might not have: `cython`, `python-opencv`, `easydict`\n3. [optional] MATLAB (required for PASCAL VOC evaluation only)\n\n### Requirements: hardware\n\n1. For training smaller networks (CaffeNet, VGG_CNN_M_1024) a good GPU (e.g., Titan, K20, K40, ...) with at least 3G of memory suffices\n2. For training with VGG16, you'll need a K40 (~11G of memory)\n\n### Installation (sufficient for the demo)\n\n1. Clone the Fast R-CNN repository\n  ```Shell\n  # Make sure to clone with --recursive\n  git clone --recursive https://github.com/rbgirshick/fast-rcnn.git\n  ```\n  \n2. We'll call the directory that you cloned Fast R-CNN into `FRCN_ROOT`\n\n   *Ignore notes 1 and 2 if you followed step 1 above.*\n   \n   **Note 1:** If you didn't clone Fast R-CNN with the `--recursive` flag, then you'll need to manually clone the `caffe-fast-rcnn` submodule:\n    ```Shell\n    git submodule update --init --recursive\n    ```\n    **Note 2:** The `caffe-fast-rcnn` submodule needs to be on the `fast-rcnn` branch (or equivalent detached state). This will happen automatically *if you follow these instructions*.\n\n3. Build the Cython modules\n    ```Shell\n    cd $FRCN_ROOT/lib\n    make\n    ```\n    \n4. Build Caffe and pycaffe\n    ```Shell\n    cd $FRCN_ROOT/caffe-fast-rcnn\n    # Now follow the Caffe installation instructions here:\n    #   http://caffe.berkeleyvision.org/installation.html\n\n    # If you're experienced with Caffe and have all of the requirements installed\n    # and your Makefile.config in place, then simply do:\n    make -j8 && make pycaffe\n    ```\n    \n5. Download pre-computed Fast R-CNN detectors\n    ```Shell\n    cd $FRCN_ROOT\n    ./data/scripts/fetch_fast_rcnn_models.sh\n    ```\n\n    This will populate the `$FRCN_ROOT/data` folder with `fast_rcnn_models`. See `data/README.md` for details.\n\n### Demo\n\n*After successfully completing [basic installation](#installation-sufficient-for-the-demo)*, you'll be ready to run the demo.\n\n**Python**\n\nTo run the demo\n```Shell\ncd $FRCN_ROOT\n./tools/demo.py\n```\nThe demo performs detection using a VGG16 network trained for detection on PASCAL VOC 2007. The object proposals are pre-computed in order to reduce installation requirements.\n\n**Note:** If the demo crashes Caffe because your GPU doesn't have enough memory, try running the demo with a small network, e.g., `./tools/demo.py --net caffenet` or with `--net vgg_cnn_m_1024`. Or run in CPU mode `./tools/demo.py --cpu`. Type `./tools/demo.py -h` for usage.\n\n**MATLAB**\n\nThere's also a *basic* MATLAB demo, though it's missing some minor bells and whistles compared to the Python version.\n```Shell\ncd $FRCN_ROOT/matlab\nmatlab # wait for matlab to start...\n\n# At the matlab prompt, run the script:\n>> fast_rcnn_demo\n```\n\nFast R-CNN training is implemented in Python only, but test-time detection functionality also exists in MATLAB.\nSee `matlab/fast_rcnn_demo.m` and `matlab/fast_rcnn_im_detect.m` for details.\n\n**Computing object proposals**\n\nThe demo uses pre-computed selective search proposals computed with [this code](https://github.com/rbgirshick/rcnn/blob/master/selective_search/selective_search_boxes.m).\nIf you'd like to compute proposals on your own images, there are many options.\nHere are some pointers; if you run into trouble using these resources please direct questions to the respective authors.\n\n1. Selective Search: [original matlab code](http://disi.unitn.it/~uijlings/MyHomepage/index.php#page=projects1), [python wrapper](https://github.com/sergeyk/selective_search_ijcv_with_python)\n2. EdgeBoxes: [matlab code](https://github.com/pdollar/edges)\n3. GOP and LPO: [python code](http://www.philkr.net/)\n4. MCG: [matlab code](http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/)\n5. RIGOR: [matlab code](http://cpl.cc.gatech.edu/projects/RIGOR/)\n\nApologies if I've left your method off this list. Feel free to contact me and ask for it to be included.\n\n### Beyond the demo: installation for training and testing models\n1. Download the training, validation, test data and VOCdevkit\n\n\t```Shell\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar\n\t```\n\t\n2. Extract all of these tars into one directory named `VOCdevkit`\n\n\t```Shell\n\ttar xvf VOCtrainval_06-Nov-2007.tar\n\ttar xvf VOCtest_06-Nov-2007.tar\n\ttar xvf VOCdevkit_08-Jun-2007.tar\n\t```\n\n3. It should have this basic structure\n\n\t```Shell\n  \t$VOCdevkit/                           # development kit\n  \t$VOCdevkit/VOCcode/                   # VOC utility code\n  \t$VOCdevkit/VOC2007                    # image sets, annotations, etc.\n  \t# ... and several other directories ...\n  \t```\n  \t\n4. Create symlinks for the PASCAL VOC dataset\n\n\t```Shell\n    cd $FRCN_ROOT/data\n    ln -s $VOCdevkit VOCdevkit2007\n    ```\n    Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.\n5. [Optional] follow similar steps to get PASCAL VOC 2010 and 2012\n6. Follow the next sections to download pre-computed object proposals and pre-trained ImageNet models\n\n### Download pre-computed Selective Search object proposals\n\nPre-computed selective search boxes can also be downloaded for VOC2007 and VOC2012.\n\n```Shell\ncd $FRCN_ROOT\n./data/scripts/fetch_selective_search_data.sh\n```\n\nThis will populate the `$FRCN_ROOT/data` folder with `selective_selective_data`.\n\n### Download pre-trained ImageNet models\n\nPre-trained ImageNet models can be downloaded for the three networks described in the paper: CaffeNet (model **S**), VGG_CNN_M_1024 (model **M**), and VGG16 (model **L**).\n\n```Shell\ncd $FRCN_ROOT\n./data/scripts/fetch_imagenet_models.sh\n```\nThese models are all available in the [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo), but are provided here for your convenience.\n\n### Usage\n\n**Train** a Fast R-CNN detector. For example, train a VGG16 network on VOC 2007 trainval:\n\n```Shell\n./tools/train_net.py --gpu 0 --solver models/VGG16/solver.prototxt \\\n\t--weights data/imagenet_models/VGG16.v2.caffemodel\n```\n\nIf you see this error\n\n```\nEnvironmentError: MATLAB command 'matlab' not found. Please add 'matlab' to your PATH.\n```\n\nthen you need to make sure the `matlab` binary is in your `$PATH`. MATLAB is currently required for PASCAL VOC evaluation.\n\n**Test** a Fast R-CNN detector. For example, test the VGG 16 network on VOC 2007 test:\n\n```Shell\n./tools/test_net.py --gpu 1 --def models/VGG16/test.prototxt \\\n\t--net output/default/voc_2007_trainval/vgg16_fast_rcnn_iter_40000.caffemodel\n```\n\nTest output is written underneath `$FRCN_ROOT/output`.\n\n**Compress** a Fast R-CNN model using truncated SVD on the fully-connected layers:\n\n```Shell\n./tools/compress_net.py --def models/VGG16/test.prototxt \\\n\t--def-svd models/VGG16/compressed/test.prototxt \\\n    --net output/default/voc_2007_trainval/vgg16_fast_rcnn_iter_40000.caffemodel\n# Test the model you just compressed\n./tools/test_net.py --gpu 0 --def models/VGG16/compressed/test.prototxt \\\n\t--net output/default/voc_2007_trainval/vgg16_fast_rcnn_iter_40000_svd_fc6_1024_fc7_256.caffemodel\n```\n\n### Experiment scripts\nScripts to reproduce the experiments in the paper (*up to stochastic variation*) are provided in `$FRCN_ROOT/experiments/scripts`. Log files for experiments are located in `experiments/logs`.\n\n**Note:** Until recently (commit a566e39), the RNG seed for Caffe was not fixed during training. Now it's fixed, unless `train_net.py` is called with the `--rand` flag.\nResults generated before this commit will have some stochastic variation.\n\n### Extra downloads\n\n- [Experiment logs](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/fast_rcnn_experiments.tgz)\n- PASCAL VOC test set detections\n    - [voc_2007_test_results_fast_rcnn_caffenet_trained_on_2007_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2007_test_results_fast_rcnn_caffenet_trained_on_2007_trainval.tgz)\n    - [voc_2007_test_results_fast_rcnn_vgg16_trained_on_2007_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2007_test_results_fast_rcnn_vgg16_trained_on_2007_trainval.tgz)\n    - [voc_2007_test_results_fast_rcnn_vgg_cnn_m_1024_trained_on_2007_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2007_test_results_fast_rcnn_vgg_cnn_m_1024_trained_on_2007_trainval.tgz)\n    - [voc_2012_test_results_fast_rcnn_vgg16_trained_on_2007_trainvaltest_2012_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2012_test_results_fast_rcnn_vgg16_trained_on_2007_trainvaltest_2012_trainval.tgz)\n    - [voc_2012_test_results_fast_rcnn_vgg16_trained_on_2012_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2012_test_results_fast_rcnn_vgg16_trained_on_2012_trainval.tgz)\n- [Fast R-CNN VGG16 model](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc12_submission.tgz) trained on VOC07 train,val,test union with VOC12 train,val\n# fast-rcnn_flow\n", 
  "id": 46635473
}