{
  "read_at": 1462558551, 
  "description": "Implementation of the method proposed in the papers \" TextProposals: a Text-specific Selective Search Algorithm for Word Spotting in the Wild\" and \"Object Proposals for Text Extraction in the Wild\" (Gomez & Karatzas), 2016 and 2015 respectively.", 
  "README.md": "# TextProposals\n\nImplementation of the method proposed in the papers:\n\n* \"TextProposals: a Text-specific Selective Search Algorithm for Word Spotting in the Wild\" (Gomez and Karatzas), arXiv:1604.02619 2016.\n\n* \"Object Proposals for Text Extraction in the Wild\" (Gomez & Karatzas), International Conference on Document Analysis and Recognition, ICDAR2015.\n\nThis code reproduces the results published on the papers for the SVT, ICDAR2013, ICDAR2015 datasets.\n\nIf you make use of this code, we appreciate it if you cite our papers:\n```\n@article{gomez2016,\n  title     = {TextProposals: a Text-specific Selective Search Algorithm for Word Spotting in the Wild},\n  author    = {Lluis Gomez and Dimosthenis Karatzas},\n  journal   = {arXiv preprint arXiv:1604.02619},\n  year      = {2016}\n}\n```\n\n```\n@inproceedings{GomezICDAR15object,\n  title     = {Object Proposals for Text Extraction in the Wild},\n  author    = {Lluis Gomez and Dimosthenis Karatzas},\n  booktitle = {ICDAR},\n  year      = {2015}\n}\n```\n\nFor any questions please write us: ({lgomez,dimos}@cvc.uab.es). Thanks!\n\nIncludes the following third party code:\n\n  - fast_clustering.cpp Copyright (c) 2011 Daniel Mullner, under the BSD license. http://math.stanford.edu/~muellner/fastcluster.html\n  - binomial coefficient approximations are due to Rafael Grompone von Gioi. http://www.ipol.im/pub/art/2012/gjmr-lsd/\n\n## CNN models \n\nThe end-to-end evaluation require the DictNet_VGG model to be placed in the project root directory.\nDictNet_VGG Caffe model and prototxt are available here https://goo.gl/sNn5Xt\n\n## Compilation\n\nRequires: OpenCV (3.0.x), Caffe (tested with d21772c), tinyXML\n\n```\ncmake .\nmake\n```\n\n(NOTE: you may need to change the include and lib paths to your Caffe and cuda installations in CMakeLists.txt file)\n\n## Run\n\n  ``./img2hierarchy <img_filename>``\n\nwrites to stdout a list of proposals, one per line, with the format: x,y,w,h,c.\nwhere x,y,w,h define a bounding box, and c is a confidence value used to rank the proposals.\n\n\n  ``./img2hierarchy_cnn <img_filename>``\n\nsame as before but for end-to-end recognition using the DictNet_VGG CNN model.\n\n## End-to-end Evaluation\n\nThe following commands reproduce end-to-end results in our paper:\n\n  ``./eval_IC03 data/ICDAR2003/SceneTrialTest/words.xml <LEX_SIZE>``\n\n  ``./eval_SVT data/SVT/test.xml <LEX_SIZE>``\n\n  ``./eval_IC15 <LEX_SIZE>``\n\nThe value of LEX_SIZE parameter indicates the size of the lexicon to be used: 0 (for small lexicons), 1 (for Full lexicon), or 2 (for no lexicon, i.e. the 90k word vocabulary of the DictNet model).\n\nGround truth data for each dataset must be downloaded and placed in their respective folders in ./data/ directory.\n\nIn the case of ICDAR2015, since test ground truth is not available, the program save the results in res/ directory. These results files can be uploaded to the ICDAR Robust Reading Competition site for evaluation.\n\n## Object Proposla Evaluation\n\nThe following command lines generate a txt file with proposals for each image in the SVT and ICDAR2013 datasets respectively.\n\n  ``for i in `cat /path/to/datasets/SVT/svt1/test.xml | grep imageName | cut -d '>' -f 2 | cut -d '<' -f 1 | cut -d '/' -f 2 | cut -d '.' -f 1 `; do echo $i; ./img2hierarchy /path/to/datasets/SVT/svt1/img/$i.jpg 13 > data/$i; done;``\n\n  ``for i in `cat /path/to/datasets/ICDAR2013/test_locations.xml | grep imageName | cut -d '>' -f 2 | cut -d '<' -f 1 | cut -d '_' -f 2 | cut -d '.' -f 1`; do echo $i; ./img2hierarchy /path/to/datasets/ICDAR2013/test/img_$i.jpg 13 > data/$i; done``\n\nonce the files are generated you may want to run the matlab code in the evaluation/ folder to get the IoU scores and plots.\n\nNotice that the MATLAB evaluation script performs deduplicatioin of the bounding boxes proposals. Thus, if tou use another evauation framework you must deduplicate proposals same way.\n", 
  "id": 36567091
}