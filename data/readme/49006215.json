{
  "read_at": 1462552312, 
  "description": "Lightweight framework for learning with side information, based on Theano and Lasagne. For more info on learning with side information see http://arxiv.org/abs/1511.06429", 
  "README.md": "# concarne \n\n#### a lightweight framework for learning with side information, based on Theano and Lasagne \n\nconcarne implements various patterns for learning with side information presented in this [paper](http://arxiv.org/abs/1511.06429).\n\n### Quickstart\n\n- Check out concarne from the repository<br/>\n```git clone https://github.com/tu-rbo/concarne.git```\n- Install concarne:<br/>\n```python setup.py install```\n- Run the simple example <br/>\n```python example/simple_multiview.py```\n\nFor more information on how to use concarne, checkout out the documentation\nor the code of the simple example example/simple_multiview.py\n\nThe experiments in the paper are implemented in example/synthetic.py and\nexample/handwritten.py\n\n\n### What is concarne?\n\nconcarne implements a variety of different patterns that enable to apply\n*side information*. As it depends on Theano and lasagne, you can use \nneural network structures that you have developed yourself and easily\ncombine them with the side information learning task.\n\n### What is learning with side information?\n\nSupervised, semi-supervised, and unsupervised learning estimate a function \ngiven input/output samples. Generalization to unseen samples requires making \nprior assumptions about this function. However, many priors assumptions cannot be defined \nby only taking the function, its input, and its output into account. \n\nWe use *side information* to define such priors. Side information are\ndata that are neither from the input space nor from the output space of the function,\nbut include useful information for learning it. Importantly, these \ndata *are not required during test time*, but only during training time.\n\nLearning with side information subsumes a variety of related approaches, such as \n- multi-task learning \n- multi-view learning (or co-learning)\n- Learning using Privileged Information\n- Slow Feature Analysis\n- and others\n\n### Examples for learning with side information?\n\nTo apply learning with side information, you need to have an additional source of data (neither input nor output of your\nclassifier/regressor) available during training - the *side information*.\nHowever, this additional data is *not required during test time*.\n\n1. Imagine you want to classify images, and during test time you only have RGB\ndata available, but during training you also have 3D depth information \navailable. Learning with side information, in particular the multi-view pattern allows you\nto incorporate the depth data during training time to shape your classifier,\nwithout making the depth data an input of your classifier.<br/>\nPaper: [Chen et al., 2014: Recognizing RGB Images by Learning from RGB-D Data](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Chen_Recognizing_RGB_Images_2014_CVPR_paper.pdf)\n\n2. Again consider image classification, but now imagine that in addition to the\nlabels for each training sample you also know the pose of the object in the image. \nYou can use this pose information as an auxiliary prediction task using\nthe *multi-task* pattern.<br/>\nPaper: [Zhao & Itti, 2016: Improved Deep Learning of Object Category using Pose Information](https://www.researchgate.net/publication/283734369_Improved_Deep_Learning_of_Object_Category_using_Pose_Information)\n\n3. Another way to use pose information is to use relative poses between\n*pairs of images*. This can be done using the *pairwise transformation pattern*.\n<br/>\nPaper: [Jayaraman & Grauman, 2015: Learning image representations equivariant to ego-motion](http://arxiv.org/pdf/1505.02206.pdf)\n\n4. If you know want your side information is much better for predicting the\ntarget than the input data, you can apply the *direct pattern* to do a regression \nof the input on the side information, and then use the resulting representation to\npredict the targets.\n\nAll examples are examples for supervised learning, but learning with side information\nis equally applicable to reinforcement learning:\n[Jonschkowski & Brock, 2015: Learning state representations with robotic priors](http://www.robotics.tu-berlin.de/fileadmin/fg170/Publikationen_pdf/Jonschkowski-15-AURO.pdf)\n\n### Requirements\n\n- [Theano](http://deeplearning.net/software/theano/)\n- [Lasagne](https://github.com/Lasagne/Lasagne)\n\nFollow the installation requirements for these frameworks.\n\nFor using the nolearn compatibility extension, you will need to install the newest version of [nolearn](https://github.com/dnouri/nolearn) which requires pydotplus.\n\n### Running tests\n\nIn the concarne repository root, type\n   ```nosetests tests```\n\n### Building the API documentation\n\nIn the concarne repository root, type\n\n    cd docs\n    make html\n    \nYou can now read the documentation by opening docs/_build/html/index.html\n\n### Citing concarne\n\nIf you use concarne in your scientific work, please consider citing the following paper:\n\n    @article{\n      author    = {Rico Jonschkowski and Sebastian H{\\\"{o}}fer and Oliver Brock},\n      title     = {Patterns for Learning with Side Information},\n      volume    = {arXiv:1511.06429 [cs.LG]},\n      year      = {2016},\n      url       = {http://arxiv.org/abs/1511.06429},\n\t}\n\nWe would also be glad if you sent us a copy of your paper!\n\n### Disclaimer\n\nParts of concarne contain code from the [nolearn](https://github.com/dnouri/nolearn) library, Copyright (c) 2012-2015 Daniel Nouri.\n\nNo animals were harmed during the development of this framework.\n", 
  "id": 49006215
}