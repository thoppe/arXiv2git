{
  "read_at": 1462548738, 
  "description": "Automatic Differentiation framework for Scala", 
  "README.md": "# scalaad\n\nAutomatic differentiation for Scala\n\n## Use\n\n```scala\nimport com.kogecoo.scalaad.graph.Var  // always need to import\nimport com.kogecoo.scalaad.ScalarRule.Implicits._  // when x is a scalar variable\n\nval x = Var(5.0)\nval y = 2 * x + 3 * x * y\n\n// forward-mode automatic differentiation\n// partial differentiation w.r.t x\nprintln(y.deriv(x))\n\n// reverse-mode automatic differentiation computes a gradient\nprintln(y.grad())\n\n// we can get partial differentiation through `gradient` after running grad()\nprintln(x.gradient)\nprintln(y.gradient)\n```\n\n## TODO\n* test\n* make it to be multiple package\n* exclude Nd4jRule and BreezeRule to other package\n* maven repo\n\n## Reference\n* http://d.hatena.ne.jp/Nos/20130811/1376232751\n* http://www.win-vector.com/dfiles/ReverseAccumulation.pdf\n* http://www.win-vector.com/blog/2010/07/gradients-via-reverse-accumulation/\n* http://www.win-vector.com/blog/2010/06/automatic-differentiation-with-scala/\n* https://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/\n* https://justindomke.wordpress.com/2009/03/24/a-simple-explanation-of-reverse-mode-automatic-differentiation/\n* http://arxiv.org/pdf/1404.7456v1.pdf\n* http://arxiv.org/pdf/1502.05767v2.pdf\n* https://en.wikipedia.org/wiki/Automatic_differentiation\n* http://www.met.reading.ac.uk/clouds/publications/adept.pdf\n* http://colah.github.io/posts/2015-08-Backprop/index.html\n* http://uhra.herts.ac.uk/bitstream/handle/2299/4335/903836.pdf?sequence=1\n", 
  "id": 43255723
}