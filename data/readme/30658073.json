{
  "read_at": 1462552138, 
  "description": "", 
  "README.md": "# Egocentric_Visual_Keyframes_Summary\n\nThis code extracts a visual summary of a set of egocentric images captured by Narrative Clip or  SenseCam. The result is a collage with one image summarizing every event of the images' set. \n\nIf you use this code, please cite the following paper:\n\n    Bolanos, M., Mestre, R., Talavera, E., Giro-i-Nieto, X. & Radeva, P. (2015). \n    \"Visual Summary of Egocentric Photostreams by Representative Keyframes\". \n    In International Workshop on Wearable and Ego-vision Systems for Augmented Experience (WEsAX). ICME (in press). \n    Pre-print: http://arxiv.org/abs/1505.01130\n\nFor using the code, please download BVLC Reference CaffeNet model from the provided script from Caffe \n(./scripts/download_model_binary.py) and pass its path as a parameter to maingVisualSummary.m. \nCheck the following link for more information:\nhttp://caffe.berkeleyvision.org/model_zoo.html\n\nThe extraction runs as follows:\n\n[visualSummaryRandomWalk, visualSummaryMinimumDistance, visualSummaryRandom, visualSummaryUniform] = mainVisualSummary(path, montageFlag);\n\nThis function extracts the visual summary of all the images of the specific path.\n\nInputs:\n\n    -path: string containing the path of the images to summarize. Example of path: path='/imatge/rmestre/work/Images/testImages/Petia2';\n    -montageFlag: boolean. If it's value is true, the code will plot every event and it's representative images. This is useful if we want to extract figures with the complete events and the representative images to evaluate the results. It is recommended to put a breakpoint at the \"montage(im)\" line, if not all figures will overwrite the previous one.\n\nOutput:\n\n    -visualSummaryRandomWalk: a cell array containing the paths of the representative images extracted through random walk.\n    -visualSummaryMinimumDistance: a cell array containing the paths of the representative images extracted through minimum distance.\n    -visualSummaryRandom: a cell array containing the paths of the representative images extracted choosing a random image of the event.\n    -visualSummaryUniform: a cell array containing the paths of the representative images extracted choosing temporally equidistant images.\n\nOnce we obtain the cell arrays, we only have to execute the montage function:\nmontage(visualSummaryRandomWalk);\n\nThe code also includes functions to extract the Jaccard Index of the events segmentation:\n\n[cutoff, numClusters, JI] = resultsClusterValidation(path, excel_filename, featuresMatrix, method, orderFlag, normFlag, N)\n\nThis function computes the Jaccard index along a rank of cutoff values. \n\nInputs:\n\n    -path: string containing the path of the images to summarize. Example of path: path='/imatge/rmestre/work/Images/testImages/Petia2';\n    -excel_filename: string containing the groundtruth file to analize. Example: excel_filename='GT_Petia2.xls';\n    -featuresMatrix: matrix containing the CNN features of the set images. The first column contains the name of this images.\n    -method: string indicating the method of linkage for the clusterdata function.\n    -orderFlag: scalar. If it is 0, the division algorithm will not be executed. If its value is 1, the temporally division will be applied, and if its value is 2 the division algorithm will be applied without taking into account the temporal information.\n    -normFlag: boolean. If it is true, the normalization will be applied.\n    -N: scalar that indicates the minimum number of images that must contain an event.\n    \nOutput:\n\n    -cutoff: vector of cutoff values.\n    -numClusters: for the cutoff values, the related number of clusters that every value cause.\n    -JI: for the cutoff values, the related Jaccard index.\n", 
  "id": 30658073
}