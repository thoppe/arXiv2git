{
  "read_at": 1462543906, 
  "description": "Code and documentation for the winning solution at the BCI Challenge @ NER 2015 : https://www.kaggle.com/c/inria-bci-challenge", 
  "README.md": "# BCI Challenge @ NER 2015\n\nCode and documentation for the winning solution at the BCI Challenge @ NER 2015 : https://www.kaggle.com/c/inria-bci-challenge\n\n**Authors**:\n* [Alexandre Barachant](http://alexandre.barachant.org) \n* Rafal Cycon\n* Cedric Gouy-Pailler\n\n**Contents** :\n\n- [Signal Processing & Classification Pipeline ](#signal-processing-classification-pipeline)\n    - [Introduction](#introduction)\n    - [Classification Pipeline](#classification-pipeline)\n    - [Results](#results)\n    - [Discussion](#Discussion)\n    - [References ](#references)\n- [Code](#code)\n- [Parameter file](#parameter-file)\n\n\n**Licence** : GLPv3. see Licence.txt\n\n# Signal Processing & Classification Pipeline \n\n## Introduction\n\nThe goal of this challenge was to detect error related potential recorded during a p300 spelling task. The classification must be done across subjects,\ni.e. training and test sets were composed by different subjects. This is a hard task due to the high inter-subjects variability of EEG. \nHowever, our Riemannian Geometry framework has been proven very powerful for dealing with this problem (see [2], [3], and the [decMeg2014 kaggle challenge](http://www.kaggle.com/c/decoding-the-human-brain)).\nThis is partly due to the property of invariance by congruent transformation of the Riemannian metric.\n\nStarting from here, the main difficulties of this challenge were to deal with the relatively high number of electrodes and to avoid overfitting.\nWe overcome the first issue by using a channel selection algorithm, and the second by using a bagging procedure and an appropriate cross-validation methodology.\n\n**The leak** : By analyzing the time between feedback events in session 5, it was possible to catch the output of the online detection Error. \nThe idea is that when an error is detected, the correction of this error induces a small delay that can be detected with more or less reliability.\nGiven that the online Error detection was properly calibrated for the current subject, this analysis gave us two insights :\n\n1. the output of the online error detection for session 5. Of course, there is a higher probability of error when the online classifier detects an error, but it depends on the accuracy of the online classifier.\nThis can be used to increase detection accuracy, but only for the session 5.\n\n2. the percentage of error in session 5 i.e. a rough estimate of the class balance for each subjects. This second information is really important, because it can help to optimize the global AUC criterion, by adjusting the prediction to match the error probability of each subjects.\nOf course, this only helps the global AUC performance, and has little effect on the subject performance.\n\nWe propose two different models. The first one does not make any use of the\nleakage information and satisfies an \"online processing\" constraint, which means\nthat any trial performed by a subject can be classified without the need for\nfuture complementary data or information. The second model uses the leak, thus\nit is not online-compatible.\nThe two models are built upon the same classification pipeline, but with parameters tuned independently to achieve the highest performance.\n\n## Classification Pipeline\n\n#### Preprocessing\nEEG Signals are bandpass filtered by a 5th order Butterworth filter between 1 and 40 Hz. \nThen, signals are epoched to take only 1.3 second after the feedback event. The EOG channel is removed prior to any preprocessing.\n\n#### Feature Extraction\n\nThe EEG-based Feature extraction is done in 4 steps :\n\n1. *Xdawn Covariances* : Two sets of 5 XDAWN [1] spatial filters are estimated, one for each class (Error and Correct).\nThe grand average evoked potential of each class is then filtered by the corresponding set of spatial filters, and concatenated to each epochs.\nThe covariance matrix of each resulting epoch is then used as feature for the next steps. This process is similar to the one described in [2] and [3].\n2. *Electrode Selection* : A channel selection is applied to keep only relevant channels. The procedure consist in a backward elimination with the Riemannian distance between the \nRiemannian Geometric mean of the covariances of each class as the criterion. The algorithm is described in [4].\n3. *Tangent Space* : Reduced Covariances matrices are then projected in the tangent space, as described in [5] and [6].\n4. *Normalization* : Feature Normalization using a l1 norm.\n\nAfter these 4 steps, a set of Meta Feature are added to the EEG-based features.\nThe basic set of Meta feature is the following :\n\n* *Session id*  : the session number of the current epoch. \n* *FeedBack*    : the Feedback count since the beginning of the session. \n* *Letter*      : the Letter position in the current word. \n* *Word*        : the word count since the beginning of the session. \n* *FeedBackTot* : the feedback count since the first session.\n* *WordTot*     : the word count since the first session.\n* *isLong*      : was the current word flashed 8 times, i.e. a long sequence of flashes.\n\n**For the leak only**, two other features are added :\n* *OnlineErr*   : 1 if the online Error detection has detected an error (only available in session 5).\n* *Err Prop*    : the percentage of errors detected in the session 5.\n\n#### Classification \n\nAll the above features are inputted to an Elastic Net algorithm.\n\n**For the leak only**, *Err Prop* is added to the prediction with a coefficient of 0.8. \nAs an effect, it biases the results with an estimation of the classes balances. This has no effect on the AUC of a single subject, \nbut acts as on optimization for the Global AUC, which was the target metric.\n\n### Bagging\n\nThe above pipeline is applied on a number of random subsets of subjects, and predictions are averaged across bagged models. \nEach bagged model is built on an unique set of features (high diversity of features between subsets of subjects is achieved mostly due to the Electrode Selection step in feature extraction) and thus represents a different point of view of the training data.\nEnsembling bagged models improves generalization and effectively counters overfitting.\n\nFinal submission was an average of predictions of 500 bagged models, each trained on 9 subjects (out of 16, just one more subject above 50%). In 4-fold CV 150 bagged models were used.\n\n### Cross-validation\n\nThe validation approach was a 4-fold CV with data randomly split into folds subject-wise. The splitting was repeated several times (10 in most cases) and obtained AUCs averaged. The method proved to produce a reliable measure of performance.\n\n## Results\n\n#### AUC \n\n|         Submission         | Public LB | Private LB | Fold-wise CV (std) | Subject-wise CV (std) |\n|----------------------------|-----------|------------|--------------------|-----------------------|\n| No Leak (online compatible)| 0.85083   | 0.84585    | 0.7294  (0.037)    | 0.7696 (0.004)        |\n| Leak                       | 0.85145   | 0.87224    | 0.8008  (0.039)    | 0.7801 (0.004)        |\n\n\nCV results are given for 150 models, using the CV procedure described above. Fold-CV refers to the average AUC evaluated on all the predictions of the tests subjects. \nSubject-wise CV refers to the average AUC evaluated for each subject independently. Subject-wise CV represents performance of the model in a real case scenario, i.e. the performance a single user could expect in a online experiment. \n\nResults across Public and Private LB are quite stable and exhibit very good performance of both models.\n\nIn cross validation, the introduction of the leak has a little effect (0.01 AUC) on subject specific performance, but has a tremendous effect on Fold CV.\nShifting the predictions according to the leak effectively improves the Fold AUC.\n\nInterestingly, this effect is not as strong for LB results. Indeed, the no-leak model is able to correctly catch the class balance of each subject and bias the prediction accordingly.\nThis effect was not observed in CV results due to a smaller test set size.\n\n#### Effect of the number of electrodes\n\nA very important parameter was the number of electrodes in the electrode selection step ('nelec') of feature extraction.\nRiemannian geometry works best with a moderately low number of electrodes. The number of features in the tangent space is N(N+1)/2 with N the number of channels.\nA too high number of electrodes can lead to overfitting and estimation issues, while a too small number of channels leads to a loss of information. \n\nVarying the number of electrodes gives the following results (for the no-leak model) :\n\n![elec numbers](https://raw.githubusercontent.com/alexandrebarachant/bci-challenge-ner-2015/master/results/ElecNumbers.png)\n\nThe electrode selection already achieves very high performance for a number of electrodes as low as 15.\nInterestingly, using all electrodes gives the best AUC for private LB, but an optimal choice of number of electrodes may be different when using more bagged models.\n\nThe introduction of bagged model stabilizes results by making the prediction less sensitive to the electrode subset. \nThis effect is bigger when the number of electrodes in the subset decreases. \n\nThe final no-leak model was set to 35 electrodes, and only 23 for the leak model.\nThese values were chosen according mainly to CV results, but also partially to public LB scores.\n\n#### Effect of the number of bagged models\n\nFor the final submission we used 500 bagged models, each composed of 9 randomly selected subjects. The number of models for the final submissions was chosen based on the fact that adding more models could improve generalization \n(up to some 'plateau' point, which was unknown at the time), but too many models could not hurt the performance. \nIt was the safest choice while keeping the processing time reasonable. \n\nPost-competition tests indicated that as few as 10 models were already enough to provide good performance in private LB (tests made with the no-leak model):\n\n![bag numbers](https://raw.githubusercontent.com/alexandrebarachant/bci-challenge-ner-2015/master/results/BagsNumbers.png)\n\n## Discussion\n\nThe proposed method shows very good performance. For the specific combination of subjects in the private LB, electrode selection and ensembling did not improve significantly results.\nHowever, they did help to prevent overfitting and increase significantly performances in cross-validation. \n\nThe introduction of Meta features improve the results by 0.015 AUC on private LB. While some of them seem odd, they are acting as a support for the classifier to take into account\nthe possible shift in error prediction due to mental fatigue of the subject and other source of variability that occurs in long EEG sessions.\n\nFor this challenge, the evaluation criterion was the AUC calculated from the predictions of all the subjects put together. \nHowever, the fact that the subjects have different classes balances allow to optimize the score without making any prediction.\nAs a matter of fact, submitting the estimation of class balance of each subject (thanks to the leak) results in a Private LB score of 0.746, enough to be ranked in the top10.\n\n## References \n\n> [1] Rivet, B.; Souloumiac, A.; Attina, V.; Gibert, G., \"xDAWN Algorithm to Enhance Evoked Potentials: Application to Brain-Computer Interface,\" IEEE Transactions on Biomedical Engineering, vol.56, no.8, pp.2035,2043, Aug. 2009\n>\n> [2] A. Barachant, M. Congedo ,\"A Plug&Play P300 BCI Using Information Geometry\", arXiv:1409.0107. [link](http://arxiv.org/abs/1409.0107)\n>\n> [3] M. Congedo, A. Barachant, A. Andreev ,\"A New generation of Brain-Computer Interface Based on Riemannian Geometry\", arXiv: 1310.8115. [link](http://arxiv.org/abs/1310.8115)\n>\n> [4] A. Barachant and S. Bonnet, \"Channel selection procedure using riemannian distance for BCI applications,\" in 2011 5th International IEEE/EMBS Conference on Neural Engineering (NER), 2011, 348-351. [pdf](http://hal.archives-ouvertes.fr/docs/00/60/27/07/PDF/NER11_0016_FI.pdf)\n>\n> [5] A. Barachant, S. Bonnet, M. Congedo and C. Jutten, \"Multiclass Brain-Computer Interface Classification by Riemannian Geometry,\" in IEEE Transactions on Biomedical Engineering, vol. 59, no. 4, p. 920-928, 2012. [pdf](http://hal.archives-ouvertes.fr/docs/00/68/13/28/PDF/Barachant_tbme_final.pdf)\n>\n> [6] A. Barachant, S. Bonnet, M. Congedo and C. Jutten, \"Classification of covariance matrices using a Riemannian-based kernel for BCI applications\", in NeuroComputing, vol. 112, p. 172-178, 2013. [pdf](http://hal.archives-ouvertes.fr/docs/00/82/04/75/PDF/BARACHANT_Neurocomputing_ForHal.pdf)\n\n# Code\n\n### Dependencies & Requirements\n\nThe code is written in python. At least 8GB of RAM is required.\nThe following packages are used :\n\n* sklearn\n* numpy\n* scipy\n* pylab\n* pandas\n* pyyaml\n* glob\n* multiprocessing\n\n### Usage\n\n#### Preprocessing\nExtract train.zip and test.zip in the data folder. Put file TrainLabels.csv in the folder data/train.\n\nApply preprocessing on the data (one time only) :\n\n```bash\ncd preproc/\npython preproc.py\n```\n\n#### Generating Submissions\n\nrun prediction.py with the desired parameter file from the main folder. \n\nFor the submission with the leak :\n```bash\npython prediction.py parameters_Leak.yaml\n```\n\nFor the submission without the leak :\n```bash\npython prediction.py parameters_noLeak.yaml\n```\n\n:warning: Generating a submission takes around 70 minutes on a 12-core, 64Gb RAM computer.\nYou may adjust the 'core' parameters in the yaml files to fit your configuration. \nDefault is 4 cores.\n\n#### Cross validation\n\nrun cross_valid.py with the desired parameter file from the main folder. \n\nFor the submission with the leak :\n```bash\npython cross_valid.py parameters_Leak.yaml\n```\n\nFor the submission without the leak :\n```bash\npython cross_valid.py parameters_noLeak.yaml\n```\n\nCV takes around 12h to run on a 12-core, 64GB RAM computer\n\n### Troubleshooting\n\nIf you get Memory Error, decrease the number of cores in the parameters file.\nBy default 4 cores are used, which should work fine on a computer with 16GB RAM. \n\n# Parameter file\n\nFor this challenge, we built a framework based on the sklearn Pipeline system allowing us to quickly test different ideas and parameters without changing a line of code.\nThe classification pipeline is described in a parameter file, using a yaml syntax, and then parsed and built on the fly by the scripts.\nParameters files can be shared between team-mates, and Version Controlled, reducing the chance of errors. \n\nThe parameter file for the no-leak submission looks like this :\n\n```yaml\nimports:\n  sklearn.linear_model :\n    - ElasticNet\n  sklearn.preprocessing:\n    - Normalizer\n  classif:\n    - XdawnCovariances\n    - TangentSpace\n    - AddMeta\n    - ElectrodeSelect\n  \nCrossVal:\n  cores: 4\n  folds: 4\n  repetitions: 10\n  path: results.csv\n  comments: 'model-final-noLeak'\n\nSubmission:\n  path: submission-noLeak.csv\n  cores: 4\n\nMetaPipeline:\n  #leak:\n  bagging:\n     bag_size: 0.51 \n     models: 500 \n\npipeline:\n  - XdawnCovariances:\n      nfilter: 5\n      subelec: range(0,56,1)\n  - ElectrodeSelect:\n      nfilters: 5\n      nelec: 35\n      metric: \"'riemann'\"\n  - TangentSpace:\n      metric: \"'logeuclid'\"\n      tsupdate: False\n  - Normalizer:\n      norm: '\"l1\"'\n  - AddMeta:\n  - ElasticNet:\n      l1_ratio: 0.5\n      alpha: 2e-4\n      normalize: True\n```\n\n#### Imports\nThe import section lists packages to import :\nThe following section  :\n\n```yaml\nsklearn.linear_model :\n  - ElasticNet\n```\n\nis evaluated as :\n\n```python\nfrom sklearn.linear_model import ElasticNet\n```\n\n#### Pipeline\n\nThe different steps in the classification pipeline are described in the pipeline section.\nThey are build and pipelined in the order of appearance in the yaml list.\n\nThe last element should implement two methods : fit and predict.\nAll the intermediate element should implement a fit_transform and a transform methods.\nFor more information about sklearn pipeline, see [sklearn.pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n\nthe folowing section\n```yaml\n- ElasticNet:\n    l1_ratio: 0.5\n    alpha: 2e-4\n    normalize: True\n```\n\nis evaluated as :\n\n```python\nElasticNet(l1_ratio=0.5 , alpha=2e-4 , normalize=True)\n```\n\n### Build your own pipeline\n\nModifying or adding new steps in the pipeline can't be easier.\nLet say you want to add a PCA before the classification step.\n\nJust declare the sklearn pca in the import section\n\n```yaml\nimports:\n  sklearn.linear_model :\n    - ElasticNet\n  sklearn.decomposition: \n    - PCA\n```\n\nand add it in the pipeline :\n\n```yaml\npipeline:\n  - XdawnCovariances:\n      nfilter: 5\n      subelec: range(0,56,1)\n  - ElectrodeSelect:\n      nfilters: 5\n      nelec: 35\n      metric: \"'riemann'\"\n  - TangentSpace:\n      metric: \"'logeuclid'\"\n      tsupdate: False\n  - Normalizer:\n      norm: '\"l1\"'\n  - AddMeta:\n  - PCA:\n      n_components: 10\n  - ElasticNet:\n      l1_ratio: 0.5\n      alpha: 2e-4\n      normalize: True\n```\n\nand then run the prediction.py (or cross_valid.py) script :\n\n```\npython prediction.py parameters.yaml\n```\n\nVoila!\n", 
  "id": 32271432
}