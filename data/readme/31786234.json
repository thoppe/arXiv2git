{
  "read_at": 1462543359, 
  "description": "Using text analysis to automatically assign categories to articles from arXiv.", 
  "README.md": "## Automated classification of arXiv papers\n\nThe general goal of this project is to automatically classify research \narticles by assigning them to one or more of \nthe arXiv ([1]) subject categories. The training data consist \nof a collection of titles and abstracts from a representative sample of \narticles, downloaded using the arXiv API ([2]), or, alternatively, one of the related services described at [3].\n\n### Questions\n\n- Which classification methods provide the greatest accuracy for this problem?\n- How many articles from each subject area are needed to train the classifier?\n- How much does the date range of the training set matter (due to e.g. \n  changes in subjects being studied and terminology used over time)?\n- Does additional article metadata such as the authors' names improve the \n  accuracy of the classification algorithm?\n- Are certain subjects more difficult to identify than others?\n- Is there any evidence that some of the existing arXiv subject classes are \n  either too narrowly defined (e.g. if articles from two different classes \n  tend to get grouped together often) or too broad (may need to use \n  unsupervised categorization to determine this)?\n\n### Future extensions\n\n- Experiment with unsupervised categorization of article abstracts, using \n  topic modeling methods like latent Dirichlet allocation. How closely do \n  the categories identified match up with the existing arXiv subject classes? \n  Does the analysis suggest a need for any new subject classes?\n- Train the algorithm using full text from a selected set of articles ([4], [5]).\n- Devise a measure of similarity between articles, and use this metric to \n  link articles together. Such a network could be useful for multiple \n  applications, e.g. suggesting new articles to read based on what a \n  researcher is currently reading, or helping authors and journal referees \n  identify articles that should have been cited by a new study but weren't.\n\n[1]: http://arxiv.org/\n[2]: http://arxiv.org/help/api/index\n[3]: http://arxiv.org/help/bulk_data\n[4]: http://www.cs.cornell.edu/projects/kddcup/datasets.html\n[5]: http://arxiv.org/help/bulk_data_s3\n", 
  "id": 31786234
}