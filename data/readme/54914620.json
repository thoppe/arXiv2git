{
  "read_at": 1462554940, 
  "description": "Python implementation of Markov Networks for neural computing.", 
  "README.md": "[![Build Status](https://travis-ci.org/rhiever/MarkovNetwork.svg?branch=master)](https://travis-ci.org/rhiever/MarkovNetwork)\n[![Code Health](https://landscape.io/github/rhiever/MarkovNetwork/master/landscape.svg?style=flat)](https://landscape.io/github/rhiever/MarkovNetwork/master)\n[![Coverage Status](https://coveralls.io/repos/rhiever/MarkovNetwork/badge.svg?branch=master&service=github)](https://coveralls.io/github/rhiever/MarkovNetwork?branch=master)\n![Python 2.7](https://img.shields.io/badge/python-2.7-blue.svg)\n![Python 3.5](https://img.shields.io/badge/python-3.5-blue.svg)\n![License](https://img.shields.io/badge/license-MIT%20License-blue.svg)\n[![PyPI version](https://badge.fury.io/py/MarkovNetwork.svg)](https://badge.fury.io/py/MarkovNetwork)\n\n# Markov Network\n\n[![Join the chat at https://gitter.im/rhiever/MarkovNetwork](https://badges.gitter.im/rhiever/MarkovNetwork.svg)](https://gitter.im/rhiever/MarkovNetwork?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nPython implementation of Markov Networks for neural computing.\n\n## License\n\nPlease see the [repository license](https://github.com/rhiever/MarkovNetwork/blob/master/LICENSE) for the licensing and usage information for datacleaner.\n\nGenerally, we have licensed the MarkovNetwork package to make it as widely usable as possible.\n\n## Installation\n\nMarkovNetwork is built to use NumPy arrays for fast array processing. As such, we recommend installing the [Anaconda Python distribution](https://www.continuum.io/downloads) prior to installing MarkovNetwork. However, MarkovNetwork should work fine with any basic install of Python.\n\nOnce the prerequisites are installed, datacleaner can be installed with a simple `pip` command:\n\n```\npip install MarkovNetwork\n```\n\n## Usage\n\nWhen creating an instance of a MarkovNetwork, you can pass the following parameters:\n\n```\nnum_input_states: int (required)\n    The number of input states in the Markov Network\nnum_memory_states: int (required)\n    The number of internal memory states in the Markov Network\nnum_output_states: int (required)\n    The number of output states in the Markov Network\nseed_num_markov_gates: int (default: 4)\n    The number of Markov Gates with which to seed the Markov Network\n    It is important to ensure that randomly-generated Markov Networks have at least a few Markov Gates to begin with\n    May sometimes result in fewer Markov Gates if the Markov Gates are randomly seeded in the same location\nprobabilistic: bool (default: True)\n    Flag indicating whether the Markov Gates are probabilistic or deterministic\ngenome: array-like (default=None)\n    An array representation of the Markov Network to construct\n    All values in the array must be integers in the range [0, 255]\n    If None, then a random Markov Network will be generated\n```\n\nThe following code creatives a deterministic MarkovNetwork, provides some input, activates the network, then retrieves the output:\n\n```python\nfrom MarkovNetwork import MarkovNetwork\nimport numpy as np\n\nmy_mn = MarkovNetwork(num_input_states=2,\n                      num_memory_states=4,\n                      num_output_states=2,\n                      seed_num_markov_gates=5,\n                      probabilistic=False)\n\nmy_mn.update_input_states([1, 0])\nmy_mn.activate_network()\noutput_states = my_mn.get_output_states()\n```\n\nYou can repeat this process multiple times with different input:\n\n```python\nfrom MarkovNetwork import MarkovNetwork\nimport numpy as np\n\nmy_mn = MarkovNetwork(num_input_states=2,\n                      num_memory_states=4,\n                      num_output_states=2,\n                      seed_num_markov_gates=5,\n                      probabilistic=False)\n\nmy_mn.update_input_states([1, 0])\nmy_mn.activate_network()\noutput_states1 = my_mn.get_output_states()\n\nmy_mn.update_input_states([0, 1])\nmy_mn.activate_network()\noutput_states2 = my_mn.get_output_states()\n```\n\nIf you want to allow the MarkovNetwork to activate multiple times with the same inputs, you can pass a `num_activations` parameter to `activate_network()`:\n\n```python\nfrom MarkovNetwork import MarkovNetwork\nimport numpy as np\n\nmy_mn = MarkovNetwork(num_input_states=2,\n                      num_memory_states=4,\n                      num_output_states=2,\n                      seed_num_markov_gates=5,\n                      probabilistic=False)\n\nmy_mn.update_input_states([1, 0])\nmy_mn.activate_network(num_activations=20)\noutput_states = my_mn.get_output_states()\n```\n\nFinally, you can seed a MarkovNetwork with a pre-existing byte string by passing the `genome` parameter:\n\n```python\nfrom MarkovNetwork import MarkovNetwork\nimport numpy as np\n\nmy_mn_genome = np.random.randint(0, 256, 15000)\nmy_mn = MarkovNetwork(num_input_states=2,\n                      num_memory_states=4,\n                      num_output_states=2,\n                      probabilistic=False,\n                      genome=my_mn_genome)\n```\n\n## Having problems with the MarkovNetwork package?\n\nBefore you file a bug report, please [check the existing issues](https://github.com/rhiever/MarkovNetwork/issues?utf8=%E2%9C%93&q=is%3Aissue) to make sure that your issue hasn't already been filed or solved. If the bug is unreported, please [file a new issue](https://github.com/rhiever/MarkovNetwork/issues/new) and describe your bug in detail.\n\n## Contributing to the MarkovNetwork package\n\nWe welcome you to [check the existing issues](https://github.com/rhiever/MarkovNetwork/issues/) for bugs or enhancements to work on. If you have an idea for an extension to the MarkovNetwork package, please [file a new issue](https://github.com/rhiever/MarkovNetwork/issues/new) so we can discuss it.\n\n## Citing MarkovNetwork\n\nIf you use the MarkovNetwork package as part of your workflow in a scientific publication, please consider citing the following publication that describes Markov Networks in detail.\n\nRandal S. Olson, David B. Knoester, and Christoph Adami. \"Evolution of swarming behavior is shaped by how predators attack.\" *Artificial Life Journal*, to appear in Spring 2016.\n\n```\n@misc{Olson2016SelfishHerd,\nauthor = {Olson, Randal S. and Knoester, David B. and Adami, Christoph},\ntitle = {Evolution of swarming behavior is shaped by how predators attack},\nhowpublished={arXiv e-print. http://arxiv.org/abs/1310.6012},\nyear={2016}\n}\n```\n\nYou can also cite the repository directly using the following DOI:\n\n[![DOI](https://zenodo.org/badge/20747/rhiever/MarkovNetwork.svg)](https://zenodo.org/badge/latestdoi/20747/rhiever/MarkovNetwork)\n", 
  "id": 54914620
}