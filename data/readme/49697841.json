{
  "read_at": 1462552374, 
  "description": "Learning Multi-Domain Convolutional Neural Networks for Visual Tracking", 
  "README.md": "## MDNet: Multi-Domain Convolutional Neural Network Tracker\n\nCreated by [Hyeonseob Nam](http://cvlab.postech.ac.kr/~hyeonseob/) and [Bohyung Han](http://cvlab.postech.ac.kr/~bhhan/) at POSTECH\n\nProject Webpage: http://cvlab.postech.ac.kr/research/mdnet/\n\n### Introduction\n\nMDNet is the state-of-the-art visual tracker based on a CNN trained on a large set of tracking sequences,\nand the winner tracker of [The VOT2015 Challenge](http://www.votchallenge.net/vot2015/).\n\nDetailed description of the system is provided by our [arXiv technical report](http://arxiv.org/abs/1510.07945).\n\nThis software is implemented using [MatConvNet](http://www.vlfeat.org/matconvnet/) and part of [R-CNN](https://github.com/rbgirshick/rcnn).\n\n### Citation\n\nIf you're using this code in a publication, please cite our paper.\n\n\t@article{nam2015mdnet,\n      title={Learning Multi-Domain Convolutional Neural Networks for Visual Tracking},\n      author={Hyeonseob Nam and Bohyung Han},\n      journal={CoRR},\n      volume={abs/1510.07945},\n      year={2015},\n    }\n\n\n### License\n\nThis software is being made available for research purpose only.\nCheck LICENSE file for details.\n\n\n### System Requirements\n\nThis code is tested on 64 bit Linux (Ubuntu 14.04 LTS).\n\n**Prerequisites** \n  0. MATLAB (tested with R2014a)\n  0. MatConvNet (tested with version 1.0-beta10, included in this repository)\n  0. For GPU support, a GPU (~2GB memory) and CUDA toolkit according to the [MatConvNet installation guideline](http://www.vlfeat.org/matconvnet/install/) will be needed.\n\n\n### Installation\n\n  0. Compile MatConvNet according to the [installation guideline](http://www.vlfeat.org/matconvnet/install/). An example script is provided in 'compile_matconvnet.m'.\n  0. Run 'setup_mdnet.m' to set the environment for running MDNet.\n\n\n### Online Tracking using MDNet\n\n**Pretrained Models**\n\nIf you only need to run the tracker, you can use the pretrained MDNet models:\n  0. models/mdnet_vot-otb.mat (trained on VOT13,14,15 excluding OTB)\n  0. models/mdnet_otb-vot14.mat (trained on OTB excluding VOT14)\n  0. models/mdnet_otb-vot15.mat (trained on OTB excluding VOT15)\n\n**Demo**\n  0. Run 'tracking/demo_tracking.m'.\n\nThe demo performs online tracking on *'Diving'* sequence using a pretrained model 'models/mdnet_vot-otb.mat'.\n\nIn case of out of GPU memory, decrease *opts.batchSize_test* in 'tracking/mdnet_init.m'.\nYou can also disable the GPU support by setting *opts.useGpu* in 'tracking/mdnet_init.m' to false (not recommended).\n\n\n### Learning MDNet\n  \n**Preparing Datasets**\n\nYou may need OTB and VOT datasets for learning MDNet models. You can also use other datasets by configuring 'utils/genConfig.m'.\n  0. Download [OTB](http://cvlab.hanyang.ac.kr/tracker_benchmark/datasets.html) and [VOT](http://www.votchallenge.net/) datasets.\n  0. Locate the OTB sequences in 'dataset/OTB' and VOT201x sequences in 'dataset/VOT/201x', or modify the variables *benchmarkSeqHome* in 'utils/genConfig.m' properly.\n\n**Demo**\n  0. Run 'pretraining/demo_pretraining.m'.\n\nThe demo trains new MDNet models using OTB or VOT sequences.\n", 
  "id": 49697841
}