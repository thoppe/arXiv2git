{
  "read_at": 1462557507, 
  "description": "A lightweight library to build and train Deep Reinforcement Learning agents using Theano+Lasagne", 
  "README.md": "# AgentNet\nA lightweight library to build and train neural networks for reinforcement learning using Theano+Lasagne\n\n[![Build Status](https://travis-ci.org/yandexdataschool/AgentNet.svg?branch=master)](https://travis-ci.org/yandexdataschool/AgentNet)\n[![Gitter](https://badges.gitter.im/yandexdataschool/AgentNet.svg)](https://gitter.im/yandexdataschool/AgentNet?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=body_badge)\n\n\n## Installation\n[Here's an installation guide](https://github.com/yandexdataschool/AgentNet/wiki/Installing-AgentNet)\n\nIn short, \n### Manual install\n 1. Install [bleeding edge theano/lasagne](http://lasagne.readthedocs.io/en/latest/user/installation.html#bleeding-edge-version)\n 2. `[sudo] pip install --upgrade https://github.com/yandexdataschool/AgentNet/archive/master.zip`\n\n### [Docker container](https://hub.docker.com/r/justheuristic/agentnet/)\n 1. install [Docker](http://docs.docker.com/installation/), \n 2. make sure `docker` daemon is running (`sudo service docker start`)\n 3. make sure no application is using port 1234 (this is the default port that can be changed) \n 4. `[sudo] docker run -d -p 1234:8888 justheuristic/agentnet`\n 5. Access via localhost:1234 or whatever port you chose\n\n\n# Documentation and tutorials\nAgentNet is using embedded documentation, so calling `help(some_function_or_object)` or pressing shift+tab in Ipython will yield description of what that thing is supposed to do.\n\nA standard pipeline of AgentNet experiment can be found among examples\n* [Playing Atari SpaceInvaders with Convolutional NN via OpenAI Gym](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning%20%28OpenAI%20Gym%29.ipynb)\n  * Step-by-step explaination of what you need to do to recreate DeepMind Atari DQN\n  * Written in a generic way, so that adding recurrent memory or changing learning algorithm could be done in a couple of lines\n* [Simple Deep Recurrent Reinforcement Learning setup](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Basic%20tutorial%20on%20Boolearn%20Reasoning%20problem.ipynb)\n  * Most basic demo, if a bit boring. Covers the problem of learning \"If X1 than Y1 Else Y2\".\n  * Only required if SpaceInvaders left you confused.\n\n\n\n# Demos\n##### If you wish to get acquainted with the current library state, view some of the ./examples\n* [Playing Atari with Convolutional NN via OpenAI Gym](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Playing%20Atari%20with%20Deep%20Reinforcement%20Learning%20%28OpenAI%20Gym%29.ipynb)\n  * Can switch to any visual game thanks to their awesome interface\n  * Very simplistic, non-recurrent suffering from atari flickering, etc.\n* [Deep Recurrent Kung-Fu training with GRUs and actor-critic](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Deep%20Kung-Fu%20with%20GRUs%20and%20A2c%20algorithm%20%28OpenAI%20Gym%29.ipynb)\n  * Uses the \"Playing atari\" example with minor changes\n  * Trains via Advantage actor-critic (value+policy-based)\n* [Simple Deep Recurrent Reinforcement Learning setup](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Basic%20tutorial%20on%20Boolearn%20Reasoning%20problem.ipynb)\n  * Trying to guess the interconnected hidden factors on a synthetic problem setup\n* [Stack-augmented GRU generator](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Stack%20RNN%20for%20formal%20sequence%20modelling.ipynb)\n  * Reproducing http://arxiv.org/abs/1503.01007 with less code\n* [MOAR deep recurrent value-based LR for wikipedia facts guessing](https://github.com/yandexdataschool/AgentNet/blob/master/examples/Advanced%20MDP%20tools%20and%20wikicat.ipynb)\n  * Trying to figure a policy on guessing musician attributes (genres, decades active, instruments, etc)\n  * Using several hidden layers and 3-step Q-learning\n* More to come\n\nIf you wish to join the development, we would be eager to accept your help. Current priority development anchors are maintained at the bottom of this readme. \n\n\n\n", 
  "id": 52731535
}