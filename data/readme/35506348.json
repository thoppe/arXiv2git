{
  "id": 35506348, 
  "read_at": 1462558813, 
  "generate-readme.sh": "#!/bin/bash\n\ncat > README.md<<\"EOF\"\n<!-- Automatically generated by generate-readme.sh -->\n<!-- Do not edit directly! -->\n\n\n\n\n\n\n\n# Augment\n\n> This project is deprecated and unused.\nThis batch-processes a data set and writes the augmented images to disk.\nData augmentations for deep learning are better done on-the-fly\nwhile sampling training data to leverage free CPU cycles and\nsave disk space.\n\n**Crafted by [Brandon Amos](https://bamos.github.io).**\n\n[![Build Status](https://travis-ci.org/bamos/augment.svg?branch=master)](https://travis-ci.org/bamos/augment)\n\n## Input\n![](./images/lennon.jpg)\n\n## Output: Augmented Images\n![](./images/lennon-tiles-local.png)\n\n# Motivation\nDeep neural networks for object recognition empirically perform\nbetter with more data in the training set.\nThis tool, `augment`, augments an image and is intended to be\napplied to all training images prior to training.\n\nAn alternative, as in [1], is to augment images on the fly\nduring the training phase.\n\n# Translations\nThis project implements image translations as in Section 4.1 of [1]\nextracting random subsets from an input image.\n\n# Horizontal Reflections\nMany objects and faces should be recognized when flipped horizontally,\nso `augment` horizontally reflects every translated image\nto double the size of the data set.\n\n# Intensity Modifications\n**Warning: Using intensity modifications for face recognition\nmight not be desirable - I haven't seen good results from it.**\n\nSection 4.1 of [1] also discusses intensity modifications.\nPCA is performed on the set of RGB pixel values throughout the\nentire training set.\nMultiples of the principle components multiplied by a random\nvalue are added to each pixel in image,\nand each RGB channel is sampled independently.\n\n## Covariance Matrix Choices\nSee Section 4.1 of [1] for full details about how the\nintensity modifications use a covariance matrix of RGB pixels.\n\nThe `--imgCov` flag uses only the pixels in the current image,\notherwise the covariance matrix from\nCASIA-WebFace [2] is used.\n\n`augment-cov` can be used to compute the covariance\nmatrix for another dataset.\n\n# Using this library\n\n**Warning:\nDon't mix augmented data for the same image between your training and\ntesting sets.**\n\n## Building with cabal\nTo build the analytics binary, first install `GHC`, the\nGlasgow Haskell Compiler, and `cabal`, a build system\nand library database.\nAlso, [friday](https://github.com/RaphaelJ/friday), the\nimage processing library, requires [DevIL](https://github.com/DentonW/DevIL)\nand [hmatrix] requires blas and LAPACK.\n\n  + Arch: `pacman -S ghc cabal-install devil `\n  + OSX: `brew install ghc cabal-install devil `\n  + Ubuntu: `apt-get install ghc cabal-install libdevil-dev libblas-dev liblapack-dev`\n\nNext, `cd` into the `augment` directory and\ninstall the Haskell dependencies and build\nthe code with: `cabal install`.\nThe binary `augment` is now\nin `~/.cabal/bin`.\nYou can add `cabal`s bin directory to your `PATH`\nor use the full path.\n\n\n## `augment` Command Line Interface\n\n```\nEOF\n\n./dist/build/augment/augment --help >> README.md\n\ncat >> README.md<<\"EOF\"\n```\n\n# Augmenting Images in Parallel\n\nCombine `augment` with `xargs` to process images with a thread pool.\n\n```\ncat training-labels.txt \\\n  | xargs -l --max-procs=8 -I IMG augment --preserveSize --image IMG Append\n```\n\nUsing this on my 8-core server augmented 111,736 input images\nof size 152x152 to TODO output images in 27.75 hours.\n\n# References\n+ [1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton.\n  \"Imagenet classification with deep convolutional neural networks.\"\n  In Advances in neural information processing systems, pp. 1097-1105. 2012.\n  [Link.](http://papers.nips.cc/paper/4824-imagenet)\n+ [2] Yi, Dong, Zhen Lei, Shengcai Liao, and Stan Z. Li.\n  \"Learning Face Representation from Scratch.\"\n  arXiv preprint arXiv:1411.7923 (2014).\n  [Link.](http://arxiv.org/pdf/1411.7923.pdf)\nEOF\n", 
  "README.md": "<!-- Automatically generated by generate-readme.sh -->\n<!-- Do not edit directly! -->\n\n\n\n\n\n\n\n# Augment\n\n> This project is deprecated and unused.\nThis batch-processes a data set and writes the augmented images to disk.\nData augmentations for deep learning are better done on-the-fly\nwhile sampling training data to leverage free CPU cycles and\nsave disk space.\n\n**Crafted by [Brandon Amos](https://bamos.github.io).**\n\n[![Build Status](https://travis-ci.org/bamos/augment.svg?branch=master)](https://travis-ci.org/bamos/augment)\n\n## Input\n![](./images/lennon.jpg)\n\n## Output: Augmented Images\n![](./images/lennon-tiles-local.png)\n\n# Motivation\nDeep neural networks for object recognition empirically perform\nbetter with more data in the training set.\nThis tool, `augment`, augments an image and is intended to be\napplied to all training images prior to training.\n\nAn alternative, as in [1], is to augment images on the fly\nduring the training phase.\n\n# Translations\nThis project implements image translations as in Section 4.1 of [1]\nextracting random subsets from an input image.\n\n# Horizontal Reflections\nMany objects and faces should be recognized when flipped horizontally,\nso `augment` horizontally reflects every translated image\nto double the size of the data set.\n\n# Intensity Modifications\n**Warning: Using intensity modifications for face recognition\nmight not be desirable - I haven't seen good results from it.**\n\nSection 4.1 of [1] also discusses intensity modifications.\nPCA is performed on the set of RGB pixel values throughout the\nentire training set.\nMultiples of the principle components multiplied by a random\nvalue are added to each pixel in image,\nand each RGB channel is sampled independently.\n\n## Covariance Matrix Choices\nSee Section 4.1 of [1] for full details about how the\nintensity modifications use a covariance matrix of RGB pixels.\n\nThe `--imgCov` flag uses only the pixels in the current image,\notherwise the covariance matrix from\nCASIA-WebFace [2] is used.\n\n`augment-cov` can be used to compute the covariance\nmatrix for another dataset.\n\n# Using this library\n\n**Warning:\nDon't mix augmented data for the same image between your training and\ntesting sets.**\n\n## Building with cabal\nTo build the analytics binary, first install `GHC`, the\nGlasgow Haskell Compiler, and `cabal`, a build system\nand library database.\nAlso, [friday](https://github.com/RaphaelJ/friday), the\nimage processing library, requires [DevIL](https://github.com/DentonW/DevIL)\nand [hmatrix] requires blas and LAPACK.\n\n  + Arch: `pacman -S ghc cabal-install devil `\n  + OSX: `brew install ghc cabal-install devil `\n  + Ubuntu: `apt-get install ghc cabal-install libdevil-dev libblas-dev liblapack-dev`\n\nNext, `cd` into the `augment` directory and\ninstall the Haskell dependencies and build\nthe code with: `cabal install`.\nThe binary `augment` is now\nin `~/.cabal/bin`.\nYou can add `cabal`s bin directory to your `PATH`\nor use the full path.\n\n\n## `augment` Command Line Interface\n\n```\nAugment\n\nUsage: augment --image FILE [--noOverwrite] [--preserveSize]\n               [-w|--cropWidth PIXELS] [-e|--cropHeight PIXELS]\n               [-c|--numCrops INT] [-i|--numIntensities INT] [--imgCov] MODE\n\nAvailable options:\n  -h,--help                Show this help text\n  --image FILE             Input image to augment.\n  --noOverwrite            Don't overwrite images on output.\n  --preserveSize           Resize cropped images to the original size.\n  -w,--cropWidth PIXELS    The width of cropped images. (Default: 150)\n  -e,--cropHeight PIXELS   The height of cropped images. (Default: 150)\n  -c,--numCrops INT        The number of cropped images. (Default: 10)\n  -i,--numIntensities INT  The number of intensity changes to make above and\n                           below, per cropped image. (Default: 10)\n  --imgCov                 Shift intensities from the input image's covariance\n                           matrix instead of a covariance matrix from a set of\n                           training images.\n  MODE                     How to output images. Described as 'commands' below.\n\nAvailable commands:\n  OutputDir                Output images in the specified directory.\n  Append                   Output images by appending to the file name.\n```\n\n# Augmenting Images in Parallel\n\nCombine `augment` with `xargs` to process images with a thread pool.\n\n```\ncat training-labels.txt \\\n  | xargs -l --max-procs=8 -I IMG augment --preserveSize --image IMG Append\n```\n\nUsing this on my 8-core server augmented 111,736 input images\nof size 152x152 to TODO output images in 27.75 hours.\n\n# References\n+ [1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton.\n  \"Imagenet classification with deep convolutional neural networks.\"\n  In Advances in neural information processing systems, pp. 1097-1105. 2012.\n  [Link.](http://papers.nips.cc/paper/4824-imagenet)\n+ [2] Yi, Dong, Zhen Lei, Shengcai Liao, and Stan Z. Li.\n  \"Learning Face Representation from Scratch.\"\n  arXiv preprint arXiv:1411.7923 (2014).\n  [Link.](http://arxiv.org/pdf/1411.7923.pdf)\n", 
  "description": "Image augmentation for training deep neural networks."
}