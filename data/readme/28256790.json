{
  "read_at": 1462557070, 
  "description": "Training deep neural networks with low precision multiplications", 
  "README.md": "# deep-learning-multipliers\n\n## Requirements\n\n* Theano 0.6 (Bleeding edge version)\n* Pylearn2 0.1 \n* PyTables (for the SVHN dataset)\n* a CUDA capable GPU\n\n## Goal\n\nThis code was written to allow anyone to easily reproduce the results \nof the article \"Deep learning with low precision multipliers\", available at http://arxiv.org/abs/1412.7024 .\nThe article in question assesses whether it is possible to train Deep Neural Networks with low precision multipliers.\n\nNote that this code only simulates the impact of low precision multipliers.\nIt does not exploit it in any way.\nIf you are looking for fast low precision GPU kernels, NervanaSystems made some available https://github.com/NervanaSystems/nervanagpu . \n\n## How to run it\n\n### Command line\n\n    python main.py [task] [format] [initial range] [propagations bit-width] \n        [parameters updates bit-width] [ranges updates frequency]\n        [maximum overflow rate] [number of epochs of ranges initialization]\n\n### Task\n\nThere are 4 different tasks: the permutation invariant MNIST (PI_MNIST), \nMNIST, CIFAR10 and SVHN.\nA set of hyperparameters is associated with each of those tasks \n(They are stored in model.py).\nFor the SVHN dataset, \nyou need to set an environment variable: \n\n    SVHN_LOCAL_PATH=/tmp/SVHN/ \n    \nYou then need to pre-process it with the script \nutilities/svhn_preprocessing.py (script taken from pylearn2).\n\n### Format\n\nThere are 4 different formats: floating point (FLP), \nhalf floating point (HFLP), \nfixed point (FXP) and dynamic fixed point (DFXP).\n\n### Initial range\n\nInitial range is only useful for FXP and DFXP. \nIt is the initial position of the radix point \nfor the fixed point formats.\n5 works most of the time.\n\n### Propagations and parameters updates bit-widths\n\nOnly useful for FXP and DFXP.\nThose are the bit-widths of respectively the \npropagations and the parameters updates.\nNote that the sign is not counted in the bit-width.\n\n### Ranges update frequency\n\nRange update frequency is only useful for DFXP.\nIt is the number of batches between two ranges updates.\n\n### Maximum overflow rate\n\nOnly useful for DFXP.\nIt is the amount of overflow tolerated before modifying the range.\n    \n### Number of epochs of range initialization\n\nOnly useful for DFXP.\nThis is the number of epochs we train with high precision \nto find the initial scaling factors.\nOnce they are found, \nthe parameters are reinitialized, and the DFXP training can begin.    \n        \n### Examples\n\n    python main.py PI_MNIST FLP\n    python main.py SVHN FXP 5 19 19\n    python main.py CIFAR10 DFXP 5 9 11 100 0.0001 2\n        \n", 
  "id": 28256790
}