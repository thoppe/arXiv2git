{
  "read_at": 1462511806, 
  "description": "Collaborative Sound Design Based on Perceptual Mapping", 
  "README.md": "# SoundDesigner - Collaborative Sound Design Based on Perceptual Mapping \n![Screen-shot of prototype 1](overview.png \"Screen-shot of prototype\")\n![User study](g2.png \"People using one of the prototypes at the evaluation (video feed)\")\n\nThis is the original source code for the prototypical sound design application in the \npublication:\n\nKlugel, Niklas and Becker, Timo and Groh Georg. \"Designing Sound Collaboratively-Perceptually Motivated Audio Synthesis\"\n\nAbstract:\nIn this contribution, we will discuss a prototype that allows a group of users to design sound collaboratively in real time using a multi-touch tabletop. We make use of a machine learning method to generate a mapping from perceptual audio features to synthesis parameters. This mapping is then used for visualization and interaction. Finally, we discuss the results of a comparative evaluation study.\n\nwhich can be found here: http://www.nime.org/proceedings/2014/nime2014_339.pdf and http://arxiv.org/pdf/1406.6012 (extended version)\n\nThis application relies on a data set which has been published here as well, however the original sampling and timbre space construction method has not been released so far.\nIt is originally a tabletop application but the framework also allows use with mouse input apart from TUIO and native win7 touch.\n\nDependencies:\n- reakt: https://github.com/lodsb/reakt\n- UltraCom: https://github.com/lodsb/UltraCom\n- the Vector phase distortion synth has to be installed (part of the repository)\n\n- checkout and build + sbt publish for each of these\n\n- The real-time audio synthesis uses SuperCollider / ScalaCollider, therefore an additional SuperCollider installation is necessary.\n- External midi input to drive the synthesis algorithms\n- Audio output device with multiple channels (for individial headphone outputs)\n\n\n\n", 
  "id": 33392949
}