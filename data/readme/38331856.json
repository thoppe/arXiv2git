{
  "read_at": 1462549536, 
  "description": "Research on ALE --- mainly about bpro features", 
  "README.md": "# ALEResearch-LFA\nResearch on ALE --- mainly about bpro features and its extensions.\n\nWe choose to focus on using the linear function approximation, which is a simpler yet fixed representation approach.\n\nWe aim to achieve performance comparable to DQN's (Deep Q-networks)\n\nBpro and its extensions exploit spatial invariance, temporal offsets and a simple way to detect sprites.\n\nThe codes in the master branch are not used to generate any research results. Instead it lays the premiliminary foundation for real research.\nBproVector has the fastest codes to run BPRO feature set.\nbproTime has the codes to run BPROST feature set.\nBlob (branch) has the codes to run Blob-BPROST features set (blob is the name of our simple methods to detect sprites on screens).\nOther braches have some other experiments (e.g we tried to implement tug-of-wash hashing)\nAnother intersting brach is blobThreeVersion1(and blobThreeVersion2). Instead of doing pairwise offsets, it does offsets between three pixels. Still it has spatial invariance built in.\n\nIn blob and bproTime, it has seperate functions to generate temporal offsets (one pixel comes from current screen and the other comes from the screen five frames ago  and spatial offsets (both pixels come from current screens). The fucntions are called addTimeDimensionalOffsets and addRelativeFeaturesIndices respectively. In case you only want to run Blob-PROS or Blob-PROT (or B-PROS/ B-PROT), you can commet out the corresponding functions. Both have a redundant function called addThreePointOffsetsIndices, it never gets called. \n\nThe latest research results are available on http://arxiv.org/abs/1512.01563\n\nBraches start with Adaptive include our codes to attempt an adaptive feature representation in ALE. The work is still in progress.\n\n\n", 
  "id": 38331856
}