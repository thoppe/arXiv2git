{
  "read_at": 1462555476, 
  "description": "Implementation attempt of \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\"", 
  "README.md": "## SparseMax in Torch\n\nImplementation attempt of \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\" paper (Andre F. T. Martins, Ramon Fernandez Astudillo: http://arxiv.org/abs/1602.02068) in Torch\n\n## Example\n\n```lua\n\n  ______             __   |  Torch7\n /_  __/__  ________/ /   |  Scientific computing for Lua.\n  / / / _ \\/ __/ __/ _ \\  |  Type ? for help\n /_/  \\___/_/  \\__/_//_/  |  https://github.com/torch\n                          |  http://torch.ch\n\nth> nn = require 'nn'\n                                                                      [0.0000s]\nth> a1 = torch.rand(10)\n                                                                      [0.0001s]\nth> a1\n 0.1851\n 0.5324\n 0.2838\n 0.0006\n 0.3066\n 0.0450\n 0.4762\n 0.2809\n 0.0798\n 0.9339\n[torch.DoubleTensor of size 10]\n\n                                                                      [0.0001s]\nth> nn.SoftMax():forward(a1)\n 0.0847\n 0.1199\n 0.0935\n 0.0705\n 0.0957\n 0.0737\n 0.1134\n 0.0932\n 0.0763\n 0.1792\n[torch.DoubleTensor of size 10]\n\n                                                                      [0.0058s]\nth> nn.SparseMax():forward(a1)\n 0.0000\n 0.2182\n 0.0000\n 0.0000\n 0.0000\n 0.0000\n 0.1620\n 0.0000\n 0.0000\n 0.6197\n[torch.DoubleTensor of size 10]\n\nth> nn.SparseMax():test()\n\n...\n\n======= 2D Test =======\n-> 2D Input\n 0.9696  0.2880  0.2762  0.3397  0.2526  0.0734  0.9772  0.7903  0.0893  0.0026\n 0.9996  0.5334  0.5426  0.8036  0.2914  0.9608  0.6773  0.5930  0.5310  0.3592\n[torch.DoubleTensor of size 2x10]\n\n-> SoftMax\n 0.1647  0.0833  0.0823  0.0877  0.0804  0.0672  0.1659  0.1376  0.0683  0.0626\n 0.1412  0.0886  0.0894  0.1161  0.0696  0.1359  0.1023  0.0940  0.0884  0.0744\n[torch.DoubleTensor of size 2x10]\n\n-> SparseMax\n 0.3906  0.0000  0.0000  0.0000  0.0000  0.0000  0.3982  0.2113  0.0000  0.0000\n 0.3893  0.0000  0.0000  0.1933  0.0000  0.3505  0.0669  0.0000  0.0000  0.0000\n[torch.DoubleTensor of size 2x10]\n\n\n======= 3D Test =======\n-> 3D Input\n(1,.,.) =\n  0.9208  0.7367\n  0.3335  0.3119\n\n(2,.,.) =\n  0.8805  0.7559\n  0.1164  0.9982\n\n(3,.,.) =\n  0.4688  0.6817\n  0.7545  0.5034\n\n(4,.,.) =\n  0.7565  0.2452\n  0.8948  0.9769\n[torch.DoubleTensor of size 4x2x2]\n\n-> SoftMax\n(1,.,.) =\n  0.2902  0.2795\n  0.1968  0.1628\n\n(2,.,.) =\n  0.2788  0.2849\n  0.1584  0.3234\n\n(3,.,.) =\n  0.1847  0.2646\n  0.2998  0.1972\n\n(4,.,.) =\n  0.2463  0.1710\n  0.3450  0.3166\n[torch.DoubleTensor of size 4x2x2]\n\n-> SparseMax\n(1,.,.) =\n  0.4015  0.3452\n  0.0059  0.0000\n\n(2,.,.) =\n  0.3612  0.3645\n  0.0000  0.5053\n\n(3,.,.) =\n  0.0000  0.2903\n  0.4269  0.0106\n\n(4,.,.) =\n  0.2372  0.0000\n  0.5672  0.4841\n[torch.DoubleTensor of size 4x2x2]\n\n...\n```\n\n## TODO\n\n- Implement updateGradInput for > 1D tensors\n- Implement Equation (14) for better complexity\n- Write more tests\n", 
  "id": 53410903
}