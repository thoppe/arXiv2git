{
  "read_at": 1462555440, 
  "description": "", 
  "README.md": "# Special Feature for My Caffe \n\n- Clone from the official caffe with  f19f0f1 \n- Add faster rcnn joint train and test \\[DOING\\]\n- Add action recognition \\[DONE\\] \n- Add spatial transform network \\[Not Started\\] \n- Test for \"partial convolution\" to speed up\\[DOING\\]\n- With demos including all tasks above \\^_\\^\n\nIt's not completed, but I will update continually.\n\n## Faster RCNN End-To-End\n\n### Disclaimer\nThe official Faster R-CNN code (written in MATLAB) is [available](https://github.com/ShaoqingRen/faster_rcnn) here. If your goal is to reproduce the results in our NIPS 2015 paper, please use the [official](https://github.com/ShaoqingRen/faster_rcnn) code.\n\nThis repository contains a C++ reimplementation of the Python code([py-faster-rcnn](https://github.com/rbgirshick/py-faster-rcnn)). This C++ implementation is built on the offcial [caffe](https://github.com/BVLC/caffe), I will continue to update this code for improvement and up-to-date by offcial caffe.\n\nAll following steps, you should do these in the $CAFFE\\_ROOT path.\n\n### Demo\nUsing **sh example/FRCNN/demo.sh**, the will process five pictures in the examples/FRCNN/images , and put results into examples/FRCNN/results .\n\nNote: You should prepare the trained caffemodel into models/FRCNN/ as ZF\\_faster\\_rcnn\\_final.caffemodel \n\n### Train\nUsing **sh example/FRCNN/train.sh**, the will start train voc2007 data using ZF model.\n\n- VOCdevkit should be put into $CAFFE\\_ROOT, ** ln -s $YOUR\\_VOCdevkit\\_Path $CAFFE\\_ROOT/VOCdevkit\n- ZF pretrain model should be put into models/FRCNN/ as ZF.v2.caffemodel\n\n### Detail\n\nMore details in the code.\n\n# Caffe\n\n[![Build Status](https://travis-ci.org/BVLC/caffe.svg?branch=master)](https://travis-ci.org/BVLC/caffe)\n[![License](https://img.shields.io/badge/license-BSD-blue.svg)](LICENSE)\n\nCaffe is a deep learning framework made with expression, speed, and modularity in mind.\nIt is developed by the Berkeley Vision and Learning Center ([BVLC](http://bvlc.eecs.berkeley.edu)) and community contributors.\n\nCheck out the [project site](http://caffe.berkeleyvision.org) for all the details like\n\n- [DIY Deep Learning for Vision with Caffe](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.p)\n- [Tutorial Documentation](http://caffe.berkeleyvision.org/tutorial/)\n- [BVLC reference models](http://caffe.berkeleyvision.org/model_zoo.html) and the [community model zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)\n- [Installation instructions](http://caffe.berkeleyvision.org/installation.html)\n\nand step-by-step examples.\n\n[![Join the chat at https://gitter.im/BVLC/caffe](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/BVLC/caffe?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nPlease join the [caffe-users group](https://groups.google.com/forum/#!forum/caffe-users) or [gitter chat](https://gitter.im/BVLC/caffe) to ask questions and talk about methods and models.\nFramework development discussions and thorough bug reports are collected on [Issues](https://github.com/BVLC/caffe/issues).\n\nHappy brewing!\n\n## License and Citation\n\nCaffe is released under the [BSD 2-Clause license](https://github.com/BVLC/caffe/blob/master/LICENSE).\nThe BVLC reference models are released for unrestricted use.\n\nPlease cite Caffe in your publications if it helps your research:\n\n    @article{jia2014caffe,\n      Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n      Journal = {arXiv preprint arXiv:1408.5093},\n      Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n      Year = {2014}\n    }\n", 
  "id": 53186140
}