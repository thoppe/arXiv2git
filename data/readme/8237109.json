{
  "README": "This is the collection of codes used in analysis of european POPRES data\n(see Nelson et al, http://www.ncbi.nlm.nih.gov/pubmed/18760391; \nobtain access to data at http://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000145.v1.p1 .)\nfor the paper \"The geography of recent genetic ancestry across Europe\", \nby Peter Ralph and Graham Coop, \npublished May 7, 2013, in PLoS Biology, at\nhttp://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001555\n\nTo see what makes what, see the makefile.\n\nMost of the files are pretty clean, but a few have some clutter.\n\nNone will actually do anything without obtaining the POPRES data and running BEAGLE http://faculty.washington.edu/browning/beagle/beagle.html on them.\n\nPlease use these if they are useful, and credit us if appropriate.\n\n\n--------------\n\nIf you are looking to use the inference method, look for the functions sinv() and squoosh().\n\nAlso, linv() gives the least-squares approximation, useful for finding a good starting point.\n\nFor instance, see the block in inversion-writeup-plots.R that sets things up to infer histories for all the pairs of populations:\n\n# Set-up: the operator L and the false positive rate estimates:\ngens <- cumsum( rep(1:36, each=10) )\nL <- error.disc.trans( lenbins=lenbins, gens=gens, chrlens=.chrlens[setdiff(seq_along(.chrlens),omitchroms)] )) # this takes a while!! do it once and save.\nfp <- disc.fp(lenbins, chrlens=.chrlens)\nfp <- runmed(fp,k=15)\n# Set-up for intial least-squares estimate:\nS <- as.vector( smooth( hist( blocks$maplen, breaks=c(lenbins,100), plot=FALSE )$counts ) )\nS <- S/mean(S)\nS[lenbins>20] <- exp( predict( lm( log(S) ~ lenbins + I(lenbins^2), subset=(lenbins>20) & (S>0) ), newdata=list(lenbins=lenbins[lenbins>20]) ) )\nest.Sigma <- function ( np, X, alpha=100 ) {\n    # estimate Sigma by combining the population average with the smoothed, observed data\n    # where Sigma is the covariance matrix of X/np\n    smX <- as.vector( smooth(X) )\n    ppp <- (alpha*np/(2543640+alpha*np))  # 2543640 = total # pairs\n    Sigma <- ppp*smX + (1-ppp)*sum(smX)*S/sum(S)\n    return( Sigma/np^2 )\n}\nKsvd <- svd( 1/sqrt(as.vector(S)) * L )  # pre-compute SVD of L\ntotal.npairs <- choose( length(unique(blocks$id1)), 2 )\nlinverse <- linv( X=lendist/total.npairs, S=as.vector(S), Sigma=est.Sigma(np=total.npairs,X=lendist), Ksvd=Ksvd, maxk=30, fp=fp )\nsminverse <- smoothed.nonneg( lS=linverse, Ksvd=Ksvd, bestk=15, lam=1 )\n\n# Here is where we get the actual estimate:\nans <- sinv( lendist, sminverse, L, fp, npairs=total.npairs, lam=0, gamma=1e6 )\n\n# squoosh iterates sinv, looking for the smoothest solution that drops no more than 2 units of log-likelihood\nsmooth = squoosh( lendist, xinit=ans, L, fp, npairs=ans$npairs, minlen=minlen, gamma=100, lam=0, fitfn=\"loglik\", relthresh=2/ans$npairs, twid=.05 )\n\n\n--------------\n\nNotes:\n\n* The .gmap files provide a mapping from the endpoint indices that BEAGLE uses to genetic distances (e.g. in centiMorgans).  Important: BEAGLE uses 0-based indices.\n\n* BEAGLE 4.0 is out, and improved over the version we used (3.3).\n", 
  "read_at": 1462547513, 
  "description": "Code to do data processing and create figures for \"The geography of recent genetic ancestry across Europe\", http://arxiv.org/abs/1207.3815", 
  "id": 8237109
}