{
  "read_at": 1462554024, 
  "description": "Single node topic model learning and inference via method of moments using tensor decomposition. Alternating least squares with pre-processing (a whitening step consists of orthogonalization and dimensionality reduction) is implemented. ", 
  "README.md": "TopicModeling\n=============\n\n\ncitation:\n\n@article{DBLP:journals/corr/HuangNHVA13,\nauthor    = {Furong Huang and\nNiranjan U. N and\nMohammad Umar Hakeem and\nPrateek Verma and\nAnimashree Anandkumar},\ntitle     = {Fast Detection of Overlapping Communities via Online Tensor Methods\non GPUs},\njournal   = {CoRR},\nyear      = {2013},\nvolume    = {abs/1309.0787},\nurl       = {http://arxiv.org/abs/1309.0787},\ntimestamp = {Sat, 25 Oct 2014 03:19:58 +0200},\nbiburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HuangNHVA13},\nbibsource = {dblp computer science bibliography, http://dblp.org}\n}\n\n\n\n================\nSingle node topic model learning and inference via method of moments using tensor decomposition. \nAlternating least squares with pre-processing (a whitening step consists of orthogonalization and dimensionality reduction) is implemented. \n\nSynthetic Data Generator: \n\t\tTopicModeling/SyntheticDataGenerator.m\n\nData folder is: \n\t\t$(SolutionDir)\\datasets\\\n\nInput Arguments:\n\n//=========================================================================\n\t// User Manual: \n\t// (1) Data specs\n\tInputArgument 1: NX is the training sample size\n\tInputArgument 2: NX_test is the test sample size\n\tInputArgument 3: NA is the vocabulary size\n\tInputArgument 4: KHID is the number of topics you want to learn\n\tInputArgument 5: alpha0 is the mixing parameter, usually set to < 1\n\tInputArgument 6: DATATYPE denotes the index convention. \n\t// -> DATATYPE == 1 assumes MATLAB index which starts from 1,DATATYPE ==0 assumes C++ index which starts from 0 .\n\t// e.g.  10000 100 500 3 0.01 1 \n\tconst char* FILE_GA = argv[7];\n\tconst char* FILE_GA_test = argv[8];\n\t// (2) Input files\n\tInputArgument 7: $(SolutionDir)\\datasets\\$(CorpusName)\\samples_train.txt \n\tInputArgument 8: $(SolutionDir)\\datasets\\$(CorpusName)\\samples_test.txt \n\t// e.g. $(SolutionDir)datasets\\synthetic\\samples_train.txt $(SolutionDir)datasets\\synthetic\\samples_test.txt\n\tconst char* FILE_alpha_WRITE = argv[9];\n\tconst char* FILE_beta_WRITE = argv[10];\n\tconst char* FILE_hi_WRITE = argv[11];\n\t// (3) Output files\n\tInputArgument 9: FILE_alpha_WRITE denotes the filename for estimated topic marginal distribution\n\tInputArgument 10: FILE_beta_WRITE denotes the filename for estimated topic-word probability matrix\n\tInputArgument 11: FILE_hi_WRITE denote the estimation of topics per document for the test data. \n\t// The format is:\n\t// $(SolutionDir)\\datasets\\$(CorpusName)\\result\\alpha.txt \n\t// $(SolutionDir)\\datasets\\$(CorpusName)\\result\\beta.txt \t\n\t// $(SolutionDir)\\datasets\\$(CorpusName)\\result\\hi.txt \n\t// e.g. $(SolutionDir)datasets\\synthetic\\result\\alpha.txt $(SolutionDir)datasets\\synthetic\\result\\beta.txt $(SolutionDir)datasets\\synthetic\\result\\hi.txt\n\t//=====================================================================\n\n", 
  "id": 27342714
}