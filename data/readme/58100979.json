{
  "read_at": 1462556731, 
  "description": "Sentence/Caption evaluation using automated metrics", 
  "README.md": "## Caption Evaluator ##\n\nSentence/Caption evaluation using automated metrics.\n\nThis code is released as supplementary material with\n[S2VT](https://vsubhashini.github.io/s2vt.html)\\[1\\].\n\nThis code can be used to\n\n1. evaluate sentences/captions for any dataset,\n2. it provides BLEU, METEOR, ROUGE-L and CIDEr scores.\n\nThis uses the MSCOCO caption evaluation code \\[2\\].\n\n### Getting started\n\n1. **Get this code.** `git clone https://github.com/vsubhashini/caption-eval.git`\n2. **Get the coco evaluation scripts.** `./get_coco_scripts.sh`\n\nTo ensure you have all the dependencies for the evaluation scripts, please refer\nto the [COCO Caption Evaluation page](https://github.com/tylin/coco-caption).\n\n\n### Evaluating predicted sentences against groundtruth references\n\n**Make sure you have the coco scripts**\n```\n    ./get_coco_scripts.sh\n```\n\n**Create your groundtruth references in the desired format**\n\nHere's a sample file with several reference sentences: `data/references.txt`\n```\n    python create_json_references.py -i data/references.txt -o data/references.json\n```\n\n**Evaluate the model predictions against the references**\n\nSample file with predictions from a model is in `data/predicted_sentences.txt`\n```\n    python run_evaluations.py -i data/predicted_sentences.txt -r data/references.json\n```\n\n### References\n\n- [Sequence to Sequence - Video to Text](http://arxiv.org/abs/1505.00487)\n- [Microsoft COCO Captions: Data Collection and Evaluation Server](http://arxiv.org/abs/1504.00325)\n- PTBTokenizer: [Stanford Tokenizer](http://nlp.stanford.edu/software/tokenizer.shtml) which is included in [Stanford CoreNLP \n3.4.1](http://nlp.stanford.edu/software/corenlp.shtml).\n- BLEU: [BLEU: a Method for Automatic Evaluation of Machine Translation](http://www.aclweb.org/anthology/P02-1040.pdf)\n- Meteor: [Project page](http://www.cs.cmu.edu/~alavie/METEOR/) with related publications. COCO server uses version (1.5) of the \n[Code](https://github.com/mjdenkowski/meteor).\n- Rouge-L: [ROUGE: A Package for Automatic Evaluation of Summaries](http://anthology.aclweb.org/W/W04/W04-1013.pdf)\n- CIDEr: [CIDEr: Consensus-based Image Description Evaluation] (http://arxiv.org/pdf/1411.5726.pdf)\n\n\n\\[1\\] [Sequence to Sequence - Video to Text](https://vsubhashini.github.io/s2vt.html)\n\n    Sequence to Sequence - Video to Text\n    S. Venugopalan, M. Rohrbach, J. Donahue, T. Darrell, R. Mooney, K. Saenko\n    The IEEE International Conference on Computer Vision (ICCV) 2015\n\n\\[2\\] [Microsoft COCO Captions: Data Collection and Evaluation Server](https://github.com/tylin/coco-caption)\n\n    Microsoft COCO Captions: Data Collection and Evaluation Server\n    X. Chen, H. Fang, T.Y. Lin, R. Vedantam, S. Gupta, P. Dollar, C.L. Zitnick\n    arXiv preprint arXiv:1504.00325\n", 
  "id": 58100979
}