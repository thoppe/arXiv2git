{
  "read_at": 1462548128, 
  "description": "Faster than real time visual odometry", 
  "README.md": "# BPVO\n\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/8506/badge.svg)](https://scan.coverity.com/projects/halismai-bpvo)\n[![Build Status](https://api.travis-ci.org/halismai/bpvo.svg?branch=master)](https://github.com/halismai/bpvo)\n\n\nA library for (semi-dense) real-time visual odometry from stereo data using direct alignment of feature descriptors. There are descriptors implemented. First, is raw intensity (no descriptor), which runs in  _real-time_  or faster. Second, is an implementation of the Bit-Planes descriptor designed for robust performance under challenging illumination conditions as described [here][bp] and [here][bpvo].\n\nIf you run into any issues, or have questions contact\n```\nhalismai @ cs . cmu . edu\n```\n\n## Building\n\n### Dependencies\n\n* Compiler with c++11 support. Code is tested with `gcc-4.9`, `clang-3.5`, and `icc 16.0.1`\n* [Eigen][eigen] version 3.2+\n* [OpenCV][opencv] version 2.11 usage of opencv is limited to a few function. You need the `core`, `imgproc`, and optionally `highgui` and `contrib` modules.\n* Optional, but recommended,`tbb` to speed up Bit-Planes. The code works with OpenMP as well, if available in the system.\n* Optional: boost `program_options` and `circular_buffer`. You need version 1.58, 1.59 (there seems to be a bug with boost version 1.60). Older versions of boost will not work, as they do not have support for move semantics.\nOther optional packages:\n\nThere are two libraries, the core `bpvo` and some utilities `bpvo_utils`. You do not need to compile the utilities if you want to embed the library in your code. If you are not building the utilities library, you do not need the following dependencies:\n* `boost`\n* `opencv_highgui`\n* `opencv_contrib`\n\nYou can drop opencv altogether if you provide your own stereo code (and edit the code slightly).\n\nTo build the code base\n```shell\nmkdir build && cmake .. && make -j2\n```\n\nSee `CMakeLists.txt` for additional flags and configurations. You may also configure the library using `cmake-gui`\n\n\n## Building the Matlab interface\nGet [mexmat](https://github.com/halismai/mexmat) and install it on your system.\n```\ngit clone https://github.com/halismai/mexmat.git\n```\nIt is a header-only library, so no compilation is needed. Then, until the matlab interface is integrated into the build system,\n```\ncd matlab && make\n```\n\nYou might need to modify `matlab/Makefile` to point to the right location of Matlab and the c++ compiler. As of the date of writing (04/2016) Matlab R2015a supports up to g++-4.7. The code will require `g++4.8+`\n\nIf you get issues with Matlab GLIB_xxx not found, start matlab as\n```\nLD_PRELOAD=`g++-4.8+ -print-file-name=libstdc++.so` matlab\n```\n\nThere is an experimental support for building the Matlab interface directly from the CMake build system. To try it out configure the build as:\n```\ncmake -DBUILD_MATLAB=ON ..\n```\nIf that does not work, try the manual makefile above.\n\nIn either case, you will have to manually edit the location of mexmat and the Matlab path. The process will be fully automated in the future.\n\n\n## Examples\nA complete example is provided in `apps/vo.cc`\n\nA simple example in `apps/vo_example.cc`\n\nFor real-time timting looin in `apps/vo_perf.cc` On my machine a dual core i7 from 2011, `vo_perf.cc` runs at 100+ Hz\n\nA minimal example is as follows:\n```cpp\n#include <bpvo/vo.h>\n#include <bpvo/trajectory.h>  // if you want the trajectory\n#include <bpvo/point_cloud.h> // if you want the point cloud\n\nusing namespace bpvo;\n\nint main()\n{\n  //\n  // initialize VO using the calibration and AlgorithmParameters\n  //\n  Matrix33 K; // your calibration (Eigen typedef)\n  float b;    // the stereo baseline\n  ImageSize image_size(rows, cols); // the image size\n\n  VisualOdometry vo(K, b, image_size, AlgorithmParameters());\n\n  //\n  // for every frame\n  //  image_ptr is a uint8_t* to the image data\n  //  disparity_ptr is a float* to the disparity map\n  //\n  // Both, the image and disparity size must be the same as supplied to\n  // VisualOdometry constructor\n  //\n  Result result = vo.addFrame(image_ptr, disparity_ptr);\n\n  //\n  // If you want the point cloud, you must check if it is available\n  //\n  if(result.pointCloud) {\n    // do something with the point cloud\n  }\n\n  // you can also get the trajectory of the camera at any point by calling\n  auto trajectory = vo.trajectory();\n\n  // DONE, there is nothing special to do delete the object\n  return EXIT_SUCCESS;\n}\n```\n\n### Matlab Example\n```matlab\nparams = VoMex.DefaultParameters;\nvo = VoMex(K, baseline, image_size, params);\n\nT = eye(4); % the accumulated camera poses\n% get images and disparities\n% the image must be uint8_t and disparity float\n% this assertion must hold\n% assert( isa(I, 'uint8') && isa(D, 'single') );\nresult = vo.addFrame(I, D);\n\n% accumulate the pose\nT(:,:,end+1) = T(:,:,end) * inv( result.pose );\n```\n\nSee also the code in side `matlab/`\n\n## AlgorithmParameters\nThe parameters for the algorithm are documented in `bpvo/types.h`. It is important to get the parameters right for the type of data. Below are additional comments\n\n### Common parameters\n* `numPyramidLevels` You want this to be as small as possible to handle large motions. If you set it to -1, the code will automatically decide the number of pyramid levels. Sometimes, the lowest resolution image is too small and things might not work. For 640x480 images a value of 4 seems to works ok.\n\n* `lossFunction` this is the type of the robust loss function used in the IRLS optimization. Use `kTukey`, or `kHuber`. You can also run without weighting with `kL2`, which is much faster but fails too often too often.\n\n* `goodPointThreshold` Weights assigned to every point are between 0 and 1. Set this value to determine which points should be considered *good*. This will affect the number of 3D points you get in the point cloud. If the data is relatively clean, set this value to something high (e.g. 0.85), but if the data is fairly difficult without much stereo, set it to something lower (e.g. 0.6).\n\n* `minNumPixelsForNonMaximaSuppression` to achieve real-time VO, when the number of pixels in the image exceeds minNumPixelsForNonMaximaSuppression we do non-maxima suppression on a saliency map extracted from the descriptor image. This results in semi-dense maps at the highest resolution. If you do not want this, and instead want as many 3D points at possible, set `minNumPixelsForNonMaximaSuppression to` a value higher than the number of pixels of your image. You can also disable this option be setting `nonMaxSuppRadius` to negative value.\n\n* `minSaliency` minimum saliency to use a pixel. If you want to use all pixels irrespective of their saliency, set this to a negative value.\n\n\n### For Intensity descriptor\nIf you want to use intensity only, disable parallisim. Compile the code with\n```\ncmake .. -DWITH_TBB=OFF -DWITH_SIMD=OFF\n```\n\nOr in your code\n```\nbpvo::setNumThreads(1);\n```\n\nThe overhead of threads with intensity is not worth it for medium resolution images.\n\n### Keyframing\n\n* `minTranslationMagToKeyFrame`\n* `minRotationMagToKeyFrame`\n* `maxFractionOfGoodPointsToKeyFrame`\n\nIf you want to disable keyframing in order to get pose and point clouds for every image you add, set `minTranslationMagToKeyFrame=0.0`\n\n### parameters specific to illumination robust mode\n\n* `sigmaPriorToCensusTransform` this is the standard deviation of a Gaussian to blur the image before computing Bit-Planes. This should have a value less than 1.5, otherwise too much information is lost. A value of 0.5-0.75 is good.\n\n* `sigmaBitPlanes` a standard deviation of Gaussian to smooth the Bit-Planes descriptor. You should experiment with this as it affects the basin of convergence. It also depends on how much motion there is in the data. A value of 0.75-1.5 is good.\n\n\n## 3D point clouds\nPoint clouds are generated from the current keyframe. You should check if result.pointCloud is not NULL prior to accessing it. The point cloud comes with its pose as well in the world coordinate system.\n\n## Citation\nIf you find this work useful please cite either\n```\n@ARTICLE{2016arXiv160400990A,\n   author = {{Alismail}, Hatem and {Browning}, Browning and {Lucey}, Simon},\n    title = \"{Direct Visual Odometry using Bit-Planes}\",\n  journal = {ArXiv e-prints arXiv:1064.00990},\n  year = {2016}\n}\n```\nor\n```\n@article{alismail2016bit,\n  title={Bit-Planes: Dense Subpixel Alignment of Binary Descriptors},\n  author={{Alismail}, Hatem and {Browning}, Brett and {Lucey}, Simon},\n  journal={arXiv preprint arXiv:1602.00307},\n  year={2016}\n}\n```\n\nKeep an eye on [http://www.cs.cmu.edu/~halismai/] for additional data\n\n[bp]: http://arxiv.org/abs/1602.00307\n[bpvo]: http://arxiv.org/abs/1604.00990\n[eigen]: http://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2\n[opencv]: https://github.com/Itseez/opencv/archive/2.4.11.zip\n\n", 
  "id": 55660051
}