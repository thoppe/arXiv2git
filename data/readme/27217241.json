{
  "read_at": 1462553792, 
  "description": "Latent Dirichlet allocation (LDA) with bumping variational inference.", 
  "README.md": "lda-bump-cpp\n============\n\nLatent Dirichlet allocation (LDA) with bumping variational inference.\n\n[![](http://img.shields.io/badge/license-GPLv2-red.svg?style=flat)](https://github.com/akucukelbir/lda-bump-cpp/blob/master/LICENSE)\n\nImplements three versions of LDA\n* Coordinate ascent (mean-field)\n* Stochastic variational inference (https://github.com/Blei-Lab/onlineldavb)\n* Bumping variational inference [1]\n\n[1] Alp Kucukelbir and David M Blei. _Population Empirical Bayes._\nUncertainty in Artificial Intelligence (UAI) 2015.\n\n\nRequirements\n------------\n\n`lda-bump-cpp` is written in C++11. It requires a modern compiler. It also\ndepends on Eigen 3, Boost, and CMake. It uses docopt (provided).\n\n* Eigen 3: http://eigen.tuxfamily.org/\n* Boost: http://www.boost.org/\n* CMake: http://www.cmake.org/\n\nRefer to platform-specific instructions for installation.\n(I recommend homebrew on Mac OS X.)\n\n\nInstructions to Build and Run\n-----------------------------\n\nThe driver (main) program runs all three algorithms.\n\n```\ncmake .\nmake driver\n```\n\nA toy dataset of arXiv abstracts is provided.\n\nExample\n```\n./driver --topics=5\n         --vocabulary=data/arxiv-vocab.dat\n         --datatr=data/arxiv-train-5k.dat\n         --datatest=data/arxiv-test-1k.dat\n```\n\nFor more help, run\n```\n./driver -h\n\nlda-bump-cpp LDA with bumping variational inference.\n\nUsage:\n  driver --topics=NUM_TOPICS --vocabulary=VOCAB\n         --datatr=TRAIN --datatest=TEST\n         [--bootstrap=NUM_BOOTSTRAP] [--minibatch=MINIBATCH]\n         [--alpha=ALPHA] [--eta=ETA]\n         [--tau0=TAU0] [--kappa=KAPPA]\n         [--fixed_step_size=STEPSIZE]\n         [--max_itr=MAX_ITR]\n         [--compute_elbo]\n  driver (-h | --help)\n  driver --version\n\nOptions:\n  --topics=NUM_TOPICS        Number of topics for LDA\n  --vocabulary=VOCAB         Vocabulary, one word per line\n  --datatr=TRAIN             Training data in LDA-C format\n  --datatest=TEST            Testing  data in LDA-C format\n  --bootstrap=NUM_BOOTSTRAP  Number of bootstraps for bumping [default: 10]\n  --minibatch=MINIBATCH      Number of docs in minibatch [default: 500]\n  --alpha=ALPHA              Hyperparameter on topic proportions [default: 1/K]\n  --eta=ETA                  Hyperparameter on topics [default: 100/V]\n  --tau0=TAU0                Learning rate delay [default: 10.0]\n  --kappa=KAPPA              Learning rate forgetting rate [default: 0.75]\n  --fixed_step_size=STEPSIZE Fixed stepsize instead RobMonro [default: 0.0]\n  --max_itr=MAX_ITR          Max number of iterations for LDA [default: 100]\n  --compute_elbo             Boolean flag for computing ELBO\n  -h --help                  Show this screen\n  --version                  Show version\n\n```\n\n\nVocabulary Data Format\n----------------------\n\nA text file with each word (`[term_1]` through `[term_N]`) on a separate line.\n\n\nCorpus Data Format\n------------------\n\nA text file where each line is of the form (the LDA-C format):\n\n`[M] [term_1]:[count] [term_2]:[count] ...  [term_N]:[count]`\n\nwhere `[M]` is the number of unique terms in the document, and the\n`[count]` associated with each term is how many times that term appeared\nin the document.\n\n\nVisualizing the Output\n----------------------\n\nA python script visualizes the topics.\n(Modified from https://github.com/Blei-Lab/onlineldavb)\n\n```\n./printtopics.py data/arxiv-vocab.dat\n                 results/Thu_Nov_27_10-45-09_2014/lambda_coord_ascent.dat\n\n./printtopics.py data/arxiv-vocab.dat\n                 results/Thu_Nov_27_10-45-09_2014/lambda_svi.dat\n\n./printtopics.py data/arxiv-vocab.dat\n                 results/Thu_Nov_27_10-45-09_2014/lambda_bumping.dat\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", 
  "id": 27217241
}