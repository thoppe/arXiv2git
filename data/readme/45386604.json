{
  "read_at": 1462554471, 
  "description": "Caffe modification for the python-based Tiramisu ", 
  "README.md": "# Caffe4Tiramisu\n\nThis projects extends Caffe for the Tiramisu project.\nMostly it modifies the feature extraction code for easier interaction, changing the output to an image vector file.\n\n## GoogLeNet models\n\nThe GoogLeNet models needed to run feature extraction are added in this repository. This is done for the sake of simplicity, even though its not recommended due to their size (50MB). Instructions on how to get them can be found on the original caffe site.\n\n## Before running\n\nAfter download, two parameters need to be modified in the prototxt file (e.g., ~/gits/caffe4Tiramisu/models/bvlc_googlenet/feat_extract.prototxt):\n- the location of the mean_file shold be set to your local imagenet_mean.binaryproto (e.g., /your/local/path/caffe4Tiramisu/data/ilsvrc12)\n- the file_list.txt, by default set to /tmp/file_list.txt. This two column file of the form \"image_path.jpg 0\" defines the image (SINGULAR) to process. Its a required temporal file.\n\n## Calling feature extraction (example)\n/your/local/path/caffe4Tiramisu/build/tools/extract_featuresTiramisu /your/local/path/caffe4Tiramisu/models/bvlc_googlenet/bvlc_googlenet.caffemodel /your/local/path/caffe4Tiramisu/models/bvlc_googlenet/feat_extract.prototxt inception_4e/output /tmp/tst outFileName outputType \n\n- the target directory (/tmp/tst in the example) must exist!\n- the layers to extract (inception_4e/output) can be multiple, separated by commas\n- only one image is process per call\n- output is stored in /tmp/tst/outFileName\n- output type is either 1 (char file) or 2 (binary file)\n\n# Caffe\n\n[![Build Status](https://travis-ci.org/BVLC/caffe.svg?branch=master)](https://travis-ci.org/BVLC/caffe)\n[![License](https://img.shields.io/badge/license-BSD-blue.svg)](LICENSE)\n\nCaffe is a deep learning framework made with expression, speed, and modularity in mind.\nIt is developed by the Berkeley Vision and Learning Center ([BVLC](http://bvlc.eecs.berkeley.edu)) and community contributors.\n\nCheck out the [project site](http://caffe.berkeleyvision.org) for all the details like\n\n- [DIY Deep Learning for Vision with Caffe](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.p)\n- [Tutorial Documentation](http://caffe.berkeleyvision.org/tutorial/)\n- [BVLC reference models](http://caffe.berkeleyvision.org/model_zoo.html) and the [community model zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)\n- [Installation instructions](http://caffe.berkeleyvision.org/installation.html)\n\nand step-by-step examples.\n\n[![Join the chat at https://gitter.im/BVLC/caffe](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/BVLC/caffe?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nPlease join the [caffe-users group](https://groups.google.com/forum/#!forum/caffe-users) or [gitter chat](https://gitter.im/BVLC/caffe) to ask questions and talk about methods and models.\nFramework development discussions and thorough bug reports are collected on [Issues](https://github.com/BVLC/caffe/issues).\n\nHappy brewing!\n\n## License and Citation\n\nCaffe is released under the [BSD 2-Clause license](https://github.com/BVLC/caffe/blob/master/LICENSE).\nThe BVLC reference models are released for unrestricted use.\n\nPlease cite Caffe in your publications if it helps your research:\n\n    @article{jia2014caffe,\n      Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n      Journal = {arXiv preprint arXiv:1408.5093},\n      Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n      Year = {2014}\n    }\n", 
  "id": 45386604
}