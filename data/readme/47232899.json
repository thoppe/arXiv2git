{
  "read_at": 1462549922, 
  "description": "A torch implementation of http://arxiv.org/abs/1511.06434", 
  "README.md": "DCGAN.torch: Train your own image generator\n===========================================================\n\n1. [Train your own network](#1-train-your-own-network)\n   1. [Train a face generator using the Celeb-A dataset](#11-train-a-face-generator-using-the-celeb-a-dataset)\n   2. [Train Bedrooms, Bridges, Churches etc. using the LSUN dataset](#12-train-bedrooms-bridges-churches-etc-using-the-lsun-dataset)\n   3. [Train a generator on your own set of images.](#13-train-a-generator-on-your-own-set-of-images)\n   4. [Train on the ImageNet dataset](#14-train-on-the-imagenet-dataset)\n2. [Use a pre-trained generator to generate images.](#pre-trained-network-can-be-downloaded-from-here)\n   1. [Generate samples of 64x64 pixels](#21-generate-samples-of-64x64-pixels)\n   2. [Generate large artsy images (tried up to 4096 x 4096 pixels)](#22-generate-large-artsy-images-tried-up-to-4096-x-4096-pixels)\n   3. [Walk in the space of samples](#23-walk-in-the-space-of-samples)\n3. [Vector Arithmetic of images in latent space](#vector-arithmetic)\n\n# Prerequisites\n- Computer with Linux or OSX\n- Torch-7\n- For training, an NVIDIA GPU is strongly recommended for speed. CPU is supported but training is very slow.\n\n# Installing dependencies\n## Without GPU\n- Install Torch:  http://torch.ch/docs/getting-started.html#_\n\n## With NVIDIA GPU\n- Install CUDA, and preferably CuDNN (optional).\n  - Instructions for Ubuntu are here: [INSTALL.md](INSTALL.md)\n- Install Torch:  http://torch.ch/docs/getting-started.html#_\n- Optional, if you installed CuDNN, install cudnn bindings with `luarocks install cudnn`\n\n## Display UI\nOptionally, for displaying images during training and generation, we will use the [display package](https://github.com/szym/display).\n\n- Install it with: `luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec`\n- Then start the server with: `th -ldisplay.start`\n- Open this URL in your browser: [http://localhost:8000](http://localhost:8000)\n\nYou can see training progress in your browser window. It will look something like this:\n![display](images/display_example.png \"Example of display\")\n\n\n# 1. Train your own network\n\n## 1.1 Train a face generator using the Celeb-A dataset\n### Preprocessing\n\n```bash\nmkdir celebA; cd celebA\n```\n\nDownload img_align_celeba.zip from [http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) under the link \"Align&Cropped Images\".\n\n```bash\nunzip img_align_celeba.zip; cd ..\nDATA_ROOT=celebA th data/crop_celebA.lua\n```\n\n### Training\n\n```bash\nDATA_ROOT=celebA dataset=folder th main.lua\n```\n\n## 1.2. Train Bedrooms, Bridges, Churches etc. using the LSUN dataset\n\nLSUN dataset is shipped as an LMDB database. First, install LMDB on your system.\n\n- On OSX with Homebrew:  `brew install lmdb`\n- On Ubuntu: `sudo apt-get install liblmdb-dev`\n\nThen install a couple of Torch packages.\n\n```bash\nluarocks install lmdb.torch\nluarocks install tds\n```\n\n### Preprocessing (with bedroom class as an example)\nDownload `bedroom_train_lmdb` from the [LSUN website](http://lsun.cs.princeton.edu).\n\nGenerate an index file:\n```bash\nDATA_ROOT=[path_to_lmdb] th data/lsun_index_generator.lua\n```\n\n### Training\n```bash\nDATA_ROOT=[path-to-lmdb] dataset=lsun th main.lua\n```\n\nThe code for the LSUN data loader is hardcoded for bedrooms. Change [this line](https://github.com/soumith/dcgan.torch/blob/master/data/donkey_lsun.lua#L21) to another LSUN class to generate other classes.\n\n## 1.3. Train a generator on your own set of images.\n### Preprocessing\n- Create a folder called `myimages`.\n- Inside that folder, create a folder called `images` and place all your images inside it.\n\n### Training\n```bash\nDATA_ROOT=myimages dataset=folder th main.lua\n```\n\n## 1.4. Train on the ImageNet dataset\n\n### Preprocessing\n[Follow instructions from this link.](https://github.com/soumith/imagenet-multiGPU.torch#data-processing)\n\n### Training\n```bash\nDATA_ROOT=[PATH_TO_IMAGENET]/train dataset=folder th main.lua\n```\n\n## All training options:\n\n```lua\n   dataset = 'lsun',       -- imagenet / lsun / folder\n   batchSize = 64,\n   loadSize = 96,\n   fineSize = 64,\n   nz = 100,               -- #  of dim for Z\n   ngf = 64,               -- #  of gen filters in first conv layer\n   ndf = 64,               -- #  of discrim filters in first conv layer\n   nThreads = 1,           -- #  of data loading threads to use\n   niter = 25,             -- #  of iter at starting learning rate\n   lr = 0.0002,            -- initial learning rate for adam\n   beta1 = 0.5,            -- momentum term of adam\n   ntrain = math.huge,     -- #  of examples per epoch. math.huge for full dataset\n   display = 1,            -- display samples while training. 0 = false\n   display_id = 10,        -- display window id.\n   gpu = 1,                -- gpu = 0 is CPU mode. gpu=X is GPU mode on GPU X\n   name = 'experiment1',\n   noise = 'normal',       -- uniform / normal\n```\n\n# 2. Use a pre-trained generator to generate images.\nThe generate script can operate in CPU or GPU mode.\n\nto run it on the CPU, use:\n```bash\ngpu=0 net=[checkpoint-path] th generate.lua\n```\n\nfor using a GPU, use:\n```bash\ngpu=1 net=[checkpoint-path] th generate.lua\n```\n\n# Pre-trained network can be downloaded from here:\n- for faces (celeb-A dataset): [celebA_25_net_G.t7](https://github.com/soumith/lfs/raw/master/dcgan.torch/celebA_25_net_G.t7)\n- for bedrooms (LSUN dataset): [bedrooms_4_net_G.t7](https://github.com/soumith/lfs/raw/master/dcgan.torch/bedrooms_4_net_G.t7)\n\n##2.1. Generate samples of 64x64 pixels\n```bash\ngpu=0 batchSize=64 net=celebA_25_net_G.t7 th generate.lua\n```\n\nThe batchSize parameter controls the number of images to generate. If you have `display` running,\nthe image will be shown there. The image is also saved to `generation1.png` in the same folder.\n\n![faces_pregen](images/faces_pregen.png \"generated faces using pre-trained network\")\n\n\n##2.2. Generate large artsy images (tried up to 4096 x 4096 pixels)\n```bash\ngpu=0 batchSize=1 imsize=10 noisemode=linefull net=bedrooms_4_net_G.t7 th generate.lua\n```\n\nControlling the `imsize` parameter will control the size of the output image.\nLarger the imsize, larger the output image.\n\n![line2d_pregen](images/line2d_pregen.png \"generated line2d using pre-trained network\")\n\n##2.3. Walk in the space of samples\n```bash\ngpu=0 batchSize=16 noisemode=line net=bedrooms_4_net_G.t7 th generate.lua\n```\n\ncontrolling the batchSize parameter changes how big of a step you take.\n\n![interp_pregen](images/interp_pregen.png \"generated interp using pre-trained network\")\n\n# Vector Arithmetic\n```bash\nnet=[modelfile] gpu=0 qlua arithmetic.lua\n```\n![vector_arithmetic](images/arithmetic.png \"generated vector arithmetic\")\n", 
  "id": 47232899
}