{
  "read_at": 1462547791, 
  "description": "Summaries  and notes of recent nlp field research paper or tutoria", 
  "README.md": "## nlp-papernotes\n\n##### Inspired by [Denny Britz](https://github.com/dennybritz)'s deep learning paper-lists, I record some interesting nlp field papers that I have read and archive my reading notes in this repo. The papers mainly come from top-tier conferences, e.g. **ACL**, **EMNLP**, **NAACL**, and I may follow latest **arXiv** pre-published papers. Hope you benefit from it, happy language processing ! Happy embedding !\n\n\n#### 2016-05 \n\n- [ ] Neural Language Correction with Character-Based Attention \n[[arXiv](http://arxiv.org/pdf/1603.09727v1.pdf)]\n- [ ] Neural Architectures for Named Entity Recognition (*2016 NAACL* [[arXiv](http://arxiv.org/pdf/1603.01360v3.pdf)])\n- [ ] Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (*2016 ICML*) [[arXiv](http://arxiv.org/pdf/1506.07285v5.pdf)]\n- [ ] Supervised and Semi-Supervised Text Categorization using One-Hot LSTM for Region Embeddings (*2016 ICML*) [[arXiv](http://arxiv.org/pdf/1602.02373v1.pdf)]\n\n \n\n\n\n\n#### 2016-04\n\n - [ ] Improving sentence compression by learning to predict gaze (*2016 NAACL Best Short Paper*) [[arXiv](http://arxiv.org/pdf/1604.03357.pdf)]\n - [ ] Abstractive Sentence Summarization with Attentive Recurrent Neural Networks (*2016 NAACL*) [[paper](http://harvardnlp.github.io/papers/naacl16_summary.pdf)]\n - [ ] Neural Headline Generation with Minimum Risk Training (*2016 IJCAI*)[[arXiv](http://arxiv.org/pdf/1604.01904.pdf)]\n - [ ] Sentence Level Recurrent Topic Model: Letting Topics Speak for Themselves  [[arXiv](http://arxiv.org/pdf/1604.02038.pdf)]\n", 
  "id": 56236673
}