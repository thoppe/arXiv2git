{
  "read_at": 1462552134, 
  "description": null, 
  "README.md": "This package contains the accompanying code for the following two papers:\n\n* \\[1\\] Yoshua Bengio, Eric Thibodeau-Laufer, Jason\n  Yosinski. [Deep Generative Stochastic Networks Trainable by Backprop](http://arxiv.org/abs/1306.1091). _arXiv\n  preprint arXiv:1306.1091._ ([PDF](http://arxiv.org/pdf/1306.1091v3),\n  [BibTeX](https://raw.github.com/yaoli/GSN/master/doc/gsn.bib))\n\n* \\[2\\] Yoshua Bengio, Li Yao, Guillaume Alain, Pascal\n  Vincent. [Generalized Denoising Auto-Encoders as Generative Models](http://papers.nips.cc/paper/5023-generalized-denoising-auto-encoders-as-generative-models). _NIPS,\n  2013._ ([PDF](http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips26/491.pdf),\n  [BibTeX](https://raw.github.com/yaoli/GSN/master/doc/dae.bib))\n\n\n\nSetup\n---------------------\n\n#### Install Theano\n\nDownload Theano and make sure it's working properly.  All the\ninformation you need can be found by following this link:\nhttp://deeplearning.net/software/theano/\n\n#### Prepare the MNIST dataset\n\n1. Download the MNIST dataset from http://deeplearning.net/data/mnist/mnist.pkl.gz\n\n2. Unzip the file to generate mnist.pkl using `gunzip mnist.pkl.gz`\n\n3. (Optional) To visualize MNIST, run `python image_tiler.py`\n\n\n\nReproducing the Results\n---------------------\n\nThe below commands are given in two formats: the first will run on the\nGPU and the second on the CPU. Choose whichever is most appropriate\nfor your setup.  Of course, the GPU versions will only work if Theano\nis being used on a machine with a compatible GPU (more about\n[using the GPU in Theano](http://deeplearning.net/software/theano/tutorial/using_gpu.html)).\n\n1. To run a two layer Generative Stochastic Network (paper \\[1\\])\n\n        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python run_gsn.py\n        THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python run_gsn.py\n\n2. To run a one layer Generalized Denoising Autoencoder with a walkback procedure (paper \\[2\\])\n\n        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python run_dae_walkback.py\n        THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python run_dae_walkback.py\n\n3. To run a one layer Generalized Denoising Autoencoder without a walkback procedure (paper \\[2\\])\n\n        THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python run_dae_no_walkback.py\n        THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python run_dae_no_walkback.py\n\n4. Getting the log-likelihood estimation and inpainting (as described in paper \\[1\\])\n\n    To test a model, by generating inpainting pictures, and 10000\n    samples used by the parzen density estimator, run this command in\n    this directory, with the `params_epoch_X.pkl` and `config` file\n    that was generated when training the model. If multiple\n    `params_epoch_X.pkl` files are present, the one with the largest\n    epoch number is used.\n\n        THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python run_gsn.py --test_model 1\n\n\n\n#### Important notes on running the code\n\n* (1), (2) and (3) will generate images for both the denoising and\n  pseudo-Gibbs sampling, and save parameters every 5 epochs. We have\n  provided some examples of the reconstruction and generated samples\n  (consecutive Gibbs samples) under the directory 'images/' for 3\n  types of models. By just looking at the pictures there, it is clear\n  that 2-layer model beats the 1-layer model with walkback training,\n  which then beats the 1-layer model without walkback training.\n\n* The code is written such that it produces better results on the\n  estimated log-likelihood by Parzen density estimator than in our\n  paper \\[2\\]. For example, (2) produces a log-likelihood of around\n  150 and (3) produces 50. Both number could be higher if the model is\n  trained longer. Trust this number with precaution, as the estimation\n  from the Parzen density estimator is biased and tends to prefer\n  rigid samples. You will notice this number is high even when the\n  generated images do not look good. Trust the visualizations more.\n\n* The codes outputs a lot of information on the screen. This is meant\n  to show the progression. Also you can safely ignore the warning\n  message from Theano. The training starts when the following is\n  printed out:\n\n        1    Train :  0.607192    Valid :  0.367054    Test  :  0.364999    time :  20.40169 MeanVisB :  -0.22522 W :  ['0.024063', '0.022423']\n        2    Train :  0.302400    Valid :  0.277827    Test  :  0.277751    time :  20.33490 MeanVisB :  -0.32510 W :  ['0.023877', '0.022512']\n        3    Train :  0.292427    Valid :  0.267693    Test  :  0.268585    time :  20.45896 MeanVisB :  -0.38779 W :  ['0.023882', '0.022544']\n        4    Train :  0.268086    Valid :  0.267201    Test  :  0.268247    time :  20.37603 MeanVisB :  -0.43271 W :  ['0.023856', '0.022535']\n        5    Train :  0.266533    Valid :  0.264087    Test  :  0.265572    time :  20.26944 MeanVisB :  -0.47086 W :  ['0.023840', '0.022517']\n\n  For each training epoch, the first 3 numbers are the cost on the\n  training, validation, and test sets, followed by the training time\n  (in seconds, on GPU Nvidia GeForce GTX580, 300 seconds in Intel(R)\n  Core(TM) i7-2600K CPU @ 3.40GHz), then the mean of the visible bias,\n  and mean of the magnitude of weights.\n\n\n#### Contact\n\nQuestions? Contact us: li.yao@umontreal.ca\n", 
  "id": 31269282
}