{
  "id": 39209911, 
  "read_at": 1462546074, 
  "readme.txt": "------------------------------------\n    Requirement\n------------------------------------\nThis software is based on the following packages/softwares. Please install them before running the code.\n\n* Python 2.7+\n* Numpy\n* Scipy\n* Chainer: https://github.com/pfnet/chainer\n* RL-glue core: https://sites.google.com/a/rl-community.org/rl-glue/Home/rl-glue\n* RL-glue Python codec: https://sites.google.com/a/rl-community.org/rl-glue/Home/Extensions/python-codec\n* Arcade Learning Environment (version ALE 0.4.4): http://www.arcadelearningenvironment.org/\n* NVIDIA GPU (This code was tested on Geforce GTX 660 with Ubuntu 14.04 LTS)\n\nAlso you may need the binary rom of the ATARI games.\nI reccomend you to run examples in RL-glue python codec and ALE before testing DQN.\n\n------------------------------------\n    How to run\n------------------------------------\nTo run a DQN, we just follow the standard RL-glue experiment. \nConcretely, we will need to start the following processes.\n\n* rl_glue\n* RLGlueAgent (dqn_agent_*.py)\n* RLGlueExperiment (experiment_ale.py)\n* ale (ALE 0.4.4)\n(So, you may need four terminal windows!)\n\nThe actual process will be:\n(first window: rlglue)\nrl_glue\n(second window: RLGlueAgent)\npython dqn_agent_nature.py\n(third window: RLGlueExperiment)\npython experiment_ale.py\n(fourth window: ALE)\n./ale -game_controller rlglue -use_starting_actions true -random_seed time -display_screen true -frame_skip 4 path_to_roms/pong.bin \n\nIn the above example, we are assuming that the binary file of the roms (\"Pong\" in this case)\nare in path_to_roms directory. \n\n------------------------------------\n    Playing other games\n------------------------------------\nThe default setting of the code is for playing \"Pong\". \nTo run with other games, you need to modify a line in \"agent_start\" function in \"dqn_agent\" class.\n\nTo make DQN play \"Breakout\", we may set as\n\n(before modification) self.DQN = DQN_class()\n( after modification) self.DQN = DQN_class(enable_controller=[0, 1, 3, 4])\n\n\"enable_controller\" is the list of available actions of the agents. \nThe minimum set of the actions required for each game rom are described\nin ale_0_4/src/games/supported/name_of_game.cpp,\n\nand you can check the corrensponding integer numbers in the section 8.1 of the technical manual of ALE:\n\nTechnical Manual (you have same manual in your ale directory!): https://github.com/mgbellemare/Arcade-Learning-Environment/tree/master/doc/manual\n\n------------------------------------\nModification of hyper-parameters\n------------------------------------\n\nIf your machine does not have enough memory to run the full-version DQN, \ntry setting \"data_size\" variable much smaller value like 2*10**4.\nThis setting may reduce the final performance, but still works well at least in \"Pong\" domain.\n\n------------------------------------\nCopyright (c) 2015 Naoto Yoshida All Right Reserved.\n", 
  "README.md": "# DQN-chainer\n\nThis software is a python implementation of Deep Q-Networks for playing ATARI games with Chainer package.\n\nI followed the implementation described in:\n* V. Mnih *et al*., \"Playing atari with deep reinforcement learning\"\n\nhttp://arxiv.org/pdf/1312.5602.pdf\n* V. Mnih *et al.*, \"Human-level control through deep reinforcement learning\"\n\nhttp://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html\n\nFor japanese instruction of DQN and historical review, please check:\n\nhttp://qiita.com/Ugo-Nama/items/08c6a5f6a571335972d5\n\n# Requirement\nMy implementation is dependent on RL-glue, Arcade Learning Environment, and Chainer. To run the software, you need following softwares/packages.\n\n* Python 2.7+\n* Numpy\n* Scipy\n* Chainer (1.3.0): https://github.com/pfnet/chainer\n* RL-glue core: https://sites.google.com/a/rl-community.org/rl-glue/Home/rl-glue\n* RL-glue Python codec: https://sites.google.com/a/rl-community.org/rl-glue/Home/Extensions/python-codec\n* Arcade Learning Environment (version ALE 0.4.4): http://www.arcadelearningenvironment.org/\n\nThis software was tested on Ubuntu 14.04 LTS.\n\n# How to run\nPlease check readme.txt\n\n", 
  "description": ""
}