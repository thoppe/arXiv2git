{
  "read_at": 1462550389, 
  "description": "My Solution to the NLP Challenge", 
  "README.md": "# NLPChallenge\nMy Solution to the NLP Challenge\n\nDoc2Vec is an extension of Word2Vec. Word2Vec extracts vector representations of words in a corpus. \nThese vectors carry semantic information. Semantically similar words will have similar vectors. \nDoc2Vec extends Word2Vec to derive vector representations of paragraphs (or sentences), too. \nHenceforth we will use the term sentence to refer to any group of words that is treated as a single entity, regardless of its length. \n\nSentence vectors can be extracted using only Word2Vec, by applying simple mathematical operations to the vectors of their component words (e.g sum, average). \nThe additional functionality that Doc2Vec offers compared to Word2Vec is that it can infer sentence vectors of new unseen samples. \nThe training of the model, in this case, takes into account the grouping of the words into distinct sentences. \n\nThe given problem is separated in two independent tasks. \nThe first one is the extraction of vector representations of the training and test sentences. \nThe second task is a classification problem where, given a set of labelled training sentences, we want to make a classifier to predict the sentiment (positive or negative) of a new review. \nThe labels of the data are only used at the second task. \nFirst we separate the data into training and test sets. \nThe test set consists of 12.5K reviews from the positive and negative sets, totally 25K samples. \nThe training set consists of the remaining 25K labelled reviews and the 50K unlabelled ones. \nFor the classification problem both the training and test sets will consist of 25K samples.\n\nOne approach for the problem would be to ignore Doc2Vec and use only Word2Vec with all the100K samples. \nThis process would extract vectors for the words and the vectors of the sentences could be derived by them as mentioned earlier. \nMikolov has written an extension of Word2Vec and a script[1] to perform this task. \nOnce the sentence vectors have been acquired, the classifier can be trained with the labelled samples and evaluated at the test samples. \nHowever, in a real word scenario this approach would be inefficient because each time a new review arrives, the neural network must be trained again. \nThe same is also true for the classifier since the vectors of the training samples should be updated as well.  \n\nA better approach is to use Doc2Vec to train the network once and then use it to infer the sentence vector of a new unseen review. \nThe classifier would also be trained once with the vectors of the labelled samples. \nThis is the approach followed here. The program consists of 5 scripts. \nThe first script splits the given documents into training and test sets. \nThe second reads the training documents, trains the Word2Vec model and saves it. It also saves the vectors of the training sentences into a file. \nThe third script reads the latest and trains a classifier. \nThe fourth script loads the trained Doc2Vec model and applies it to the test sentences. It saves the generated sentence vectors in a file. \nFinally, the fifth script loads the test vector and the saved classifier and prints the accuracy. \n\nThe scripts were written in Windows environment under the Anaconda[2] python environment, with the gensim package installed. \nFor this reason the scripts are called by a window batch file. \nTwo classifiers were tested from the scikit-learn package, linear SVM and Logistic Regression. \nThe accuracy achieved is worse than the results shown in Table 2 of Mikolov's paper[3]. \nThis is because due to time limitations the learning algorithms were not tuned and the default settings were used in most cases. \nThe svm.LinearSVC() was used instead of svm.SVC() because it performs better in big datasets. \nLogistic Regression achieves a slightly better performance with the default settings.\n\nThe batch file is named NLPChallenge.bat and can be ran from a window command line if the scripts can find the paths of the Python libraries. \nThe input documents (review files) are assumed to be in the same folder which contains the scripts. \n\nWritting intermediate vectors in files is not necessary but the emphasis here was given in modularity.\n\nA visualization for this kind of task could be done by projecting the review vectors on a 2D plot using Multidimensional Scaling (MDS).  \n\n[1] https://groups.google.com/forum/#!msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ\n\n[2] http://docs.continuum.io/anaconda/index\n\n[3] http://arxiv.org/pdf/1405.4053v2.pdf\n", 
  "id": 47916779
}