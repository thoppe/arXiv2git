{
  "read_at": 1462547050, 
  "description": "tests for statistical significance of clustering", 
  "README.md": "\n\nsigclust2 [![Build Status](https://travis-ci.org/pkimes/sigclust2.svg?branch=master)](https://travis-ci.org/pkimes/sigclust2)\n=======================\n\n## Contents\n1. [Introduction](#intro)\n2. [Testing](#test)\n3. [Plotting](#plot)\n4. [Miscellanea](#misc)\n5. [References](#refs)\n\n\n## <a name=\"intro\"></a> Introduction\n\nThis package may be used to assess statistical significance in hierarchical clustering.\nTo assess significance in high-dimensional data, the approach assumes that a cluster\nmay be well approximated by a single Gaussian (normal) distribution. Given the results\nof hierarchical clustering, the approach sequentially tests from the root node whether\nthe data at each split/join correspond to one or more Gaussian distributions. The\nhypothesis test performed at each node is based on a Monte Carlo simulation procedure,\nand the family-wise error rate (FWER) is controlled across the dendrogram using a sequential\ntesting procedure.  \n\nAn illustration of the basic usage of the package's testing procedure is provided in the\n[Testing section](#test). Variations on the basic testing procedure are described in the\nassociated subsections. Basic plotting procedures are described in the [Plotting section](#plot).  \n\nTo install the package, simply obtain the `devtools` package from [CRAN][devtools] and type the\nfollowing in the `R` console:  \n```\nR> devtools::install_github(\"pkimes/sigclust2\")\n```\n\nThe package can then be loaded using the standard call to `library`.  \n\n\n```r\nsuppressPackageStartupMessages(library(\"sigclust2\"))\n```\n\nFor the following examples, we will use a simple toy example with 150 samples (_n_) with\n100 measurements (_p_). The data are simulated from three Gaussian (normal) distributions.  \n\n\n```r\nn1 <- 60; n2 <- 40; n3 <- 50; n <- n1 + n2 + n3\np <- 100\ndata <- matrix(rnorm(n*p), nrow=n, ncol=p)\ndata[, 1] <- data[, 1] + c(rep(2, n1), rep(-2, n2), rep(0, n3))\ndata[, 2] <- data[, 2] + c(rep(0, n1+n2), rep(sqrt(3)*3, n3))\n```\nThe separation of the three underlying distributions can be observed from a PCA (principal components\nanalysis) scatterplot. While the separation is clear in the first 2 PCs, recall that the data\nactually exists in 100 dimensions.  \n\n\n```r\ndata_pc <- prcomp(data)\npar(mfrow=c(1, 2))\nplot(data_pc$x[, 2], data_pc$x[, 1], xlab=\"PC2\", ylab=\"PC1\")\nplot(data_pc$x[, 3], data_pc$x[, 1], xlab=\"PC3\", ylab=\"PC1\")\n```\n\n![plot of chunk unnamed-chunk-4](figure/unnamed-chunk-4-1.png)\n\n\n## <a name=\"test\"></a> Testing\n\nThe SHC testing procedure is performed using the `shc` function. The function requires the following\nthree arguments:  \n\n* `x`: the data as a `matrix` with samples in rows,  \n* `metric`: the dissimilarity metric, and  \n* `linkage`: the linkage function to be used for hierarchical clustering.  \n\nFor reasons outlined in the corresponding paper [(Kimes et al. 2014)](#refs) relating to how\nthe method handles testing when n << p, we recommmend using `\"euclidean\"` as the metric,\nand any of `\"ward.D2\"`, `\"single\"`, `\"average\"`, `\"complete\"` as the linkage. If a custom\ndissimilarity metric is desired, either of `vecmet` or `matmet` should be specified, as\ndescribed [later](#newmetric) in this section.  \n\nIf metric functions which do not statisfy rotation invariance are desired,\ne.g. one minus Pearson correlation (`\"cor\"`) or L1 (`\"manhattan\"`),\n`null_alg = \"2means\"` and `ci = \"2CI\"` should be specified. The `null_alg` and `ci` parameters\nspecify the algorithm for clustering and measure of \"cluster strength\" used to generate the null\ndistribution for assessing significance. Since the K-means algorithm (`2means`) optimizes\nthe 2-means CI (`2CI`), the resulting p-value will be conservative. However, since the hierarchical\nalgorithm is not rotation invariant, using `null_alg = \"hclust\"` or `ci = \"linkage\"` produces\nunreliable results. An example for testing using Pearson correlation is given [later](#pearson) in\nthis section.  \n\nFor now, we just use the recommended and default parameters.  \n\n\n```r\nshc_result <- shc(data, metric=\"euclidean\", linkage=\"ward.D2\")\n```\n\nThe output is a S3 object of class `shc`, and a brief description of the analysis results can be\nobtained by the `summary` function.  \n\n\n```r\nsummary(shc_result)\n```\n\n```\n## \n## shc object created using shc(..)\n## --------------------------------\n## Clustering Parameters:\n##     dissimilarity = euclidean\n##     linkage = ward.D2\n## Testing Parameters:\n##     n_sim = 100\n##     icovest = 1\n##     ci = 2CI\n##     null_alg = hclust\n##     min_n = 10\n##     FWER control = FALSE\n```\n\nThe analysis output can be accessed using the `$` accessor. More details on the different entries\ncan be found in the documentation for the `shc` function.  \n\n\n```r\nnames(shc_result)\n```\n\n```\n##  [1] \"in_mat\"     \"in_args\"    \"eigval_dat\" \"eigval_sim\" \"backvar\"   \n##  [6] \"nd_type\"    \"ci_dat\"     \"ci_sim\"     \"p_emp\"      \"p_norm\"    \n## [11] \"idx_hc\"     \"hc_dat\"\n```\n\nThe computed p-values are probably of greatest interest. Two p-values are computed as part of the\nSHC testing procedure: (1) an empirical p-value (`p_emp`), and (2) a Gaussian approximate\np-value (`p_norm`). The p-values are computed based on comparing the observed strength of\nclustering in the data against the expected strength of clustering under the null hypothesis\nthat the data from a single cluster. The null distribution is approximated using a\nspecified number of simulated datasets (`n_sim = 100` default argument). `p_emp` is the empirical\np-value computed from the collection of simulated null datasets. `p_norm` is an approximation to\nthe empirical p-value which provides more continuous p-values. `nd_type` stores the results of the\ntest and takes values in: `n_small`, `no_test`, `sig`, `not_sig`, `NA`. With the default implementation of\n`shc` using no FWER control, all nodes are either `NA` or `n_small`.  \n\nThe p-values are reported for each of 149 (`n-1`) nodes along the hierarchical dendrogram.\nThe very top (root) node of the dendrogram corresponds to the final entry of the `p_emp` and\n`p_norm` results.  \n\n\n```r\ndata.frame(result = head(shc_result$nd_type, 5),\n           round(head(shc_result$p_norm, 5), 5),\n           round(head(shc_result$p_emp, 5), 5))\n```\n\n```\n##   result hclust_2CI hclust_2CI.1\n## 1     NA    0.00000         0.00\n## 2     NA    0.00284         0.01\n## 3     NA    0.55944         0.51\n## 4     NA    0.89707         0.92\n## 5     NA    0.99091         1.00\n```\n\nIn addition to values between 0 and 1, some p-values are reported as `2`. These values correspond\nto nodes which were not tested, either because of the implemented family-wise error rate (FWER)\ncontrolling procedure (`alpha`) or the minimum tree size for testing (`min_n`).  \n\nVariations on the standard testing procedure are possible by changing the default parameters of\nthe call to `shc(..)`.  \n\n\n### <a name=\"newmetric\"></a>Explicitly specifying a dissimilarity function\nThe method also supports specifying your own metric function through the `vecmet` and `matmet`\nparameters. Only one of `vecmet` and `matmet` should be specified. If either is specified, the\n`metric` parameter will be ignored. The `vecmet` parameter should be passed a function which takes\ntwo vectors as input and returns the dissimilarity between the two vectors. The `matmet` parameter\nshould be passed a function which takes a matrix as input and returns a `dist` object of\ndissimilarities of the matrix rows.  \n\nThe `vecmet` example is not actually run in this tutorial since it is __incredibliy__\ncomputationally expensive. Internally, the function passed to `vecmet` is wrapped in the\nfollowing call to `outer` to compute dissimilarities between all rows of a matrix.  \n\n\n```r\nas.dist(outer(split(x, row(x)), split(x, row(x)), Vectorize(vecmet)))\n```\n\nThe following simple benchmarking example with `cor` illustrates the overhead for\nusing `outer` to call on a vector function rather than using an optimized matrix\ndissimilarity function.\n\n\n```r\nvfun <- function(x, y) {1 - cor(x, y)}\nmfun1 <- function(x) {\n    as.dist(outer(split(x, row(x)), split(x, row(x)),\n                  Vectorize(vfun)))\n}\nmfun2 <- function(x) { as.dist(1 - cor(t(x))) }\n\nsystem.time(mfun1(data))\n```\n\n```\n##    user  system elapsed \n##   0.861   0.003   0.865\n```\n\n```r\nsystem.time(mfun2(data))\n```\n\n```\n##    user  system elapsed \n##   0.002   0.000   0.002\n```\n\nThe first matrix correlation function, `mfun1`, is written it\nwould be processed if `vfun` were passed to `shc` as `vecmet`. The second funtion,\n`mfun2`, is a function that could be passed to `matmet`. The performance difference is\nclearly significant.  \n\nWhen specifying a custom dissimilarity function for `shc`, it is important to\nremember that the function must be used to compute dissimilarity matrices `n_sim` times\nfor __each node__. In our toy example where `n_sim = 100` and `n = 150`, this means\ncalling on the dissimilarity function >10,000 times.  \n\nOur custom function, `mfun2` can be passed to `shc` through the `matmet` parameter.  \n\n\n```r\nshc_mfun2 <- shc(data, matmet=mfun2, linkage=\"average\")\n\ndata.frame(result = head(shc_mfun2$nd_type),\n           round(head(shc_mfun2$p_norm), 5),\n           round(head(shc_mfun2$p_emp), 5))\n```\n\n```\n##   result hclust_2CI hclust_2CI.1\n## 1     NA    0.86228         0.87\n## 2     NA    0.01003         0.01\n## 3     NA    0.88387         0.90\n## 4     NA    0.89094         0.89\n## 5     NA    0.84273         0.85\n## 6     NA    0.10524         0.08\n```\n\nSince the toy dataset is simulated with all differentiating signal lying in the\nfirst two dimensions, Pearson correlation-based clustering does a poor job at\ndistinguishing the clusters, and the resulting p-values show weak significance.  \n\n\n\n### <a name=\"pearson\"></a> Using Pearson correlation\nAs a shortcut, without having to specify `matmet`, if testing using `(1 - cor(x))` is desired,\nthe following specification can be used.  \n\n\n```r\ndata_pearson <- shc(data, metric=\"cor\", linkage=\"average\", null_alg=\"2means\")\n```\n\nThe result will be equivalent to apply the original `sigclust` hypothesis test described\nin [Liu et al. 2008](#refs) at each node along the dendrogram.  \n\n\n\n### <a name=\"fwerstopping\"></a> Testing with FWER stopping\nBy default, p-values are calculated at all nodes along the dendrogram with at least `n_min`\nobservations (default `n_min = 10`). The package includes a FWER controlling procedure which\nproceeds sequentially from the top node such that daughter nodes are only tested if \nFWER-corrected significance was achieved at the parent node. To reduce the total number of tests\nperformed, set `alpha` to some value less than `1`.   \n\n\n```r\nshc_fwer <- shc(data, metric=\"euclidean\", linkage=\"ward.D2\", alpha=0.05)\n```\n\nThe FWER is noted in the summary of the resulting `shc` object, and can be seen in the `nd_type`\nattribute, where most tests are now labeled `no_test` (with `p_norm` and `p_emp` values of 2).  \n\n\n```r\ndata.frame(result = head(shc_fwer$nd_type, 10),\n           round(head(shc_fwer$p_norm, 10), 5),\n           round(head(shc_fwer$p_emp, 10), 5))\n```\n\n```\n##     result hclust_2CI hclust_2CI.1\n## 1      sig    0.00000         0.00\n## 2      sig    0.00280         0.01\n## 3  not_sig    0.54243         0.49\n## 4  not_sig    0.83585         0.85\n## 5  not_sig    0.99490         1.00\n## 6  no_test    2.00000         2.00\n## 7  no_test    2.00000         2.00\n## 8  no_test    2.00000         2.00\n## 9  no_test    2.00000         2.00\n## 10 no_test    2.00000         2.00\n```\n\nBy default, `p_norm` p-values are used to test for significance against the FWER cutoffs,\nbut `p_emp` can be used by specifying `p_emp = TRUE`.  \n\n\n### <a name=\"pearson\"></a> Performing tests with multiple indices\nThe `shc` function allows for testing along the same dendrogram simultaneously using\ndifferent measures of strength of clustering.  \n\nFor example, it is possible to simultaneously test the above example using both the 2-means\ncluster index and the linkage value as the measure of strength of clustering.  \n\n\n```r\ndata_2tests <- shc(data, metric=\"euclidean\", linkage=\"ward.D2\",\n                   ci=c(\"2CI\", \"linkage\"),\n                   null_alg=c(\"hclust\", \"hclust\"))\nround(head(data_2tests$p_norm), 5)\n```\n\n```\n##      hclust_2CI hclust_linkage\n## [1,]    0.00007        0.00719\n## [2,]    0.00443        0.19216\n## [3,]    0.59790        1.00000\n## [4,]    0.82995        0.99985\n## [5,]    0.99215        1.00000\n## [6,]    0.79182        0.99999\n```\n\nThe results of clustering using `hclust_2CI` and `hclust_linkage` are reported in the columns\nof the analysis results. The relative performance of a few of these different combinations are\ndescribed in the [corresponding manuscript](#refs) when using Ward's linkage clustering.\nWhen `alpha < 1` is specified, the additional `ci_idx` parameter specifies the index of the test\nthat should be used when trying to control the FWER.  \n\n\n\n## <a name=\"plot\"></a> Plotting\n\nWhile looking at the p-values is nice, plots are always nicer than numbers. A nice way to\nsee the results of the SHC procedure is simply to call `plot` on the `shc` class object\ncreated using the `shc(..)` constructor. \n\n\n```r\nplot(shc_result, hang=.1)\n```\n\n![plot of chunk unnamed-chunk-16](figure/unnamed-chunk-16-1.png)\n\nThe resulting plot shows significant nodes and splits in red, as well as the corresponding p-values.\nNodes which were not tested, as described earlier, are marked in either green or teal (blue).  \n\n### <a name=\"diagnostics\"></a> Diagnostic plots\n\nSeveral types of diagnostic plots are implemented for the SHC method. These are available through the\n`diagnostic` method. Since testing is performed separately at each node along the dendrogram, diagnostic\nplots are also generated per-node. The set of nodes for which diagnostic plots should be generated\nis specified with the `K` parameter. The default is to only generate plots for the root node, `K = 1`.  \n\nThe method currently supports four types of diagnostic plots: `background`, `qq`, `covest`, `pvalue`.\nThe desired plot type is specified to the `pty` parameter as a vector of strings. To create all four\nplots, simply specify `all`, which is also the default value.  \n\nIf the length of `K` is greater than 1 or more than one plot type is specified, the method will\nwrite files to a pdf file, `fname.pdf`, where `fname` is an input parameter that can be specifeid\nby the user.  \n\nThe `background` plot will return a jitter plot of the matrix entries, as well as a smooth kernel\ndensity estimate and best-fit Gaussian approximation used in estimating the background\nnoise level. \n\n\n```r\ndiagnostic(shc_result, K=1, pty='background')\n```\n\n![plot of chunk unnamed-chunk-17](figure/unnamed-chunk-17-1.png)\n\nThe `qq` plot provides the corresponding Quantile-Quantile plot from the background noise estimating\nprocedure.\n\n\n```r\ndiagnostic(shc_result, K=1, pty='qq')\n```\n\n![plot of chunk unnamed-chunk-18](figure/unnamed-chunk-18-1.png)\n\nThe `covest` plot shows the estimated eigenvalues of the null Gaussian distribution along with the sample\neigenvalues of the original data matrix.\n\n\n```r\ndiagnostic(shc_result, K=1, pty='covest')\n```\n\n![plot of chunk unnamed-chunk-19](figure/unnamed-chunk-19-1.png)\n\nThe `pvalue` plot shows the cluster index for the original data along with the distribution of\nsimulated cluster indices used to determine the reported empirical (Q) p-value. Additionally, the\nbest-fit Gaussian approximation to the cluster index distirbution used to compute the Gaussian-approximate\n(Z) p-value is overlaid in black.\n\n\n```r\ndiagnostic(shc_result, K=1, pty='pvalue')\n```\n\n![plot of chunk unnamed-chunk-20](figure/unnamed-chunk-20-1.png)\n\n\n\n## <a name=\"misc\"></a> Miscellanea\n\n### <a name=\"rclusterpp\"></a> Installing Rclusterpp on OSX\n\nAs described in the [`Rclusterpp` wiki][rcpp], to make use of the package's multi-threading\ncapabilities, a separate compiler (e.g. `gcc-4.9`)  must be installed and used to build the package. \nThis essentially amounts to:\n\n1. Download a local `gcc` compiler (e.g. using [`homebrew`][homebrew]).  \n2. Modify your `~/.R/Makevars` file to include the following lines:  \n    ```\n    CFLAGS += -std=c11\n    CXXFLAGS += -std=c++11\n\n    VER=-4.9\n    CC=gcc$(VER)\n    CXX=g++$(VER)\n    SHLIB_CXXLD=g++$(VER)\n    ``` \n    where `g++-4.9` is the name of name of the local compiler installed in step 1.  \n3. Rebuild `Rclusterpp` and associated dependencies in `R`:   \n    ```\n    > install.packages(\"Matrix\")\n    > install.packages(c(\"Rcpp\", \"RcppEigen\", \"Rclusterpp\"), type=\"source\")\n    ```  \n\n\n## <a name=\"refs\"></a> References\n\n* ___Kimes PK___, Liu Y, Hayes DN, and Marron JS. \"Statistical significance \nfor hierarchical clustering.\" _Under review._ [(arXiv preprint)][arXiv].\n* Huang H, Liu Y, Yuan M, and Marron JS. (2015). \"Statistical significance of \nclustering using soft thresholding.\"\n_Journal of Computational and Graphical Statistics_.\n* Liu Y, Hayes DN, Nobel A, and Marron JS. (2008). \"Statistical significance of \nclustering for high-dimension, low-sample size data.\" \n_Journal of the American Statistical Association_.\n\n\n[devtools]:https://cran.r-project.org/web/packages/devtools/index.html\n[homebrew]: http://brew.sh\n[arXiv]: http://arxiv.org/abs/1411.5259\n[rcpp]: https://github.com/nolanlab/Rclusterpp/wiki/Getting-Started\n[shinyshc]: http://pkimes.shinyapps.io/shc_example/\n", 
  "id": 16195189
}