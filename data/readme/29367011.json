{
  "read_at": 1462551506, 
  "description": "Experiment files for the paper \"An Analysis of Unsupervised Pre-training in Light of Recent Advances\", available here: http://arxiv.org/abs/1412.6597", 
  "README.md": "# An Analysis of Unsupervised Pre-training in Light of Recent Advances\nThis repo contains the experiment files for the paper \"An Analysis of Unsupervised Pre-training in Light of Recent Advances\", available here: http://arxiv.org/abs/1412.6597\n\n## Abstract\nConvolutional neural networks perform well on object recognition because of a number of recent advances: rectified linear units (ReLUs), data augmentation, dropout, and large labelled datasets. Unsupervised data has been proposed as another way to improve performance. Unfortunately, unsupervised pre-training is not used by state-of-the-art methods leading to the following question:  \n**Is unsupervised pre-training still useful given recent advances? If so, when?**  \nWe answer this in three parts: we  \n1. develop a unsupervised method that incorporates ReLUs and recent unsupervised regularization techniques  \n2. analyze the benefits of unsupervised pre-training compared to data augmentation and dropout on CIFAR-10 while varying the ratio of unsupervised to supervised samples  \n3. verify our findings on STL-10.  \n\nWe discover unsupervised pre-training, as expected, helps when the ratio of unsupervised to supervised samples is high, and surprisingly, hurts when the ratio is low.  \n\nWe also use unsupervised pre-training with additional color augmentation to achieve near state-of-the-art performance on STL-10.\n\n### Bibtex\n```\n@article{paine2014analysis,\n  title={An Analysis of Unsupervised Pre-training in Light of Recent Advances},\n  author={Paine, Tom Le and Khorrami, Pooya and Han, Wei and Huang, Thomas S},\n  journal={arXiv preprint arXiv:1412.6597},\n  year={2014}\n}\n```\n\n## About the repo\n\nThe experiments are split into two sections:\n+ cifar10\n+ stl10\n\nThe `README.md` file in each folder will give you more information about running experiments.\n\nThe experiments are written in python 2.7, and require open source software to run, including:\n+ [numpy][numpy], a standard numerical computing library for python.\n+ [anna][anna], our neural network library, which itself depends on [theano][theano] and [pylearn2][pylearn2]. The pylearn dependencies are relatively small, and we may remove them to limit the number of dependencies.\n\n### Installation Note\n\nAfter successfully installing [pylearn2][pylearn2] and [anna][anna], the user needs to follow the three steps below before training the convolutional autoencoders:\n\n1. Go to the pylearn2 root directory.\n2. Open the ./pylearn2/sandbox/cuda_convnet/pool.py file.\n3. Add the following function to the MaxPoolGrad class.\n\n``` python\ndef grad(self, inp, grads):\n        \"\"\"\n        .. todo::\n\n            WRITEME\n        \"\"\"\n        a, b, c = inp\n        ga = gpu_contiguous(a*0)\n        gb = gpu_contiguous(b*0)\n        gc = gpu_contiguous(c)\n        gz, = grads\n        gz = gpu_contiguous(gz)\n        return [ga, gb, MaxPoolRop(self.ds, self.stride)(a, gz)]\n```\n\n[numpy]:http://www.numpy.org/\n[theano]:http://deeplearning.net/software/theano/\n[pylearn2]:http://deeplearning.net/software/pylearn2/\n[anna]:https://github.com/ifp-uiuc/anna\n\n### Status\nAll experiments are added. Just need to finalize documentation.\n", 
  "id": 29367011
}