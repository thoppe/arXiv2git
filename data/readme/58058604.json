{
  "read_at": 1462556766, 
  "description": "LiTL: Library for Transparent Lock interposition", 
  "README.md": "# LiTL: Library for Transparent Lock interposition\n\nLiTL is a library that allows executing a program based on Pthread mutex locks with another locking algorithm.\n\n- Author : Hugo Guiroux <hugo.guiroux at gmail dot com>\n- Related Publication: *Multicore Locks: the Case is Not Closed Yet*, Hugo Guiroux, Renaud Lachaize, Vivien Quema, USENIX ATC'16 (*to appear*).\n\n## Building\n\n`make`\n\n### Dependencies\n\n- numactl\n- coreutils\n- make\n- gcc\n- git\n\n## Execution\n\nLaunch your application using one of the provided scripts.\nThe name of the script to you use depends on the chosen lock.\n\nExamples:\n\n * If you want to use the MCS lock with the spin-then-park policy, do the following: `./libmcs_spin_then_park.sh my_program`\n\n * For the CLH lock with the spin policy, do the following: `./libclh_spinlock.sh my_program`\n\n * For the ticket lock (which has its waiting policy hardcoded - see below), do the following: `./libticket_original.sh my_program`\n\n## Details\n\n### Usage\nThe algorithms are named according to the following schema: `lib{algo}_{waiting_policy}.sh`.\n\nThe waiting policy can either be spinlock, spin_then_park or original.\n\nSome algorithms come with different waiting policies (Malthusian, MCS, C-BO-MCS, CLH).\nFor example, if you want to execute your application with the MCS lock, using a spin-then-park waiting policy,\nuse `libmcs_spinlock.sh`.\n\nFor the other algorithms, the name of the script to use is of the form `lib{algo}_original.sh`.\nIn this case, the waiting policy depends on the one used in the original design of the corresponding lock (spin in most cases).\n\nThe library uses `LD_PRELOAD` to intercept calls to most of the `pthread_mutex_*` functions.\n\n### Supported algorithms\n\n| Name | Ref | Waiting Policy Supported | Name in the Paper [LOC] | Notes and acknowledgments |\n| ---  | --- | --- | --- | --- |\n| **ALOCK-EPFL** | [AND] | original (spin) | alock-ls | From libslock |\n| **Backoff** | [MCS] | original (spin) | backoff | From concurrencykit |\n| **C-BO-MCS**| [COH] | spinlock or spin-then-park | c-bo-mcs_spin and c-bo-mcs_stp|  |\n| **CLH** | [SYN] | spinlock of spin-then-park | clh_spin and clh_stp | |\n| **CLH-EPFL** | [SYN] | original (spin) | clh-ls | From libslock |\n| **C-PTL-TKT** | [COH] | original (spin) | c-ptl-tkt | |\n| **C-TKT-TKT** | [COH] | original (spin) | c-tkt-tkt | |\n| **HMCS** | [HMC] | original (spin) | hmcs | |\n| **HT-LOCK-EPFL** | [EVR] | original (spin) | hticket-ls | From libslock |\n| **HYS-HMCS** | [HYS] | original (spin) | ahmcs | |\n| **Malthusian** | [MAL] | spinlock or spin-then-park | malth_spin and malth_stp | This is the Malthusian-MCS version. |\n| **MCS** | [MCS] | spinlock or spin-then-park | mcs_spin and mcs_stp | From RCL |\n| **MCS-EPFL** | [MCS] | original (spin) | mcs-ls | From libslock |\n| **MCS-TP** | [PRE] | original (spin hybrid) | mcs-timepub | From RCL |\n| **Partitioned** | [PAR] | original (spin) | partitioned | |\n| **Pthread-Adaptive** | [ADP] | original (spin_then_park) | pthreadadapt | Wrapper around pthread lock with adaptive policy |\n| **Pthread-Interpose** | - | original (park) | pthread | Wrapper around classic pthread lock |\n| **Spinlock** | [SYN] | original (spin) | spinlock | |\n| **Spinlock-EPFL** | [SYN] | original (spin) | spinlock-ls | From libslock |\n| **Ticket** | [MCS] | original (spin) | ticket | From lockless |\n| **Ticket-EPFL** | [MCS] | original (spin) | ticket-ls | From libslock |\n| **TTAS** | [AND] | original (spin) | ttas | |\n| **TTAS-EPFL** | [AND] | original (spin) | ttas-ls | From libslock |\n\nNote that the pthread-adaptive and pthread-interpose wrappers are provided only for fair comparison with the other algorithms (i.e., to introduce the same library interposition overhead).\n\n### Support for condition variables\n\n#### Summary of the approach\n\nAs explained in [LOC], we rely on classic Pthread condition variables to implement condition variables.\nHere is some pseudo-code to summarize the approach:\n```C\n// return values and error checks\n// omitted for simplification\n\npthread_mutex_lock(pthread_mutex_t *m) {\n    optimized_mutex_t *om;\n    om = get_optimized_mutex(m);\n    if (om == null) {\n        om = create_and_store_optim_mutex(m);\n    }\n    optimized_mutex_lock(om);\n    real_pthread_mutex_lock(m);\n}\n\npthread_mutex_unlock(pthread_mutex_t *m) {\n    optimized_mutex_t *om;\n    om = get_optimized_mutex(m);\n    optimized_mutex_unlock(om);\n    real_pthread_mutex_unlock(m);\n}\n\npthread_cond_wait(pthread_cond_t *c,\n                  pthread_mutex_t *m) {\n    optimized_mutex_t *om;\n    om = get_optimized_mutex(m);\n    optimized_mutex_unlock(om);\n    real_pthread_cond_wait(c, m);\n    real_pthread_mutex_unlock(m);\n    optimized_mutex_lock(om);\n    real_pthread_mutex_lock(m);\n}\n\n// Note that the pthread_cond_signal and\n// pthread_cond_broadcast primitives\n// do not need to be interposed\n```\n\nThis strategy does not introduce contention on the Pthread lock, as the latter is only requested by the holder of\nthe optimized lock associated with the critical section.\n\nSome people have raised concerns about the possibility that several threads contended on the Pthread lock, especially for\nworkloads using `pthread_cond_broadcast`.\nHowever, on Glibc/Linux, `pthread_cond_broadcast` is implemented (via the `futex` syscall) in a way such that it does not\nwake up several threads at the same time. Indeed, according to the source code of the `pthread_cond_broadcast`\nimplementation, the broadcast function simply wakes up a single thread from the wait queue of the condition variable\nand transfers the remaining threads to the wait queue of the Pthread lock. This is also confirmed in the `futex(2)` man page.\nSo, overall, for workloads that use `pthread_cond_broadcast` and/or `pthread_cond_signal`, it is unlikely to have more than\ntwo threads contending for the Pthread lock at the same time.\n\n#### Disabling support for condition variables\n\nBy default, the locks are built with the above-described support for condition variables.\nHowever, if you know that the target application does not use condition variables, you can build the locks without it.\nThis allows optimizing the critical path for lock acquisition/release by removing the need to acquire/release the underlying Pthread lock.\nTo do so, use `make no_cond_var`.\n\n\n### Trylock primitives\n\n#### Implementation\nSome algorithms do not come officially with a trylock primitive (i.e., non blocking lock request).\nHere is how we implemented trylock for them :\n\n- Cohorting: first trylock the local lock, and if needed trylock the top lock. If acquiring the top lock fails, unlock the local lock.\n- HMCS: same idea as the one for the cohorting locks\n- HYS-HMCS: as the algorithm supports fast-path, we only trylock the root MCS lock.\n- Malthusian: just trylock like with a classical MCS lock.\n- Ticket lock: the grant and request tickets are two 32-bit consecutive integers that are considered as a single 64-bit integer when trylocking.\n- Partitioned Ticket: we cannot use the trick of the ticket lock because there are only 64-bit atomic ops and we have an array of tickets. So we first check if there is anybody waiting for the lock and if not, we try to lock (we may wait a little if threads come between the check and the acquisition).\n\n#### Unsupported locks\nTo the best of our knowledge, the design of these algorithms does not support trylock semantics:\n\n- CLH and CLH-EPFL\n- HTLOCK-EPFL\n\n\n### Adding a new lock\n\nThe library is designed to be extensible. In order to introduce a new lock algorithm, consider the following steps:\n\n1. Edit Makefile.config: add one line with the format `algo_waitingstrategy` (`algo` without spaces in lowercase, `waitingstrategy` is `original`, `spinlock` or `spin_then_park`)\n2. Add a file `include/algo.h`: take `spinlock` as an example\n3. Add a file `src/algo.c`: take `spinlock` as an example\n4. Modify the top of the `interpose.c` file to add a `#ifdef` for your algorithm (the Makefile takes care of everything)\n\nRemarks:\n\n- Several helper functions are available in `src/utils.c` and `src/utils.h`.\n- If each thread needs its context for a lock, see `include/mcs.h` (`#define NEED_CONTEXT 1` is important)\n- If you want to automatically support different waiting policies, use `#define SUPPORT_WAITING 1` and `waiting_policy_{sleep/wake}`. Look into `src/mcs.c` for an example.\n- There is an example of a non-lock (`src/concurrency.c`) to show a case where the library can be used for logging statistics about locks (instead of replacing the original lock algorithm).\n\n### Cascading interposition libraries\n\nYou may want to capture statistics for different locks. For example, if you want to capture the concurrency of the MCS algorithm, you can do the following:\n\n`./libconcurrency_original.sh ./libmcs_spinlock.sh my_program`\n\n#### Details\nIn order to be able to chain interposition libraries, we must add versions to the symbols we export.\nThis is done using a symbol map (see `src/interpose.map`) and by adding a `symver` asm symbol after the function declaration (see `src/interpose.c`).\nWithout that, the library is not able to get the function pointer address of the next function using `dlvsym`.\n\n## References and acknowledgments\n\n### Lock algorithms\n- [ADP] Kaz Kylhyky. 2014. What is PTHREAD_MUTEX_ADAPTIVE_NP? http://stackoverflow.com/a/25168942\n- [AND] Thomas E. Anderson. 1990. The Performance of Spin Lock Alternatives for Shared-Memory Multiprocessors. IEEE Trans. Parallel Distrib. Syst. 1, 1 (January 1990).\n- [COH] Dave Dice, Virendra J. Marathe, and Nir Shavit. 2015. Lock Cohorting: A General Technique for Designing NUMA Locks. ACM Trans. Parallel Comput. 1, 2, Article 13 (February 2015).\n- [EVR] Tudor David, Rachid Guerraoui, and Vasileios Trigonakis. 2013. Everything you always wanted to know about synchronization but were afraid to ask. In Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles (SOSP '13).\n- [HMC] Milind Chabbi, Michael Fagan, and John Mellor-Crummey. 2015. High performance locks for multi-level NUMA systems. In Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP 2015).\n- [HYS] Milind Chabbi and John Mellor-Crummey. 2016. Contention-conscious, locality-preserving locks. In Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP '16).\n- [LOC] Hugo Guiroux, Renaud Lachaize, and Vivien Quema. 2016. Multicore Locks: the Case is Not Closed Yet. *To appear* (USENIX ATC'16).\n- [MAL] Dave Dice. 2015. Malthusian Locks. In CoRR (arXiv).\n- [MCS] John M. Mellor-Crummey and Michael L. Scott. 1991. Algorithms for scalable synchronization on shared-memory multiprocessors. ACM Trans. Comput. Syst. 9, 1 (February 1991).\n- [PAR] David Dice. 2011. Brief announcement: a partitioned ticket lock. In Proceedings of the twenty-third annual ACM symposium on Parallelism in algorithms and architectures (SPAA '11)\n- [PRE] Bijun He, William N. Scherer, and Michael L. Scott. 2005. Preemption adaptivity in time-published queue-based spin locks. In Proceedings of the 12th international conference on High Performance Computing (HiPC'05)\n- [RCL] Jean-Pierre Lozi, Florian David, Gael Thomas, Julia Lawall, and Gilles Muller. 2016. Fast and Portable Locking for Multicore Architectures. ACM Trans. Comput. Syst. 33, 4, Article 13 (January 2016)\n- [SYN] Michael L. Scott. 2013. Shared-Memory Synchronization. Morgan & Claypool Publishers.\n\n### Implementations\nSome lock implementations are borrowed (fully or partially) from source code repositories developed by other people.\nWhile we try to cite the authors of the original implementation (and the corresponding license) at the beginning of each file, we may have made mistakes and omissions. Please contact us if you notice any issue.\n\nSources:\n\n- [RCL] http://rclrepository.gforge.inria.fr/\n- [EVR] https://github.com/tudordavid/libslock\n- http://locklessinc.com/articles/locks/\n- https://github.com/concurrencykit/ck\n\nLiTL also uses the [CLHT](https://github.com/LPD-EPFL/CLHT) hashtable.\nThis hashtable is used to link a pthread_mutex_lock with the underlying data structure of the interposed lock (e.g., MCS).\n", 
  "id": 58058604
}