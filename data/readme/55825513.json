{
  "read_at": 1462547831, 
  "description": "", 
  "README.md": "# Mutual Information and Diverse Decoding Improve Neural Machine Translation\n\nImplementations of the three models presented in the paper \"Mutual Information and Diverse Decoding Improve Neural Machine Translation\" by Jiwei Li and Dan Jurafsky.\n\n## Requirements:\nGPU \n\nmatlab >= 2014b\n\nmemory >= 8GB\n\n\n## Folders\nStandard: MMI reranking for standard sequence-to-sequence models\n\n    Standard/training: training p(t|s) and p(s|t)\n\n    Standard/decode: generating N-best list from p(t|s)\n\n    Standard/get_s_given_t: generating the score of p(s|t) \n\n    Standard/MMI_rerank: reranking using different features including p(t|s) and p(s|t)\n\nAttention: MMI reranking for attention models. Folders within Attention are in the same way as in Standard.\n\ndata_gr: A sample of training/dev/testing data.\n\n## Pipelines\n(1) Training p(t|s) and p(s|t)\n\n    cd training\n\n    run matlab LSTM(1) or Attention(1) to train p(english|german)\n\n    run matlab LSTM(0) or Attention(1) to train p(german|english)\n\n(2) generating the N-best list from p(t|s)\n\n    cd decode \n\n    run matlab decode()\n\n(3) generating the score of p(s|t)\n\n    cd get_s_given_t\n\n    (3.a) preparing the data\n\n        python generate_source_target.py \n\n    (3.b) computing p(s|t)\n\n        matlab generate_score()\n\n(d) feature reranking\n\n    cd MMI_rerank\n\n    Use the open package of MERT. If you don't have mert, you can do simple grid search by running\n\n    python tune_bleu.py. \n\n    Monolingual features are not currently not included.\n\n\nFor any related questions, feel free to contact jiweil@stanford.edu\n\n```latex\n@article{li2016mutual,\n  title={Mutual Information and Diverse Decoding Improve Neural Machine Translation},\n  author={Li, Jiwei and Jurafsky, Dan},\n  journal={arXiv preprint arXiv:1601.00372},\n  year={2016}\n}\n\n```\n", 
  "id": 55825513
}