{
  "read_at": 1462556454, 
  "description": "Detection of colour variants using deep learning", 
  "README.md": "#Colour Variant Detection using Modified AlexNet Implementation in Theano\nThe code here was modified from the implementation of AlexNet at https://github.com/uoguelph-mlrg/theano_alexnet/.\nIt takes in a target image, and outputs the probability of which of n other candidate images is its colour variant.\n\n\n#AlexNet Implementation with Theano\n\nDemonstration of training an AlexNet in Python with Theano.\nPlease see this [technical report](http://arxiv.org/abs/1412.2302) for a high level description.\n[theano_multi_gpu](https://github.com/uoguelph-mlrg/theano_multi_gpu) provides a toy example on how to use 2 GPUs to train a MLP on the mnist data.\n\nIf you use this in your research, we kindly ask that you cite the above report:\n\n```bibtex\n@article{ding2014theano,\n  title={Theano-based Large-Scale Visual Recognition with Multiple GPUs},\n  author={Ding, Weiguang and Wang, Ruoyan and Mao, Fei and Taylor, Graham},\n  journal={arXiv preprint arXiv:1412.2302},\n  year={2014}\n}\n```\n\n## Dependencies\n* [numpy](http://www.numpy.org/)\n* [Theano](http://deeplearning.net/software/theano/)\n* [Pylearn2](http://deeplearning.net/software/pylearn2/)\n* [PyCUDA](http://mathema.tician.de/software/pycuda/)\n* [zeromq](http://zeromq.org/bindings:python)\n* [hickle](https://github.com/telegraphic/hickle)\n\n## How to run\n\n### Prepare raw ImageNet data\nDownload [ImageNet dataset](http://www.image-net.org/download-images) and unzip image files.\n\n### Preprocess the data\nThis involves shuffling training images, generating data batches, computing the mean image and generating label files.\n\n#### Steps\n* Set paths in the preprocessing/paths.yaml. Each path is described in this file. \n* Run preprocessing/generate_data.sh, which will call 3 python scripts and do all the mentioned steps. It runs for about 1~2 days. For a quick trial of the code, run preprocessing/generate_toy_data.sh, which takes ~10 minutes and proceed.\n\npreprocessing/lists.txt is a static file that lists what files should be created by running generate_data.sh.\n\n### Train AlexNet\n\n#### Set configurations\nconfig.yaml contains common configurations for both the 1-GPU and 2-GPU version.\n\nspec_1gpu.yaml and spec_2gpu.yaml contains different configurations for the 1-GPU and 2-GPU version respectively.\n\nIf you changed preprocessing/paths.yaml, make sure you change corresponding paths in config.yaml, spec_1gpu.yaml and spec_2gpu.yaml accordingly.\n#### Start training\n\n1-GPU version, run:\n\nTHEANO_FLAGS=mode=FAST_RUN,floatX=float32 python train.py\n\n2-GPU version, run:\n\nTHEANO_FLAGS=mode=FAST_RUN,floatX=float32 python train_2gpu.py\n\nValidation error and loss values are stored as weights_dir/val_record.npy\n\nHere we do not set device to gpu in THEANO_FLAGS. Instead, users should control which GPU(s) to use in spec_1gpu.yaml and spec_2gpu.yaml.\n\n### Pretrained AlexNet\n\nPretrained AlexNet weights and configurations can be found at [pretrained/alexnet](https://github.com/uoguelph-mlrg/theano_alexnet/tree/master/pretrained/alexnet)\n\n\n## Acknowledgement\n*Frederic Bastien*, for providing the example of [Using Multiple GPUs](https://github.com/Theano/Theano/wiki/Using-Multiple-GPUs)\n\n*Lev Givon*, for helping on inter process communication between 2 gpus with PyCUDA, Lev's original script https://gist.github.com/lebedov/6408165\n\n*Guangyu Sun*, for help on debugging the code\n", 
  "id": 43971980
}