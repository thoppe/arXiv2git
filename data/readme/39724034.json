{
  "read_at": 1462546454, 
  "description": "Doc2Vec aplicado a la clasificaci\u00f3n de sentimientos en IMDB", 
  "README.md": "# Paragraph Vector Sentiment Classification IMDB\n\n## Documentacion:\n* Articulo original\n  * http://cs.stanford.edu/~quocle/paragraph_vector.pdf\n* Articulo mejor explicado\n  * http://arxiv.org/pdf/1411.2738v1.pdf\n* Explicacion con codigo sencillo\n  * http://nbviewer.ipython.org/github/fbkarsdorp/doc2vec/blob/master/doc2vec.ipynb\n  * http://linanqiu.github.io/2015/05/20/word2vec-sentiment/\n  * https://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis\n\n## Metodo propuesto (Mejor aproximacion a un problema real)\n* Paso 0:\n  * Limpiar conjunto de datos (StopWords, Caracteres raros...)\n* Paso 1, generar vectores de las palabras:\n  * Se utilizan los documentos de Train y Unsup (75K Docs) los otros 25k no se usan.\n  * Se generar los entrenamientos que mejor resultado han dado por separado\n* Paso 2:\n  * Se generan los vectores de documentos a partir del entrenamiento anterior (Doc2Vec.infer_vector())\n* Paso 3:\n  * Se entrenan los clasificadores (50% train, 50% test, desglosados como en el conjunto inicial)\n\n## Problemas encontrados y no solucionados\n* Dada esta metodologia, no es posible aproximarse a los resultados que se exponen en el paper\n* Menor error encontrado 11.9% (DBOW, epocas 30, size 100)\n* Los cosenos no se aproximan al entrenamiento o no tanto como se esperaria al menos en DM\n* Utilizando todos los datos para entrenar y cogiendo los vectores generados en entrenamiento es posible bajar el error\n\n## ?Como hacerlo funcionar?\n* Descargar conjunto de datos\n  * http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n  * Guardar la carpeta descomprimida (aclImdb) en Data\n\n* Ejecutar data/aclimdbCleaner.py (5 minutos de ejecucion como mucho)\n* Ejecutar doc2vec.py (En mi ordenador 40 minutos)\n* Dos opciones de clasificacion:\n  * Ejecutar doc2vecClass.py (1 minuto como mucho)\n  * Ejecutar doc2vecDBOWDMclass.py esta da la mejor precision, junta DM y DBOW en un mismo vector de clasificacion\n\n## Librerias en uso\n* Blas\n* Numpy ultima version\n* Scipy (Cuidado) maxima version 0.15\n* Gensim ultima version\n* Sklearn\n\n## Datos\nSe debe simular el vector de los documentos (Metodo propuesto). En las siguentes tablas y graficas se muestran los parametros elegidos y el porque. Si el coseno se acerca a 1 es que ha \"apendido\" bien el vector documento.\n\n![Alt text](./img/dmCosenos.png?raw=true \"Tabla de cosenos\")\n![Alt text](./img/dmCosenoG.png?raw=true \"DM grafica cosenos\")\n\nSiguendo el mismo proceso con DBOW\n\n![Alt text](./img/dbowCosenoG.png?raw=true \"DBOW grafica cosenos\")\n\nSi no se sigue el metodo propuesto y se aprenden todos los documentos, el menor error encontrado es del 1 - 0.88556\n\nContinuaremos informando\n\n\n", 
  "id": 39724034
}