{
  "README.markdown": "The Burrows-Wheeler-Scott transform (called the Burrows-Wheeler transform\n\"Scottified\" in existing literature, but that sounds silly) sorts together all\ninfinitely repeated cycles of each Lyndon word of the input, then takes the\nlast character of each rotation of each Lyndon word in the overall sorted\norder. Of course, this description is about as intelligible as any of the\nexisting literature on it for someone not intimately familiar with the\nconcepts involved, and incomplete for someone who is.\n\nLyndon words are sequences which are less than any of the rotations of that\nsequence. \"Less than\", that is, the order, is defined in \"the usual\nlexicographical way\": 'a' < 'b' by definition; 'aa' < 'ab' because\nthe first positions are the same and the second position is lesser in 'aa';\n'ab' < 'ba' because 'ab' is lesser in the first position. For now, the order\nof sequences whose lengths are not equal is left undefined.\n\nA Lyndon word is a sequence such that no matter how many times you take the\nrightmost (or leftmost) element and attach it to the left (or right,\nrespectively), the result is never less than the word. By the Chen-Fox-Lyndon\ntheorem, every ordered sequence has a unique \"Lyndon factorization\" of Lyndon\nwords, such that each word in the factorization is never greater than its\npredecessor, where order is _here_ (not for the BWST algorithm) defined for\nwords of unequal length such that if a is a prefix of b, then a < b.\n\nThe concept is best illustrated by example. The Lyndon factorization of the\nsequence 'FOOBAR2000' (assume ASCII - digits precede letters) is the words\n'FOO', 'B', 'AR', '2', '0', '0', and '0'. 'F' is a Lyndon word because it has\nno rotations, but it's not part of the factorization because 'FO' is also a\nLyndon word: 'FO' < 'OF'. 'FOO' is a Lyndon word because\n'FOO' < 'OFO' < 'OOF'. 'FOOB' is _not_ a Lyndon word; 'FOOB' is not less than\nits rotation 'BFOO'.\n\nDuval (1983) gives an algorithm for finding the Lyndon factorization of a\nsequence in linear time. Wikipedia's article on Lyndon words now thankfully\nhas a description of the algorithm, but it does a poor job of explaining what\nit actually does, so I'll describe it myself. It is key to realize that all\nLyndon words of length greater than 1 end with a character greater than the\none with which it starts. Knowing this, it's easy to realize that if, while\nscanning the string for the Lyndon words, a character is encountered that is\nless than the character at the start of the current word, then the word has\nended. Note, however, that this is not the only case; an illustrative example\nhere is 'ABCA', which factorizes to 'ABC' and 'A'. When the algorithm\nencounters a character equal to the first, it has to start comparing to the\nsecond character. Or, more generally, while only one of the two indices into\nthe string the algorithm holds is incremented on each step, in the case of the\ncompared characters being equal, both indices are incremented. Since this\ncauses the algorithm to treat repeated strings as equal, word boundaries are\ndetermined according to the difference of the indices, and the lower one is\nreset to the start each time the comparison yields lower earlier.\n\nNow that I think the Lyndon factorization is satisfactorily explained, the\nBWST itself can be introduced. Recall that the BWST sorts the infinitely\nrepeated rotations of all Lyndon words of the input. Let's take a word that\nDavid Scott, the person who developed BWST, actually used with respect to the\nalgorithm, which illustrates not only this concept but also one of the\nproblems involved in learning about the transform: 'SCOTTIFACATION'. Its\nLyndon factorization produces 'S', 'COTTIF', and 'ACATION'. All rotations of\nthese words are:\n\n    S\n\tCOTTIF\n\tFCOTTI\n\tIFCOTT\n\tTIFCOT\n\tTTIFCO\n\tOTTIFC\n\tACATION\n\tNACATIO\n\tONACATI\n\tIONACAT\n\tTIONACA\n\tATIONAC\n\tCATIONA\n\nThese rotations are not sorted according to the usual lexicographical order.\nIn particular, strings of different lengths are compared as if both are\nrepeated infinitely. A shorter length to compare is each word repeated as many\ntimes as the other has characters. Even shorter is to compute the LCM of the\nlengths of those words and to make up to that many comparisons.\n\nSo, if we sort the rotations, we get:\n\n    S        ACATION\n\tCOTTIF   ATIONAC\n\tFCOTTI   CATIONA\n\tIFCOTT    COTTIF\n\tTIFCOT    FCOTTI\n\tTTIFCO    IFCOTT\n\tOTTIFC   IONACAT\n\tACATION  NACATIO\n\tNACATIO  ONACATI\n\tONACATI   OTTIFC\n\tIONACAT        S\n\tTIONACA   TIFCOT\n\tATIONAC  TIONACA\n\tCATIONA   TTIFCO\n\nThe BWST is now the last character of each rotation in the sorted output:\n'NCAFITTOICSTAO'.\n\nThis was perhaps a bad example; entropy was not reduced, and the special\ncyclic order never came into play. The basic concepts have been explained,\nhowever, and that is my aim.\n\nNow, the entire point of the BWST is that it has an inverse - you can get\n'SCOTTIFACATION' back out of 'NCAFITTOICSTAO'. To do this, we need to compare\nthe BWST output with its sorted order. Sorting gives 'AACCFIINOOSTTT'. Now we\nbuild a table thus:\n\n    Index  Sorted   BWST   Start + Count = Sum   Map\n\t0      A        N      7       0       7     2\n\t1      A        C      2       0       2     12\n\t2      C        A      0       0       0     1\n\t3      C        F      4       0       4     9\n\t4      F        I      5       0       5     3\n\t5      I        T      11      0       11    4\n\t6      I        T      11      1       12    8\n\t7      N        O      8       0       8     0\n\t8      O        I      5       1       6     7\n\t9      O        C      2       1       3     13\n\t10     S        S      10      0       10    10\n\t11     T        T      11      2       13    5\n\t12     T        A      0       1       1     6\n\t13     T        O      8       1       9     11\n\n - Index is the zero-based index into the sorted sequence for each character.\n - Sorted is the sorted sequence.\n - BWST is the input into the inverse function.\n - Start is the first index in the sorted string at which the corresponding\n   BWST character is found.\n - Count is the number of times the corresponding BWST character already has\n   been found in the sequence.\n - Sum is the sum of the starts and counts.\n - Map is the line number whose sum equals the current index.\n\nWe start at index 0 and follow the map, outputting from the sorted sequence as\nwe go:\n\n    Index   Sorted   Map   Output\n\t0       A        2     A\n\t2       C        1     AC\n\t1       A        12    ACA\n\t12      T        6     ACAT\n\t6       I        8     ACATI\n\t8       O        7     ACATIO\n\t7       N        0     ACATION\n\nBut the map at line 7 points to an index we've already visited. We've now\nretrieved the lexicographically least Lyndon word from the input. Next, we\nmove to the lowest index we have not yet visited, which is 3.\n\n    Index   Sorted   Map   Output\n\t3       C        9     C\n\t9       O        13    CO\n\t13      T        11    COT\n\t11      T        5     COTT\n\t5       I        4     COTTI\n\t4       F        3     COTTIF\n\nWe know the next greatest Lyndon word. The only unvisited index so far is 10,\nso S at 10 is the greatest Lyndon word in the original input. Concatenating\nthe words in nonincreasing order yields SCOTTIFACATION. BWST inverted.\n\nResources:\n - http://groups.google.com/group/comp.compression/msg/a0236d754e869212 - This\n   is an old post, so it misses some connections which now are known, but it\n   is the only plain-English description of the BWST and UNBWST I could find.\n - http://bijective.dogma.net/00yyy.pdf - This paper is a fairly intelligible\n   description and implementation of the algorithms, but it contains several\n   significant errors. Its examples are more optimized than the ones I gave;\n   if you want to learn more, check it out, but not until you understand the\n   algorithms enough to be able to recognize the errors.\n - http://arxiv.org/abs/0908.0239 - This paper is for those with advanced\n   degrees. It is correct, but almost impossible to understand: \"Let k [?] N.\n   Let [?]_{i=1}^s[v_i] = {w_1, ..., w_n} [?] [?]^+ be a multiset built from\n   conjugacy classes [v_i]. Let M = (w_1, ..., w_n) satisfy context_k(w_1) <=\n   *** <= context_k(w_n) and let L = last(w_1) *** last(w_n) be the sequence of\n   the last symbols. Then context_k(w_i) = l_Lp_L(i)*l_Lp_L^2(i)***l_Lp_L^k(i)\n   where p_L^t denotes the t-fold application of p_L and l_Lp_L(i) =\n   l_L(p_L(i)).\"\n", 
  "read_at": 1462549746, 
  "description": "Burrows-Wheeler-Scott transform", 
  "id": 4139603
}