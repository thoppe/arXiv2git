{
  "read_at": 1462511538, 
  "description": "Working copy of Deeplab repository", 
  "README.md": "## DeepLab\r\n\r\n### Introduction\r\n\r\nDeepLab is a state-of-art deep learning system for semantic image segmentation built on top of [Caffe](http://caffe.berkeleyvision.org).\r\n\r\nIt combines densely-computed deep convolutional neural network (CNN) responses with densely connected conditional random fields (CRF).\r\n\r\nThis distribution provides a publicly available implementation for the key model ingredients first reported in an [arXiv paper](http://arxiv.org/abs/1412.7062), accepted in revised form as conference publication to the ICLR-2015 conference. \r\nIt also contains implementations for methods supporting model learning using only weakly labeled examples, described in a second follow-up [arXiv paper](http://arxiv.org/abs/1502.02734).\r\nPlease consult and consider citing the following papers:\r\n\r\n    @inproceedings{chen14semantic,\r\n      title={Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs},\r\n      author={Liang-Chieh Chen and George Papandreou and Iasonas Kokkinos and Kevin Murphy and Alan L Yuille},\r\n      booktitle={ICLR},\r\n      url={http://arxiv.org/abs/1412.7062},\r\n      year={2015}\r\n    }\r\n\r\n    @article{papandreou15weak,\r\n      title={Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation},\r\n      author={George Papandreou and Liang-Chieh Chen and Kevin Murphy and Alan L Yuille},\r\n      journal={arxiv:1502.02734},\r\n      year={2015}\r\n    }\r\n\r\n### Performance\r\n\r\nAt the time of its release, DeepLab is the state-of-art method on semantic image segmentation on the challenging PASCAL VOC-2012 image segmentation task, with the latest variant achieving 72.7% mean IoU on the test set -- see the [leaderboard](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6).\r\n\r\n### Pre-trained models\r\n\r\n1. DeepLab and corresponding prototxt files at [here](http://www.cs.ucla.edu/~lcchen/deeplab-public/vgg128_noup/). After DenseCRF, the model yields 66.4% performance on the PASCAL VOC 2012 test set.\r\n\r\n2. DeepLab-MSc at [here](http://www.cs.ucla.edu/~lcchen/deeplab-public/vgg128_ms_pool3/). After DenseCRF, the model yields 67.1% performance on the PASCAL VOC 2012 test set.\r\n\r\n3. DeepLab-COCO (has fine-tuned on [MS-COCO](http://mscoco.org/) and then on PASCAL VOC [2012](http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2012/)) at [here](http://www.cs.ucla.edu/~lcchen/deeplab-public/vgg128_noup_pool3_cocomix/). After DenseCRF, the model yields 70.4% performance on the PASCAL VOC 2012 test set.\r\n\r\n4. DeepLab-Weak-EM-Adapt at [here](http://ttic.uchicago.edu/~gpapan/deeplab/vgg128_noup_pool3_adaweak). Trained on PASCAL using only weak image-level labels. After DenseCRF, the model yields 39.0% performance on the PASCAL VOC 2012 test set.\r\n\r\n### Experimental set-up\r\n\r\n1. The scripts we used for our experiments:\r\n    1. [run_pascal.sh](http://www.cs.ucla.edu/~lcchen/deeplab-public/run_pascal.sh): the script for training/testing on the PASCAL VOC 2012 dataset. __Note__ You also need to download this [file](http://www.cs.ucla.edu/~lcchen/deeplab-public/sub.sed)\r\n    2. [run_densecrf.sh](http://www.cs.ucla.edu/~lcchen/deeplab-public/run_densecrf.sh) and [run_densecrf_grid_search.sh](http://www.cs.ucla.edu/~lcchen/deeplab-public/run_densecrf_grid_search.sh): the scripts we used for post-processing the DCNN computed results by DenseCRF.\r\n2. The image list files used in our experiments:\r\n    * The [list folder](http://www.cs.ucla.edu/~lcchen/deeplab-public/list) stores the list files for the PASCAL VOC 2012 dataset. You can download the zipped file [here](http://www.cs.ucla.edu/~lcchen/deeplab-public/list.zip) (i.e., all the lists).\r\n3. To use the mat_read_layer and mat_write_layer, please download and install [matio](http://sourceforge.net/projects/matio/files/matio/1.5.2/).", 
  "id": 34340124
}