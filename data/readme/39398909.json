{
  "README": "README: BUILDING GENASIS APPLICATIONS, EXAMPLES, AND/OR UNIT TESTS\n--------------------------------------------------------------------------\n\nMethod paper accompanying this release is available at:\nhttp://dx.doi.org/10.1016/j.cpc.2015.06.001\nor the pre-print arXiv http://arxiv.org/abs/1507.02506 \n\nA machine-specific Makefile is needed to build GenASiS programs. Several \nsample Makefiles are provided under the subdirectory Build/Machines. \nMinor modifications of one of the provided Makefiles that most\napproximates one's computing environment is often sufficient to get started. \nThe essential information needed includes the name of the compiler wrapper\nto compile MPI-based code (e.g. commonly 'mpif90' for Fortran), \ncompiler-specific flags for various debugging and optimization options, and\nthe flags and locations to include and link with third-party libraries such\nas Silo. \n\nOnce the machine-specific Makefile is set up, the environment variable \nGENASIS_MACHINE has to be set to tell the GenASiS build system to use the \ncorresponding Makefile. For example, to use the Makefile for the GNU compiler\non a Linux machine (i.e. Makefile_Linux_GNU), in a Bash Unix shell one can\ntype:\n\n> export GENASIS_MACHINE=Linux_GNU\n\nIn most common computing environments with a generic MPI library, the\nfluid dynamics example programs (described in the accompanying paper) can then be\nbuilt and executed (here with 8 MPI processes) with the following commands:\n\n> cd Programs/Examples/Basics/FluidDynamics/Executables\n> make\n> mpirun -np 8 ./SineWaveAdvection_Linux_GNU nCells=128,128,128\n> mpirun -np 8 ./SawtoothWaveAdvection_Linux_GNU nCells=128,128,128 \\\nnWavelengths=2,2,2\n> mpirun -np 8 ./RiemannProblem_Linux_GNU nCells=128,128,128 \\\nFinishTime=0.25\n\n(To compile in a manner that is unoptimized but useful for debuggers, \nreplace 'PURPOSE=OPTIMIZE' with 'PURPOSE=DEBUG'. Or omit it altogether; \nin the absence of a specification of PURPOSE, the Makefile in \nFluidDynamics/Executables sets PURPOSE=DEBUG as a default.)\nNote that in these examples, the optional non-default parameter values for\nnCells, nWavelengths, and FinishTime---which were used in\ngenerating the figures in the accompanying paper---are passed\nto the programs in this case via command-line options. The 1D and 2D cases\nof these programs can also be executed by specifying fewer elements for \nnCells, for example\n\n> mpirun -np 2 ./RiemannProblem_Linux_GNU nCells=128 Dimensionality=1D \\\nFinishTime=0.25\n> mpirun -np 4 ./RiemannProblem_Linux_GNU nCells=128,128 Dimensionality=2D \\\nFinishTime=0.25\n\nwhere the 'Dimensionality' option here is only used as an appendix to the \nname of the output file (it should be consistent with the number of \nelements given to nCells, which the program uses to determine the \ndesired dimensionality of the mesh).\n \nBy default the output files are written in the directory \"Output\"\nthat resides on the same level as the \"Executables\" directory, but\nthis can be changed with an optional 'OutputDirectory' command line\noption. \n\nIf the VisIt visualization package is available, plots similar to the Figures \nin the accompanying paper can be generated using the supplied visualization\nscript called from the \"Output\" directory. The script takes one argument, \nwhich is the program name appended with the \"Dimensionality\" string. Assuming \nthe executable \"visit\" is available, the visualization script can be called, \nfor example, as the follows:\n\n> cd Programs/Examples/Basics/FluidDynamics/Output\n> visit -cli -s ../PlaneWaveAdvection.visit.py SineWaveAdvection_3D\n> visit -cli -s ../PlaneWaveAdvection.visit.py SawtoothWaveAdvection_2D\n> visit -cli -s ../PlaneWaveAdvection.visit.py RiemannProblem_1D\n\nThe molecular dynamics programs described in the accompanying paper can be \nbuilt and executed in a manner similar to those in FluidDynamics. The \ndirectory MolecularDynamics is also found under Programs/Examples/Basics.\nA blanket \"make\" command in the Executables subdirectory compiles both \nArgonEquilibrium and ClusterFormation}. For both programs, all results \npresented in the accompanying paper were obtained with parameters \nnSteps=10000 and nWrite=1000. Various numbers of particles and processes \nused for different runs are mentioned in the accompanying paper. In the case \nof ClusterFormation, the number of particles is directly specified by a \nparameter nParticles. For ArgonEquilibrium a parameter nUnitCellsRoot is \nused instead; the number of particles is 4 * ( nUnitCellsRoot ** 3 ). Thus \nthe values 8, 12, 16, and 20 for nUnitCellsRoot correspond to 2048, 6912, 16384, and 32000 particles respectively. Specification of the number density and \ntemperature parameters for different phases of argon is discussed in the\naccompanying paper.\n\nUnit test programs exercising individual GenASIS classes can similarly be\nbuilt and executed inside the \"Executables\" directory of each leaf\ndivision of the code under \"Programs/UnitTests\". For example, the following \ncommands build and execute the unit test programs for classes in the \n\"Runtime\" division:\n\n> cd Programs/UnitTests/Basics/Runtime/Executables\n> make\n> mpirun -np 1 [program_name]\n\nThis blanket \"make\" builds all the unit test targets in the Makefile fragment \nPrograms/Basics/Runtime/Makefile_Runtime. Individual targets of course also \ncan be built.\n\nGenASiS Basics has been tested with the following compilers: GNU\nFortran compiler (gfortran, part of GCC) version 4.9, NAG Fortran compiler\nversion 5.3.1, and Cray Compiler Environment version 8.2.5. Newer versions\nof these compilers are likely to work as well. GenASiS Basics is written in \nfull compliance with the Fortran 2003 standard (with the addition of a couple of minor new features\nof Fortan 2008, including the \"impure\" attribute and finding a new\nunit number in the \"open\" statement) to enhance portability.\n\nAuthors:\nChristian Cardall (cardallcy@ornl.gov)\nReuben Budiardja (reubendb@utk.edu)\n", 
  "read_at": 1462546456, 
  "description": "Object-oriented Utilitarian Functionality for Large-scale Physics Simulations ", 
  "id": 39398909
}