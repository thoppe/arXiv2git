{
  "read_at": 1462549645, 
  "description": "Artificial neural network construction and training", 
  "README.md": "# Arignote\r\n\r\nFrom Wikipedia: Arignote or Arignota (Greek: Arignote, Arignote) was a Pythagorean philosopher who flourished around the year 500 bc. She was known as a student of Pythagoras and Theano and, according to some traditions, their daughter as well.\r\n\r\n# Introduction\r\n\r\nArignote is a library for building and training neural networks, built on the Theano library.\r\nIt's built to be flexible and extendable. Arignote trains neural networks using minibatch SGD,\r\nso you're not required to have all data in memory at once. The checkpointing feature allows\r\ntraining to stop and resume as if it had never been interrupted (useful for working with EC2\r\nspot instances).\r\n\r\nWarning -- this library currently has no tests (so is undoubtedly broken in some way).\r\nThe code is also rough in many places. At this time, Arignote only supports feed-forward\r\nnetworks; recurrent neural networks may or may not be added in the future.\r\n\r\n## Example of use\r\n\r\nThe following example instantiates and trains a simple multi-layer perceptron on the MNIST data.\r\n\r\n```\r\nfrom arignote.nnets import nets\r\nfrom arignote.data import files\r\nfrom arignote import sample_data\r\n\r\nlayers = [[\"InputLayer\", {\"name\": \"input\"}],  # May specify explicitly or leave this off.\r\n          [\"FCLayer\", {\"name\": \"fc1\", \"n_units\": 400, \"activation\": \"prelu_shelf\", \"l2\": 0.001}],\r\n          [\"DropoutLayer\", {\"name\": \"DO-fc1\", \"dropout_p\": 0.5}],\r\n          [\"FCLayer\", {\"name\": \"fc2\", \"n_units\": 400, \"activation\": \"prelu_shelf\", \"l2\": 0.001}],\r\n          [\"DropoutLayer\", {\"name\": \"DO-fc2\", \"dropout_p\": 0.5}],\r\n          [\"ClassificationOutputLayer\", {\"name\": \"output\", \"n_classes\": 10}]]\r\n\r\nclassifier = nets.NNClassifier(layers, name=\"MNIST MLP\", rng=42)\r\n\r\n# Specify how the learning rate changes during training.\r\nlr_rule = {\"rule\": \"stalled\", \"initial_value\": 0.1, \"multiply_by\": 0.25, \"interval\": 5}\r\n\r\n# Specify how the momentum changes during training.\r\nmomentum_rule = {\"rule\": \"stalled\", \"initial_value\": 0.7, \"decrease_by\": -0.1,\r\n                 \"final_value\": 0.95, \"interval\": 5}\r\n\r\nmnist_data = files.read_pickle(sample_data.mnist)\r\nclassifier.fit(mnist_data[0], n_epochs=50, valid=mnist_data[1], test=mnist_data[2],\r\n               augmentation=None, checkpoint=checkpoint, sgd_type=\"nag\",\r\n               lr_rule=lr_rule, momentum_rule=momentum_rule, batch_size=128,\r\n               train_loss=\"nll\", valid_loss=\"nll\", test_loss=[\"nll\", \"error\"])\r\n```\r\n\r\n\r\n# Installation\r\n\r\nClone the Arignote repository, then run\r\n```\r\npython setup.py install\r\n```\r\nor\r\n```\r\npython setup.py develop\r\n```\r\n\r\n## Requirements\r\n\r\n- Tested and known to work with Python 3.4 and 2.7.10\r\n- theano\r\n- numpy\r\n- six\r\n\r\nOptional requirements\r\n- pandas (needed to read HDF5 files)\r\n\r\n\r\n# Instructions\r\n\r\n## Network initialization\r\n\r\nDefine your network with a list of layers. Each element of the list must be a list or\r\ntuple with two elements: The type of the layer (a string), and a dictionary of\r\nparameters for that layer.\r\n\r\nThis is an example definition of a fully-connected layer. It has an (optional) name,\r\na number of neurons (required), an activation function (defaults to \"prelu\"), and\r\na ridge regularization constant (defaults to 0).\r\n```\r\n[\"FCLayer\", {\"name\": \"fc1\", \"n_units\": 100, \"activation\": \"relu\", \"l2\": 0.001}]\r\n```\r\n\r\nAll layers take the following parameters:\r\n- name (optional): A layer name for debugging and display.\r\n\r\nAll layers with weights take the following parameters:\r\n- l1 (0): L1 weight decay\r\n- l2 (0): L2 weight decay\r\n- maxnorm (None): Maximum norm of a row in the weight array. Rows which would become larger during training will be scaled to fit.\r\n\r\nAvailable trainable layer types and their parameters are:\r\n- \"ClassificationOutputLayer\" (A multi-output logistic regression layer)\r\n    - n_classes : int, number of output classes (softmax output)\r\n- \"FCLayer\" (Fully-connected layer)\r\n    - n_units\r\n    - activation (\"prelu\"): str, Name of the activation function\r\n- \"FCMaxoutLayer\" (Fully-connected layer using the \"maxout\" activation function)\r\n    - n_units\r\n    - maxout_k (5) : int, Number of linear activations in the maxout\r\n- \"ConvLayer\" (convolutional layer)\r\n    - n_output_maps : int, Number of output kernels\r\n    - filter_shape : length-2 list of ints, size of convolutional filter in pixels\r\n    - activation (\"prelu\"): str\r\n    - stride (1, 1): length-2 list of ints, non-default values may not be working\r\n- \"ConvMaxoutLayer\" (convolutional layer with \"maxout\" activation function)\r\n    - n_output_maps : int, Number of output kernels\r\n    - filter_shape : length-2 list of ints, size of convolutional filter in pixels\r\n    - maxout_k (5): int, Number of linear activations in the maxout\r\n    - stride (1, 1): length-2 list of ints, non-default values may not be working\r\n- \"MLPConvLayer\" (\"mlpconv\" layer from arXiv:1312.4400v3)\r\n    - n_output_maps : int, Number of output kernels\r\n    - filter_shape : length-2 list of ints, size of convolutional filter in pixels\r\n    - n_units : list of integers, number of neurons in each layer of the mlpconv activation\r\n    - activation (\"prelu\"): str\r\n    - stride (1, 1): length-2 list of ints, non-default values may not be working\r\n\r\nNon-trainable layer types:\r\n- \"DropoutLayer\"\r\n    - dropout_p : float between 0 and 1. Dropout this fraction of the previous layer's outputs.\r\n- \"MaxPool2DLayer\"\r\n    - pool_shape : length-2 list of ints\r\n    - stride (None) : Defaults to `pool_shape`\r\n\r\nUtility layers:\r\n- \"InputImageLayer\" (Required if input is more than 1D)\r\n    - n_images : int, number of channels in the input\r\n    - n_pixels : length-2 list of ints, number of pixels in each image\r\n- \"BC01ToC01BLayer\" (Place before a block of convolutions. Required for CUDA-Convnet optimizations)\r\n- \"C01BToBC01Layer\" (Place after a block of convolutions. Required for CUDA-Convnet optimizations)\r\n\r\n\r\n## Data input\r\n\r\nArignote can take dense arrays of floating-point data, or HDF5 files containing dense arrays\r\nof floating-point data.\r\n\r\nYou can create HDF5 files using pandas, for example:\r\n```\r\nimport pandas as pd\r\n\r\nstore = pd.HDFStore(filename)\r\nfor i_row in range(n_images):\r\n        image, label = read_image_from_somewhere(i_row)\r\n\r\n        # \"label\" should be a list or array.\r\n        store.append(\"labels\", label)\r\n        store.append(\"images\", pd.Panel4D({i_row: image}),\r\n                     axes=[\"labels\", \"major_axis\", \"minor_axis\"], complib=\"zlib\", complevel=9)\r\n\r\nstore.close())\r\n```\r\n\r\nThen create an Arignote data reader with e.g.\r\n```\r\nfrom arignote.data import readers\r\n\r\nfeatures = readers.HDFReader(filename, \"images\", asarray=True)\r\nlabels = readers.HDFReader(filename, \"labels\", asarray=False)\r\ndata = readers.DataWithHoldoutParitions(features, labels, batch_size=batch_size,\r\n                                        valid_frac=valid_frac, test_frac=test_frac)\r\n```\r\n\r\nYou can create your own data input object to feed in data from arbitrary data sources.\r\nJust subclass the `readers.Reader` abstract class and define the method `iter_epoch` which\r\ntakes arguments `batch_size, start=0, stop=None, start_on_batch=True, allow_partial=False`.\r\nSee the `readers` module for more.\r\n\r\nNote that the `reader.Data` and `reader.DataWithHoldoutPartitions` also accept functions\r\nwhich can alter each minibatch on readout, for example for data augmentation.\r\nThis function will run inside a thread, so that it can operate during GPU training\r\n(theano releases the GIL, and your CPUs aren't doing anything else while the GPU is working).\r\n\r\n## Training\r\n\r\nNow that you've defined your network and gotten your data sources, it's time to\r\ntrain the network. Instantiate a new network with\r\n```\r\nfrom arignote.nnets import nets\r\n\r\nclassifier = nets.NNClassifier(layer_definition_list, name=\"Sample network\", rng=42)\r\n```\r\n\r\nand fit it with `classifier.fit`. See the docstrings in the `nets.NNClassifier` class\r\nfor details of the usage and all of the arguments available.\r\n\r\n### The `fit` function\r\n\r\nPerform supervised training on the input data.\r\n\r\nWhen restoring a pickled `NNClassifier` object to resume training,\r\ndata, augmentation functions, and checkpoint locations must be\r\nre-entered, but other parameters will be taken from the previously\r\nstored training state. (The `n_epochs` may be re-supplied to alter\r\nthe number of epochs used, but will default to the previously\r\nsupplied `n_epochs`.)\r\n\r\nTraining may be stopped early by pressing ctrl-C.\r\n\r\nTraining data may be provided in either of the following formats:\r\n- An array of (n_examples, n_features) in the first positional\r\n    argument (keyed by `X`), and an array of (n_examples, n_labels)\r\n    in the second positional argument (keyed by `y`)\r\n- An object of type `readers.DataWithHoldoutParitions` or `readers.Data`\r\n    presented in the first positional argument\r\n\r\nValidation data may be optionally supplied with the `valid` key\r\nin one of the following formats (only if the training data were not\r\ngiven as a `readers.DataWithHoldoutParitions` object):\r\n- A tuple of (X, y), where `X` is an array of\r\n    (n_validation_examples, n_features) and `y` is an array of\r\n    (n_validation_examples, n_labels)\r\n- A `readers.Data` object\r\n- A float in the range [0, 1), in which case validation data will\r\n    be held out from the supplied training data (only if training\r\n    data were given as an array)\r\n\r\nTest data may be optionally supplied with the `test` key, using the same\r\nformats as for validation data.\r\n\r\n    Parameters\r\n    ----------\r\n    X, y, valid, test\r\n        See above for discussion of allowed input formats.\r\n    n_epochs : int\r\n        Train for this many epochs. (An \"epoch\" is one complete pass through\r\n        the training data.) Must be supplied unless resuming training.\r\n    batch_size : int\r\n        Number of examples in a minibatch. Must be provided if was\r\n        not given during object construction.\r\n    augmentation : function, optional\r\n        Apply this function to each minibatch of training data.\r\n    checkpoint : str, optional\r\n        Filename for storing network during training. If supplied,\r\n        Arignote will store the network after every epoch, as well\r\n        as storing the network with the best validation loss and\r\n        the final network. When using a checkpoint, the trainer\r\n        will restore the network with best validation loss at the\r\n        end of training.\r\n    sgd_type : {\"adadelta\", \"nag\", \"adagrad\", \"rmsprop\", \"sgd\"}\r\n        Choice for stochastic gradient descent algorithm to use in training\r\n    lr_rule, momentum_rule : dict of sgd_updates.Rule params, optional\r\n        Use these dictionaries of parameters to create Rule objects\r\n        which describe how to alter the learning rate and momentum\r\n        during training.\r\n    train_loss, valid_loss : {\"nll\", \"error\"}\r\n        Loss function for training and validation. With a custom\r\n        output layer, may also be the name of a function which returns\r\n        a theano symbolic variable giving the cost.\r\n        (\"nll\" = \"negative log likelihood\")\r\n    test_loss : str or list\r\n        May be any of the loss functions usable for training, or\r\n        a list of such functions.\r\n\r\n    Other Parameters\r\n    ----------------\r\n    sgd_max_grad_norm : float, optional\r\n        If provided, scale gradients during training so that the norm\r\n        of all gradients is no more than this value.\r\n    validation_frequency : int, optional\r\n        Check the validation loss after training on this many examples.\r\n        Defaults to validating once per epoch.\r\n    validate_on_train : bool, optional\r\n        If set, calculate validation loss (using the deterministic\r\n        network) on the training set as well.\r\n    checkpoint_all : str, optional\r\n        Keep the state of the network at every training step.\r\n        Warning: may use lots of hard drive space.\r\n    extra_metadata : dict, optional\r\n        Store these keys with the pickled object.\r\n\r\n\r\n### SGD Parameters\r\n\r\nTraining uses stochastic gradient descent. You can control the parameters of the SGD\r\nby defining rules for learning rate and (if applicable to the SGD algorithm) momentum.\r\nThese are defined in the docstring of the `arignote.nnets.sgd_update.Rule` class, and are:\r\n\r\n    rule : {\"const\", \"constant\", \"fixed\", \"stalled\"}\r\n        Type of rule to apply\r\n    initial_value : float\r\n        Where to start the parameter\r\n    final_value : float, optional\r\n        Stop changing the parameter when it reaches this value.\r\n    decrease_by : float, optional\r\n        When changing this parameter, subtract this value from it.\r\n    multiply_by : float, optional\r\n        When changing this parameter, multiply by this value.\r\n        This is done after subtracting `decrease_by`.\r\n    interval : int, optional\r\n        Update the parameter after this many validations.\r\n        Typically, we validate once per epoch.\r\n        If a `schedule` is also provided, use the `interval` only\r\n        once the schedule is exhausted.\r\n    schedule : list of ints, optional\r\n        Alter the parameter at these set epochs.\r\n\r\n\r\n## Credits\r\n\r\nArignote began with code from the tutorials published by the University of Montreal's LISA lab,\r\nhttp://deeplearning.net/tutorial/. It's taken inspiration and sometimes snippets of code from\r\nexisting neural network libraries such as Lasagne (https://github.com/Lasagne/Lasagne).\r\nI've tried to add credits to code which was copied directly or nearly directly from elsewhere.\r\nFunctions directly inspired by a particular research paper contain a reference to that paper.\r\n\r\nArignote contains a copy of the MNIST dataset (http://yann.lecun.com/exdb/mnist/), converted\r\nto a Python pickle file by the LISA lab: http://deeplearning.net/tutorial/gettingstarted.html#mnist-dataset .\r\n", 
  "id": 38085553
}