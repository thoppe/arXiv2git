{
  "id": 45412798, 
  "read_at": 1462554260, 
  "README.txt": "SimpleDS version 1.0 - 02.Nov.2015 - First version\n                 1.1 - 10.Nov.2015 - Multilingual support\n\nDESCRIPTION\n-----------\nSimpleDS is a simple dialogue system trained with deep reinforcement learning.\nIn contrast to other dialogue systems, this system selects dialogue actions \ndirectly from raw (noisy) text of the last system and user responses. The moti-\nvation is to train dialogue agents with as little human intervention as possible. \n\nThis system runs under a client-server architecture, where the learning agent (in \nJavaScript) acts as the \"server\" and the environment (in Java) acts as the \"client\". \nThey communicate by exchanging messages, where the server tells the client the \naction to execute, and the client tells the server the state and reward observed. \nSimpleDS is based on ConvNetJS (cs.stanford.edu/people/karpathy/convnetjs/), which \nimplements the algorithm `Deep Q-Learning with experience replay' (Mnih, et al. 2015).\nSimpleDS is a dialogue system on top of ConvNetJS with support for multi-threaded \nand client-server processing, and fast learning via constrained search spaces.\n\nThis system has been tested with simulated and real dialogues using the Google Speech\nRecogniser. It has also been tested in three different languages: English, German and \nSpanish. SimpleDS is for experimental purposes, represents work in progress, and is \ntherefore released without any guarantees.\n\nSOFTWARE\n--------\nThis system was implemented and tested under Linux and Mac OS X with the following \nsoftware -- though it should run in other operating systems with minor modifications.\n+ Ubuntu 14.10.4 / Mac OS X 10.10\n+ Java 1.8.0 or higher\n+ Ant 1.9.3 or higher\n+ Node 0.10.25 or higher\n+ Octave 3.8.0 or higher\n+ Android 4.4.3 (optional)\n\nDOWNLOAD\n--------\nYou can download the system directly from the command line:\n>git clone https://github.com/cuayahuitl/SimpleDS.git\n\nYou can also download the system as a zip file using the following URL, \nand then unzip it in your path of preference.\nhttps://github.com/cuayahuitl/SimpleDS/archive/master.zip \n\nCOMPILATION\n-----------\n>cd YourPath/SimpleDS\n>ant\n\nEXECUTION\n---------\n>cd YourPath/SimpleDS\n>scripts/run.sh train\n>[From the command line, press Ctrl+C for termination]\n\nor \n\n>cd YourPath/SimpleDS\n>scripts/run.sh test\n>[From the command line, press Ctrl+C for termination]\n\nAlternatively, you can run the system from two terminals\nTerminal1:YourPath/SimpleDS>ant SimpleDS\nTerminal2:YourPath/SimpleDS/web/main>node runclient.js (train|test) [num_dialogues] [-v|-nv]\n\nFor practical reasons, you can specify the number of dialogues and verbose mode from the command \nline. The values of these parameters would override the values specified in the file config.txt.\n\nThe outputs from the training phase consists in the learnt interaction policy (json file under the \nfolder 'results/language'), and logged performance metrics (txt file under the 'results/language'). \nDepending on the config file, the metrics produce multiple rows with the following information: \nnumber of dialogues, average reward, epsilon value, number of actions per state, number of \ndialogues, and execution time (in hours). The outputs from the test phase are similar exept that \nno learnt policy is generated. In addition, executing the system in verbose mode would print out \ntraining/test dialogues -- according to the specified parameters.\n\nPLOTTING\n--------\nYou can visualise a learning curve of the SimpleDS agent according to number of \nlearning steps in the x-axis and average reward + learning time in the y-axis.\n\n>cd YourPath/SimpleDialogueSystem\n>octave scripts/plotdata.m results/simpleds-output.txt\n>[From the command line, press the space bar key for termination]\n\nor \n\n>cd YourPath/SimpleDialogueSystem\n>octave scripts/plotdata.m results/simpleds-output.txt results/simpleds-output.png\n>[From the command line, press the space bar key for termination]\n\nThe latter generates an image of the plot in png (Portable Network Graphics) format.\nThe file plotdata.m can also be used from Matlab if that software is prefered.\n\nCONFIGURATION\n-------------\nThe config file \"YourPath/SimpleDialogueSystem/config.txt\" has the following parameters:\n\nDialogues=Number of dialogues for training/test (positive integer)\nVerbose=Shows compressed information or detailed info (false or true)\nLanguage=Defines the (spoken) language to use (english, german, spanish)\nSysResponses=Path and file name of system responses (e.g. resources/SysResponses.txt)\nUsrResponses=Path and file name of system responses (e.g. resources/UsrResponses.txt)\nSlotValues=Slot-value pairs of the system (e.g. resources/SlotValues.txt)\nDemonstrationsPath=Path to the demonstration dialogues (e.g. data/)\nDemonstrationsFile=Pointer to training instances from demonstrations (models/demonstrations.arff)\nMinimumProbability=Minimum probability (>=0) for probable actions considered for action-selection\nSlotsToConfirm=Number of slots to confirm (positive integer, e.g. 3)\nOutputPath=The directory where the output files (policy and metrics) will be stored\nNoiseLevel=Scores under this level (<=0.2) would receive distorsion to model noisy recognition\nAddressPort=Address and port of the client socket (e.g. ws://localhost:8082/simpleds)\nSavingFrequency=This number defines the frequency for policiy/output saving (positive integer)\nNumInputs=This number defines the number of input nodes of the neural net (positive integer) \nNumActions=This number defines the number of actions of the agent (positive integer)\nLearningSteps=This number defines the number of time steps during learning (positive integer)\nExperienceSize=This number defines the size of the experience replay moemory (positive integer)\nBurningSteps=This number defines the time steps with random action selection (positive integer)\nDiscountFactor=This number defines gamma parameter also known as discount factor (real number)\nMinimumEpsilon=This number defines the minimum epsilon during learning (real number)\nBatchSize=This number defines the batch size (positive integer, e.g. 32 or 64)\nAndroidSupport=This variable is used to test dialogues with a real speech recogniser (true or false)\nSocketServerPort=This number defines the socket port used for communication with Android (positive integer)\n\nYou may want to set Verbose=false during training and Verbose=true during tests.\nYou may also want to set a high number of dialogues during training and a low one during tests.\nYou may want to change the system/user responses if you want different verbalisations. If this\nis the case, then you will also want to update the demonstration dialogues in the folder data/.\n\nForthcoming extensions:\n+ Instructions on how to apply SimpleDS to different types of interactive systems.\n+ Tools for testing and visualising the learnt policies.\n+ Other learning algorithms, among others.\n\nCITATION\n--------\nPlease use the following reference if you use SimpleDS code or if you want to cite this work.\n\n@inproceedings{HC2016iwsds,\n  author    = {Heriberto Cuay\\'ahuitl},\n  title     = {{SimpleDS}: A Simple Deep Reinforcement Learning Dialogue System},\n  booktitle = {International Workshop on Spoken Dialogue Systems (IWSDS)},\n  url       = {https://github.com/cuayahuitl/SimpleDS/blob/master/doc/hc-iwsds2016.pdf},\n  year      = {2016},\n}\n\nSimpleDS has been applied to Strategic Dialogue Management, and can be applied to other interactive \nsystems in a fairly straightforward way. See \"How to apply SimpleDS to interactive systems\".\n\nCOMMENTS/QUESTIONS/COLLABORATIONS?\n----------------------------------\nContact: Heriberto Cuayahuitl\nEmail: h.cuayahuitl@gmail.com\n", 
  "README.md": "# SimpleDS\nA Simple Deep Reinforcement Learning Dialogue System\n\nDESCRIPTION\n-----------\nSimpleDS is a simple dialogue system trained with deep reinforcement learning. In contrast to other dialogue systems, this system selects dialogue actions directly from raw (noisy) text of the last system and user responses. The motivation is to train dialogue agents with as little human intervention as possible.\n\nThis system runs under a client-server architecture, where the learning agent (in JavaScript) acts as the \"server\" and the environment (in Java) acts as the \"client\". They communicate by exchanging messages, where the server tells the client the action to execute, and the client tells the server the actions available, environment state and reward observed. SimpleDS is based on [ConvNetJS](http://cs.stanford.edu/people/karpathy/convnetjs/), which implements the algorithm [`Deep Q-Learning with experience replay' (Mnih, et al. 2013)](http://arxiv.org/pdf/1312.5602v1.pdf). SimpleDS is a dialogue system on top of ConvNetJS with support for multi-threaded and client-server processing, and fast learning via constrained search spaces.\n\nThis system has been tested with simulated and real dialogues using the Google Speech Recogniser. It has also been tested in three different languages: English, German and Spanish. SimpleDS is for experimental purposes, represents work in progress, and is therefore released without any guarantees.\n\nSOFTWARE\n--------\nThis system was implemented and tested under Linux and Mac OS X with the following software -- though it should run in other operating systems with minor modifications.\n+ Ubuntu 14.10.4 / Mac OS X 10.10\n+ Java 1.8.0 or higher\n+ Ant 1.9.3 or higher\n+ Node 0.10.25 or higher\n+ Octave 3.8.0 or higher\n+ Android 4.4.3 (optional)\n\nDOWNLOAD\n--------\nYou can download the system directly from the command line:\n\n>git clone https://github.com/cuayahuitl/SimpleDS.git\n\nYou can also download the system as a zip file using the following URL, \nand then unzip it in your path of preference. \nhttps://github.com/cuayahuitl/SimpleDS/archive/master.zip \n\nCOMPILATION\n-----------\n>cd YourPath/SimpleDS\n\n>ant\n\nEXECUTION\n---------\n>cd YourPath/SimpleDS\n\n>scripts/run.sh train\n\n![Alt text](https://github.com/cuayahuitl/SimpleDS/blob/master/screenshots/Screenshot-SimpleDS-train.png \"Example screenshot of SimpleDS during training (Dialogues=2000, Verbose=false)\")\n\n>[From the command line, press Ctrl+C for termination]\n\nor \n\n>cd YourPath/SimpleDS\n\n>scripts/run.sh test\n\n![Alt text](https://github.com/cuayahuitl/SimpleDS/blob/master/screenshots/Screenshot-SimpleDS-test.png \"Example screenshot of SimpleDS at test time (Dialogues=1, Verbose=true)\")\n\n>[From the command line, press Ctrl+C for termination]\n\nAlternatively (recommended), you can run the system from two terminals:\n\nTerminal1:YourPath/SimpleDS>ant SimpleDS\n\nTerminal2:YourPath/SimpleDS/web/main>nodejs runclient.js (train|test) [num_dialogues] [-v|-nv]\n\nFor practical reasons, you can specify the number of dialogues and verbose mode from the command line. The values of these parameters would override the values specified in the file config.txt.\n\nThe outputs from the training phase consists in the learnt interaction policy (json file under the folder 'results/language'), and logged performance metrics (txt file under the 'results/language'). Depending on the config file, the metrics produce multiple rows with the following information: number of dialogues, average reward, epsilon value, number of actions per state, number of dialogues, and execution time (in hours). The outputs from the test phase are similar exept that no learnt policy is generated. In addition, executing the system in verbose mode would print out training/test dialogues -- according to the specified parameters.\n\nPLOTTING\n--------\nYou can visualise a learning curve of the SimpleDS agent according to number of learning steps in the x-axis and average reward + learning time in the y-axis. Learning curves can be generated for newly trained or pre-trained policies in the currently supported languages (English, German and Spanish).\n\n>cd YourPath/SimpleDS\n\n>octave scripts/plotdata.m results/english/simpleds-output.txt\n\n>[From the command line, press the space bar key for termination]\n\nor \n\n>cd YourPath/SimpleDS\n\n>octave scripts/plotdata.m results/english/simpleds-output.txt results/english/simpleds-output.png\n\n>[From the command line, press the space bar key for termination]\n\nThe latter generates an image of the plot in png (Portable Network Graphics) format. The file plotdata.m can also be used from Matlab if that software is prefered. The following learning curves (available from YourPath/results/*/*.png) can be obtained with the default parameters for the supported languages: [English](https://github.com/cuayahuitl/SimpleDS/blob/master/results/english/simpleds-output.png), [German](https://github.com/cuayahuitl/SimpleDS/blob/master/results/german/simpleds-output.png) and [Spanish](https://github.com/cuayahuitl/SimpleDS/blob/master/results/spanish/simpleds-output.png).\n\nCONFIGURATION\n-------------\nThe config file \"YourPath/SimpleDialogueSystem/config.txt\" has the following parameters:\n\nDialogues=Number of dialogues for training/test (positive integer)\n\nVerbose=Shows compressed information or detailed info (false or true)\n\nLanguage=Defines the (spoken) language to use (english, german, spanish)\n\nSysResponses=Path and file name of system responses (e.g. resources/SysResponses.txt)\n\nUsrResponses=Path and file name of system responses (e.g. resources/UsrResponses.txt)\n\nSlotValues=Slot-value pairs of the system (e.g. resources/SlotValues.txt)\n\nDemonstrationsPath=Path to the demonstration dialogues (e.g. data/)\n\nDemonstrationsFile=Pointer to training instances from demonstrations (models/demonstrations.arff)\n\nMinimumProbability=Minimum probability (>=0) for probable actions considered for action-selection\n\nSlotsToConfirm=Number of slots to confirm (positive integer, e.g. 3)\n\nOutputPath=The directory where the output files (policy and metrics) will be stored\n\nNoiseLevel=Scores under this level (<=0.2) would receive distorsion to model noisy recognition\n\nAddressPort=Address and port of the client socket (e.g. ws://localhost:8082/simpleds)\n\nSavingFrequency=This number defines the frequency for policiy/output saving (positive integer)\n\nNumInputs=This number defines the number of input nodes of the neural net (positive integer) \n\nNumActions=This number defines the number of actions of the agent (positive integer)\n\nLearningSteps=This number defines the number of time steps during learning (positive integer)\n\nExperienceSize=This number defines the size of the experience replay moemory (positive integer)\n\nBurningSteps=This number defines the time steps with random action selection (positive integer)\n\nDiscountFactor=This number defines gamma parameter also known as discount factor (real number)\n\nMinimumEpsilon=This number defines the minimum epsilon during learning (real number)\n\nBatchSize=This number defines the batch size (positive integer, e.g. 32 or 64)\n\nAndroidSupport=This variable is used to test dialogues with a real speech recogniser (true or false)\n\nSocketServerPort=This number defines the socket port used for communication with Android (positive integer)\n\nYou may want to set Verbose=false during training and Verbose=true during tests. You may also want to set a high number of dialogues during training (e.g. Dialogues=2000) and a low one during tests (e.g. Dialogues=1). You may want to change the system/user responses if you want different verbalisations. If this is the case, then you will also want to update the demonstration dialogues in the folder YourPath/SimpleDS/data/.\n\nCITATION\n--------\nPlease use the following reference if you use SimpleDS code or if you want to cite this work.\n\n@inproceedings{HC2016iwsds,\n\n  author    = {Heriberto Cuay\\'ahuitl},\n  \n  title     = {{SimpleDS}: A Simple Deep Reinforcement Learning Dialogue System},\n  \n  booktitle = {International Workshop on Spoken Dialogue Systems (IWSDS)},\n  \n  url       = {http://arxiv.org/abs/1601.04574},\n  \n  year      = {2016},\n  \n}\n\nSimpleDS has been applied to [Strategic Dialogue Management](http://arxiv.org/abs/1511.08099), and can be applied to other interactive systems in a fairly straightforward way. See [\"How to apply SimpleDS to interactive systems\"](https://github.com/cuayahuitl/SimpleDS/blob/master/doc/How2UseSimpleDS.txt).\n\nCOMMENTS/QUESTIONS/COLLABORATIONS?\n-------------------\nContact: [Heriberto Cuayahuitl](http://staff.lincoln.ac.uk/hcuayahuitl)\n\nEmail: h.cuayahuitl@gmail.com\n", 
  "description": "A Simple Deep Reinforcement Learning Dialogue System"
}