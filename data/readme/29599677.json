{
  "id": 29599677, 
  "read_at": 1462551613, 
  "README.rst": "===============================\nlangchangetrack\n===============================\n\n.. image:: https://badge.fury.io/py/langchangetrack.png\n    :target: http://badge.fury.io/py/langchangetrack\n\n.. image:: https://travis-ci.org/viveksck/langchangetrack.png?branch=master\n        :target: https://travis-ci.org/viveksck/langchangetrack\n\n.. image:: https://pypip.in/d/langchangetrack/badge.png\n        :target: https://pypi.python.org/pypi/langchangetrack\n        \n.. image:: https://github.com/viveksck/langchangetrack/blob/master/langchangetrack/images/gay_invisible.png\n\n\nPackage for Statistically Significant Language Change.\n\n* Free software: BSD license\n* Documentation: https://langchangetrack.readthedocs.org.\n\nFeatures\n--------\n\n* This package provides tools to detect linguistic change in temporal corpora. \n\n* The meta algorithm works in 2 main steps\n\n    #. **Time series construction**:Given a word, we construct a time series that tracks the displacement of a word through time. We track the displacement of a word using either Frequency, Part of Speech Distribution or Co-occurrences.\n\n    #. **Change point detection**: We then use change point detection methods to detect if the time series contains a change point and if so what the change point is.\n\nThe details of the above steps are outlined in : http://arxiv.org/abs/1411.3315\n\n\nVisualization Demo\n-------------------\n\nPlease see this for a cool visualization of words moving through time: http://tinyurl.com/wordvis\n\nUsage\n------\n    \nInput\n------\n\nWe assume a temporal corpus of text files (appropriately tokenized) to be present in a directory. In addition we assume list of words in a single text file that one is interested in tracking. \nThis could just be the set of words in the common vocabulary of the temporal corpus.\n\nOutput\n------\n\nThe output consists of the pvalues for each word indicating the significance of the changepoint detected.\n\nSample Usage\n------------\n``$ngrams_pipeline.py --corpus-dir data/temporal_corpus/ --file-extension \"ngrams\" --working-dir ./working --output-dir ./output --context-size 5 --epochs 3 --start-time-point 1900 --end-time-point 2000 --step-size 5 --vocabulary-file data/temporal_corpus/common_vocab.txt --workers 16``\n\n``$pos_pipeline.py --corpus-dir data/temporal_corpus/ --file-extension \"ngrams\" --working-dir ./working --output-dir ./output --start-time-point 1900 --end-time-point 1930 --step-size 5 --vocabulary-file data/temporal_corpus/common_vocab.txt --workers 16``\n\n``$freq_pipeline.py --corpus-dir data/temporal_corpus/ --file-extension \"ngrams\" --working-dir ./working --output-dir ./output --start-time-point 1900 --end-time-point 2000 --step-size 5 --vocabulary-file data/temporal_corpus/common_vocab.txt --workers 16``\n\n**You might need to tune the hyper parameters as per your specific need.**\n\nDetailed Usage\n---------------\n**Usage: ngrams_pipeline.py**\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --corpus-dir CORPUS_DIR\n                        Corpus directory\n  --file-extension EXT  Corpus file extension\n  --working-dir WORKING_DIR\n                        Working directory\n  --output-dir OUTPUT_DIR\n                        Output directory\n  --context-size WINDOW\n                        Context size to use for training embeddings\n  --epochs EPOCHS       Number of epochs to training embeddings\n  --start-time-point START\n                        Start time point\n  --end-time-point END  End time point\n  --step-size STEP      Step size for timepoints\n  --model-family MODEL_FAMILY\n                        Model family default (locallinear)\n  --number-nearest-neighbors KNN \n                        Number of nearest neighbors to use for mapping to\n                        joint space (default:1000)\n                          --vocabulary-file VOCAB_FILE\n                        Common vocabulary file\n  --threshold THRESHOLD\n                        Threshold for mean shift model for change point\n                        detection (default: 1.75)\n  --bootstrap-samples BOOTSTRAP\n                        Number of bootstrap samples to draw (default: 1000)\n  --workers WORKERS     Maximum number of workers (default: 1)\n  -l LOG, --log LOG     log verbosity level\n \n\n**Usage: pos_pipeline.py**\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --corpus-dir CORPUS_DIR\n                        Corpus directory\n  --file-extension EXT  Corpus file extension\n  --working-dir WORKING_DIR\n                        Working directory\n  --output-dir OUTPUT_DIR\n                        Output directory\n  --start-time-point START\n                        Start time point\n  --end-time-point END  End time point\n  --step-size STEP      Step size for timepoints\n  --vocabulary-file VOCAB_FILE\n                        Common vocabulary file\n  --threshold THRESHOLD\n                        Threshold for mean shift model for change point\n                        detection\n  --bootstrap-samples BOOTSTRAP\n                        Number of bootstrap samples to draw\n  --workers WORKERS     Maximum number of workers\n  -l LOG, --log LOG     log verbosity level\n  \n \n **usage: freq_pipeline.py**\n \noptional arguments:\n  -h, --help            show this help message and exit\n  --corpus-dir CORPUS_DIR\n                        Corpus directory\n  --file-extension EXT  Corpus file extension\n  --working-dir WORKING_DIR\n                        Working directory\n  --output-dir OUTPUT_DIR\n                        Output directory\n  --start-time-point START\n                        Start time point\n  --end-time-point END  End time point\n  --step-size STEP      Step size for timepoints\n  --vocabulary-file VOCAB_FILE\n                        Common vocabulary file\n  --threshold THRESHOLD\n                        Threshold for mean shift model for change point\n                        detection\n  --bootstrap-samples BOOTSTRAP\n                        Number of bootstrap samples to draw\n  --workers WORKERS     Maximum number of workers\n  -l LOG, --log LOG     log verbosity level\n\n\n\nRequirements\n------------\n* wheel==0.23.0\n* argparse>=1.2.1\n* numpy>=0.9.1\n* scipy>=0.15.1\n* more_itertools>=2.2\n* joblib>=0.8.3-r1\n* gensim==0.10.3\n* statsmodels>=0.5.0\n* changepoint>=0.1.0\n* nltk>=3.0.0\n* textblob>=0.9.0\n* textblob-aptagger>=0.2.0\n* psutil>=2.2.0\n* GNU Parallel\n* R (good to have)\n* rpy2 (good to have)\n\n\n\nInstallation\n------------\n#. Install GNU Parallel from here:  www.gnu.org/software/software.html\n#. cd langchangetrack\n#. pip install -r requirements.txt \n#. python setup.py install\n\n", 
  "description": "Package for Statistically significant linguistic change"
}