{
  "read_at": 1462550269, 
  "description": "Auralisation of learned features in CNN (for audio)", 
  "README.md": "# AuralisationCNN\nThis repo is for an example of auralisastion of CNNs that is demonstrated on ISMIR 2015.\n\n## Files\nauralise.py: includes all required function for deconvolution.\nexample.py: includes the whole code - just clone and run it by `python example.py`\nYou might need to use older version of Keras, e.g. [this](https://github.com/fchollet/keras/commit/06a1545645d974350d13425246eec53a08cb6ab8) (ver 0.3.x)\n\n## Folders\nsrc_songs: includes three songs that I used in my blog posting.\n\n## Usage\nLoad weights that you want to auralise. I'm using this function\n```W = load_weights()```\nto load my keras model, it can be anything else.\n`W` is a list of weights for the convnet. (TODO: more details)\n\nThen load source files, get STFT of it. I'm using `librosa`.\n\nThen deconve it with `get_deconve_mask`.\n\n## External links\n* [The second blog post](https://keunwoochoi.wordpress.com/2016/03/23/what-cnns-see-when-cnns-see-spectrograms/) has more extensive demo. Detailed description will follow after paper submission.\n* [The first blog post](http://keunwoochoi.blogspot.co.uk/2015/10/ismir-2015-lbd.html) that explains [my ISMIR 2015 Late-Breaking session paper](http://ismir2015.uma.es/LBD/LBD24.pdf).\n\n#### Credits\n* [Keras](https://github.com/fchollet/keras), [librosa](https://bmcfee.github.io/librosa/index.html), [Matt's deconvolution] paper(http://arxiv.org/abs/1311.2901), [Naver Labs](http://labs.naver.com)\n", 
  "id": 47410461
}