{
  "read_at": 1462550548, 
  "description": "collaborative topic modeling", 
  "README.md": "Reference\n---------\nP. Gopalan, L. Charlin, D.M. Blei, Content-based recommendations with Poisson factorization, In submission.\n\n\nInstallation\n------------\n\nRequired libraries: gsl, gslblas, pthread\n\nOn Linux/Unix run\n\n ./configure\n make; make install\n\n***Note: We have NOT tested the code on Mac. Please use Linux.***\n\nOn Mac OS, the location of the required gsl, gslblas and pthread\nlibraries may need to be specified:\n\n ./configure LDFLAGS=\"-L/opt/local/lib\" CPPFLAGS=\"-I/opt/local/include\"\n make; make install\n\nThe binary 'collabtm' will be installed in /usr/local/bin unless a\ndifferent prefix is provided to configure. (See INSTALL.)\n\nCOLLABTM: Nonnegative Collaborative Topic Modeling tool\n--------------------------------------------------------\n\n**collabtm** [OPTIONS]\n\n    -dir <string>            path to dataset directory with files described under INPUT below\n \n    -mdocs <int>\t     number of documents\n\n    -nuser <int>\t     number of users\n\n    -nvocab <int>\t     size of vocabulary\n    \t    \n    -k <int>                 latent dimensionality\n\n    -fixeda                  fix the document length correction factor ('a') to 1\n    \n    -lda-init                use LDA based initialization (see below)\n    \nOPTIONAL:    \n\n    -binary-data             treat observed ratings data as binary; if rating > 0 then rating is treated as 1\n\n    -doc-only                use document data only\n\n    -ratings-only            use ratings data only\n    \n    -content-only            use both data, but predict only with the topic affinities (i.e., topic offsets are 0)\n\nEXPERIMENTAL:\n\n    -online                  use stochastic variational inference\n    \n    -seq-init -doc-only\t     use sequential initialization for document only fits\n    \n    \n    \nRECOMMENDED\n-----------\n\nWe recommend running CTPF using the following options:\n\n~/src/collabtm -dir <path-to>/mendeley -nusers 80278 -ndocs 261248 -nvocab 10000 -k 100 -lda-init -fixeda\n\nIf the document lengths are expected to vary significantly, we recommend additionally running without the \"-fixeda\" option above.\n\nThe above options depend on LDA-based fits being available for the document portion of the model. See below.\n\nINPUT \n-----\n\nThe following files must be present in the data directory (as indicated by the\n'-dir' switch): \n\ntrain.tsv, test.tsv, validation.tsv, test_users.tsv\n\ntrain/valid/test files contain triplets in the following format (one per line): \nuserID itemID rating\n\nwhere tab characters separate the fields. \n\ntest_users.tsv contains the userIDs of all users that are tested on (one per\nline). \n\nThe new files additionally needed are mult.dat and vocab.dat.  (They are really text files.) This is the \"document\" portion of the data. Each line of mult.dat is a document and has the following format:\n\n     <number of words> <word-id0:count0> <word-id1:count1>....\n\nEach line of vocab.dat is a word. Note that both the word index and the document index starts at 0. So a word-id in vocab.dat can be 0 and the document id \"rated\" in train.tsv can be 0.\n\nEXAMPLE\n-------\n\nRun two versions -- with the correction scalar 'a' inferred and one with 'a' fixed at a 1.  One of these fits might be better than the other. The \"-fixeda\" option specifies that the documents are of similar lengths.\n\n***Always use LDA-based initialization.***\n\n~/src/collabtm -dir <path-to>/mendeley -nusers 80278 -ndocs 261248 -nvocab 10000 -k 100 -lda-init\n\n~/src/collabtm -dir <path-to>/mendeley -nusers 80278 -ndocs 261248 -nvocab 10000 -k 100 -fixeda -lda-init\n\n\nLDA BASED INITIALIZATION\n------------------------\n\n1. Run Chong's gibbs sampler to obtain LDA fits on the word frequencies\n(see below for details)\n\n2. Create a directory \"lda-fits\" within the \"dataset directory\" above and put\ntwo files in it: the topics beta-lda-k<K>.tsv and the memberships\ntheta-lda-k<K>.tsv.  If K=100, these files will be named beta-lda-k100.tsv and\ntheta-lda-k100.tsv, respectively.\n\n3. Run collabtm inference with the -lda-init option as follows (the -fixeda option fixes 'a' at 1):\n\n~/src/collabtm -dir <path-to>/mendeley -nusers 80278 -ndocs 261248 -nvocab 10000 -k 100 -lda-init\n\n~/src/collabtm -dir <path-to>/mendeley -nusers 80278 -ndocs 261248 -nvocab 10000 -k 100 -lda-init -fixeda\n\n\nCHONG's GIBBS SAMPLER\n---------------------\n\nThe LDA code is provided under the \"lda\" directory.\n\nFor example, run LDA with parameters\n    - 50 topics\n    - the topic Dirichlet set to 0.01\n    - the topic proportion Dirichlet set to 0.1\nas follows:\n\n./lda --directory fit_50/ --train_data ~/arxiv/dat/mult_lda.dat --num_topics 50 --eta 0.01 --alpha 0.1 --max_iter -1 --max_time -1\n\nmult_lda.dat contains the documents (see the David Blei's lda-c package for\nthe exact format: http://www.cs.princeton.edu/~blei/lda-c/index.html)\n\n***Note*** The values of eta and alpha need to reflect those used when loading the LDA fits \nin CTPF (see collabtm.cc:initialize()).\n\nThe output directory (\"fit_50/\" in the above example) will contain the fit files which \ncan be used to initialize CTPF with -lda-init option. Specifically *.topics corresponds \nto beta-lda-k<K>.tsv, and *.doc.states corresponds to theta-lda-k<K>.tsv.\n", 
  "id": 13530472
}