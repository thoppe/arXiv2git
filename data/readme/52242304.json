{
  "read_at": 1462557807, 
  "description": "", 
  "README.md": "# Cross Modal Distillation for Supervision Transfer\nSaurabh Gupta, Judy Hoffman, Jitendra Malik\n\nThis codebase allows use of RGB-D object detection models from this [arXiv tech report](http://arxiv.org/abs/1507.00448). \n\n### License\n\nThis code base is built on Fast R-CNN. License for Fast R-CNN can be found in LICENSE_fast_rcnn.\n\n### Citing \n\nIf you find this code base and models useful in your research, please consider citing an appropriate sub-set of the following papers:\n\n    @article{gupta2015cross,\n      title={Cross Modal Distillation for Supervision Transfer},\n      author={Gupta, Saurabh and Hoffman, Judy and Malik, Jitendra},\n      journal={arXiv preprint arXiv:1507.00448},\n      year={2015}\n    }\n\n    @incollection{gupta2014learning,\n      title={Learning rich features from RGB-D images for object detection and segmentation},\n      author={Gupta, Saurabh and Girshick, Ross and Arbel{\\'a}ez, Pablo and Malik, Jitendra},\n      booktitle={Computer Vision--ECCV 2014},\n      pages={345--360},\n      year={2014},\n      publisher={Springer}\n    }\n\n    @article{girshick15fastrcnn,\n        Author = {Ross Girshick},\n        Title = {Fast R-CNN},\n        Journal = {arXiv preprint arXiv:1504.08083},\n        Year = {2015}\n    }\n\n### Contents\n1. [Requirements: software](#requirements-software)\n2. [Requirements: hardware](#requirements-hardware)\n3. [Basic installation](#installation-sufficient-for-the-demo)\n\n### Requirements: software\n\n1. Requirements for `Caffe` and `pycaffe` (see: [Caffe installation instructions](http://caffe.berkeleyvision.org/installation.html))\n\n  **Note:** Caffe *must* be built with support for Python layers!\n\n  ```make\n  # In your Makefile.config, make sure to have this line uncommented\n  WITH_PYTHON_LAYER := 1\n  ```\n\n2. Python packages you might not have: `cython`, `python-opencv`, `easydict`\n\n### Requirements: hardware\n\n1. For training smaller networks (CaffeNet, VGG_CNN_M_1024) a good GPU (e.g., Titan, K20, K40, ...) with at least 3G of memory suffices\n2. For training with VGG16, you'll need a K40 (~11G of memory)\n\n### Installation (sufficient for the demo)\n\n1. Clone the repository\n  ```Shell\n  # Clone the python code\n  git clone git@github.com:s-gupta/fast-rcnn.git\n  ```\n  \n2. We'll call the directory that you cloned Fast R-CNN into `FRCN_ROOT`. Clone Caffe with roi_pooling_layers:\n\n    ```Shell\n    cd $FRCNN_ROOT\n    git clone https://github.com/rbgirshick/caffe-fast-rcnn.git caffe-fast-rcnn\n    cd caffe-fast-rcnn\n    # caffe-fast-rcnn needs to be on the fast-rcnn branch (or equivalent detached state).\n    git checkout fast-rcnn\n    ```\n    \n3. Build the Cython modules\n    ```Shell\n    cd $FRCN_ROOT/lib\n    make\n    ```\n    \n4. Build Caffe and pycaffe\n    ```Shell\n    cd $FRCN_ROOT/caffe-fast-rcnn\n    # Now follow the Caffe installation instructions here:\n    #   http://caffe.berkeleyvision.org/installation.html\n\n    # If you're experienced with Caffe and have all of the requirements installed\n    # and your Makefile.config in place, then simply do.\n    # Make sure caffe is built with PYTHON layers.\n    make -j8 && make pycaffe\n    ```\n    \n### Download models and data\n1. Download the NYUD2 data\n\n  ```Shell\n  cd $FRCN_ROOT\n  ./data/scripts/fetch_nyud2_data.sh\n  ```\n\t\n2. Download the NYUD2 MCG boxes\n\n  ```Shell\n  cd $FRCN_ROOT\n  ./data/scripts/fetch_nyud2_mcg_boxes.sh\n  ```\n\n3. Download the ImageNet and Supervision Transfer Models \n\n  ```Shell\n  cd $FRCN_ROOT\n  ./data/scripts/fetch_init_models.sh\n  ```\n\n4. Fetch NYUD2 Object Detector Models.\n\n  ```Shell\n  cd $FRCN_ROOT\n  ./outputs/scripts/fetch_nyud2_detectors.sh\n  ```\n\n### Usage\n\nLook at experiments/test_pretrained_models.sh and experiments/train_models.sh to use pretrained models and train your models yourself.\n# fast-rcnn-distillation\n", 
  "id": 52242304
}