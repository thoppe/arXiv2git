{
  "read_at": 1462509789, 
  "description": "OAI client for Elasticsearch", 
  "README.md": "![OAI-PMH](https://github.com/jprante/elasticsearch-oai/raw/master/src/site/resources/OA200.gif)\n\nImage Copyright (C) [OAI](http://www.openarchives.org/)\n\n# OAI Harvester for Elasticsearch [![Travis](https://travis-ci.org/jprante/elasticsearch-oai.png)](https://travis-ci.org/jprante/elasticsearch-oai)\n\nThe [Open Archives Initiative - Protocol for Metadata Harvesting (OAI-PMH)](http://www.openarchives.org/pmh/)\nclient allows to harvest metadata into Elasticsearch.\n\nThis application for Elasticsearch can run as a feeder in a standalone JVM, and connects to a remote cluster.\n\nIt harvests DC / XML / RDF formats from OAI data providers (OAI servers).\n\nA list of OAI servers can be found [here](http://www.openarchives.org/Register/BrowseSites)\nThe metadata is internally represented as resources, using Resource Description Framework (RDF) of\nthe W3C Semantic Web Initiative, before the resources are serialized into JSON for\nElasticsearch schema-less indexing.\n\n## Versions\n\n| Elasticsearch version    | Plugin     | Release date |\n| ------------------------ | -----------| -------------|\n| 2.1.0                    | 2.1.0.0    | Dec  2, 2015 |\n| 1.5.1                    | 1.5.1.0    | Apr 22, 2015 |\n| 1.2.1                    | 1.2.1.0    | Jun 10, 2014 |\n| 1.1.0                    | 1.1.0.0    | Apr 24, 2014 |\n| 1.1.0                    | 1.1.0.1    | May 10, 2014 |\n\n## Installation\n\n    mkdir -p lib bin\n    cd lib\n    curl -O 'xbib.org/repository/org/xbib/elasticsearch/plugin/elasticsearch-oai/2.1.0.0/elasticsearch-oai-2.1.0.0-standalone.jar'\n    cd ..\n    <create a bash feed.sh script in bin folder>\n    <add log4j2.xml to bin folder>\n    ./bin/feed.sh\n\n## Project docs\n\nThe Maven project site is available at\n[Github](http://jprante.github.io/elasticsearch-oai)\n\n## Issues\n\nAll feedback is welcome! If you find issues, please post them at\n[Github](https://github.com/jprante/elasticsearch-oai/issues)\n\n# Documentation\n\nA feeder is a standalone application that can push data into a remote Elasticsearch cluster and\nruns outside an Elasticsearch node. This push mode is similar to Logstash, which is a\ndata pipeline tool that can prepare event-based data for Elasticsearch.\n\nYou can create a feeder script for example for indexing the Arxiv repository:\n\n    ./bin/arxiv.sh\n\nwhere the shell script has the content::\n\n\n    #!/bin/bash\n\n    # cron?\n    tty -s\n    if [ \"$?\" -gt \"0\" ]\n    then\n        # assume this working dir in $HOME\n        cd $HOME/oai-tool\n        pwd=$(pwd)\n        bin=${pwd}/bin\n        lib=${pwd}/lib\n    else\n        pwd=\"$( cd -P \"$( dirname \"$0\" )\" && pwd )\"\n        bin=${pwd}/../bin\n        lib=${pwd}/../lib\n    fi\n\n    java=\"java\"\n\n    # arxiv.org is throttling to 20sec by HTTP Status 503 retry-after.\n    # concurrency should be 1.\n\n    echo '\n    {\n        \"uri\" : [\n            \"http://export.arxiv.org/oai2?verb=ListRecords&metadataPrefix=arXiv&from=2000-01-01&until=2016-01-01\"\n        ],\n        \"concurrency\" : 1,\n        \"elasticsearch\" : {\n            \"cluster\" : \"elasticsearch\",\n            \"host\" : \"localhost\",\n            \"port\" : 9300\n        },\n        \"index\" : \"arxiv\",\n        \"type\" : \"arxiv\",\n        \"maxbulkactions\" : 1000,\n        \"maxconcurrentbulkrequests\" : 1,\n        \"mock\" : true,\n        \"timewindow\" : \"yyyyMMddHH\",\n        \"aliases\" : true,\n        \"ignoreindexcreationerror\" : true\n\n    }\n    ' | ${java} \\\n        -cp ${lib}/\\*:${bin}/\\* \\\n        -Dlog4j.configurationFile=${bin}/log4j2.xml \\\n        org.xbib.tools.Runner \\\n        org.xbib.tools.OAIFeeder\n\n\nBefore running, please check where your Java 8 installation is located, and fix the ``java`` variable setting.\n\nMore examples can be found in the `bin` folder of the repository.\n\n## Logging\n\nThe logging can be controlled by the `log4j2.xml` file in the bin folder.\n\n## Parameters\n\n`uri` - a list of URLs for harvesting\n\n`concurrency` - how many URLs should be processed simultaneously\n\n`elasticsearch` - connection data for a node in an Elasticsearch cluster\n\n`index` - the name of the Elasticsearch index\n\n`type` - the name of the Elasticsearch index type\n\n`maxbulkactions` - the maximum number of actions in a bulk request\n\n`maxconcurrentbulkrequests` - the maximum number of concurrent bulk requests\n\n`mock` - set to `true` if harvested docs should not be indexed but logged instead\n\n`timewindow` - appendix for index name if date-stamp is wanted, like `yyyyMMddHH`\n\n`aliases` - set index aliases automatically\n\n `ignoreindexcreationerror` - if true, do not fail with error when index already exists\n\n## License\n\nElasticsearch OAI Harvester\n\nCopyright (C) 2014 J\u00f6rg Prante\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.", 
  "id": 4229204
}