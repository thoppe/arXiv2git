{
  "read_at": 1462559070, 
  "description": "An example application using Word2Vec. Given a list of words, it finds the one which isn't 'like' the others - a typical language understanding evaluation task.", 
  "README.md": "Example of using word2vec\n===========\n\nA common test of language competence is to identify a word which doesn't belong in a list with several other words. \n\nAs an example, in the list: car, boat, plane, train, microwave, all the words except microwave are modes of transportation, so the answer would be microwave.\n\nUntil recently, such a task would have been nearly impossible for a computer to solve without extreme effort on behalf of the programmer. A tool called word2vec [https://code.google.com/p/word2vec/] was released a few days ago, which allows for efficient computation of distributed representations of words as real-valued vectors. Feature vectors are learned by using recent advances in deep learning and neural networks, and have been shown to learn very rich representations of word meaning and usage. See this paper for more information on how the vector representations are learned: http://arxiv.org/pdf/1301.3781.pdf\n\nWith this new tool, it is possible to examine a range of previously difficult NLP tasks, one of which is identifying a word which doesn't belong in a list. This program demonstrates this capability. Some samples:\n\n->staple hammer saw drill\n\nI think staple doesnt belong in this list!\n\n->math shopping reading science\n\nI think shopping doesnt belong in this list!\n\n->rain snow sleet sun\n\nI think sun doesnt belong in this list!\n\n->eight six seven five three owe nine\n\nI think owe doesnt belong in this list!\n\n->breakfast cereal dinner lunch\n\nI think cereal doesnt belong in this list!\n\n->england spain france italy greece germany portugal australia\n\nI think australia doesnt belong in this list!\n\netc.\n\nThe vector representations were learned from 1GB of wikipedia text, which if I remember correctly amounted to about 100-200 million words. If you're looking to download and try it out, the file which holds the vectors is pretty large - about 500M. I chunked it up into smaller files so that GitHub would let me push.\n\nIf you decide to try it out, keep in mind that the longer the list, the better it will perform.\nFeel free to check it out, pull, modify, anything. word2vec is really an amazing tool which has the potential to make our NLP systems incredibly more intelligent!\n\nIf you want to see some visualizations of the representations, see the /visualizations directory. t-SNE was used to generate the 2D scatterplot.\n", 
  "id": 12199877
}