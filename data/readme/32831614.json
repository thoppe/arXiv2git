{
  "read_at": 1462544898, 
  "description": "RandomizED Singular Value Decomposition", 
  "README.md": "# redsvd\nRandomizED Singular Value Decomposition\n\nForked from:\nhttps://code.google.com/p/redsvd/\n\nOriginal author is:  \tDaisuke Okanohara\n\t\t\thttps://code.google.com/u/Daisuke.Okanohara/\n\nredsvd is a C++ library for solving several matrix decompositions including singular value decomposition (SVD), principal component analysis (PCA), and eigen value decomposition. redsvd can handle very large matrix efficiently, and optimized for a truncated SVD of sparse matrices. For example, redsvd can compute a truncated SVD with top 20 singular values for a 100K x 100K matrix with 1M nonzero entries in less than one second.\n\nThe algorithm is based on the randomized algorithm for computing large-scale SVD. Although it uses randomized matrices, the results is very accurate with very high probability.\n\nNicolas Tessore made a header only version of redsvd, which is useful for manys https://github.com/ntessore/redsvd-h\nHow to Use\nCurrently, redsvd is supported in Linux Ubuntu\n\nFirst, install eigen3 eigen3.0-beta1\n\nNext, download the latest tarball of redsvd from Downloads.\n\nFinally type the following commands.\n\n> tar xvjf redsvd-x.x.x.tar.bz2\n> cd redsvd-x.x.x\n> ./waf configure\n> ./waf\nsudo ./waf install\nNow the program redsvd is installed.\n\nIf you want to install redsvd in local environment, type the following commands.\n\n> tar xvjf redsvd-x.x.x.tar.bz2\n> cd redsvd-x.x.x\n> ./waf configure --prefix=\"/your/local/path\" \n>./waf \n./waf install\nYou can see the usage of redsvd by calling redsvd without options.\n\n>redsvd\nusage: redsvd --input=string --output=string [options] ...\n\nredsvd supports the following format types (one line for each row)\n\n[format=dense] (<value>+\\n)+\n[format=sparse] ((colum_id:value)+\\n)+\nExample:\n>redsvd -i imat -o omat -r 10 -f dense\ncompuate SVD for a dense matrix in imat and output omat.U omat.V, and omat.S\nwith the 10 largest eigen values/vectors\n>redsvd -i imat -o omat -r 3 -f sparse -m PCA\ncompuate PCA for a sparse matrix in imat and output omat.PC omat.SCORE\nwith the 3 largest principal components\n\noptions:\n  -i, --input     input file (string)\n  -o, --output    output file's prefix (string)\n  -r, --rank      rank       (int [=10])\n  -f, --format    format type (dense|sparse) See example.  (string [=dense])\n  -m, --method    method (SVD|PCA|SymEigen) (string [=SVD])\n> cat file1\n 1.0  2.0  3.0  4.0  5.0\n-2.0 -1.0  0.0  1.0  2.0\n 1.0 -2.0  3.0 -5.0  7.0\n> redsvd -i file1 -o file1 -r 2 -f 2\nread dense matrix from file1 ... 0.000102997 sec.\nSVD for a dense matrix\nrows:   3\ncols:   5\nrank:   2\ncompute SVD... -4.69685e-05 sec.\nwrite matrix to file1(.U|.S|.V) ... 0.018553 sec.\nfinished.\n> cat file1.U\n-0.372291 -0.926217\n-0.005434 -0.061765\n-0.928100 +0.371897\n> cat file1.V\n-0.411950 -0.186912\n-0.031819 -0.450366\n-0.441672 -0.257618\n+0.432198 -0.806197\n-0.668891 -0.214273\n> cat file1.S\n+9.176333\n+6.647099\nYou can also use a sparse matrix representation.\n\n> \n> cat news20.binary\n1:0.016563 3:0.016563 6:0.016563  ...\n...\n\n> redsvd -i news20.binary -o news20 -f 1 -r 10\nread sparse matrix from news20.binary ... 4.84901 sec.\n   rows:        19954\n   cols:        1355192\nnonzero:        9097916\n   rank:        10\ncompute SVD... 2.52615 sec.\nwrite matrix to news20(.U|.S|.V) ... 5.6056 sec.\nfinished.\n> cat news20.S\n+17.973207\n+2.556800\n+2.460566\n+2.135978\n+2.022737\n+1.931362\n+1.927033\n+1.853175\n+1.770231\n+1.764138\nExperimental Result\nSee the detailed result redsvd_result.pdf\n\nYou can reproduce these result by\n\n> performanceTest.sh\n> accuracyTest.sh\nEnvironment\nIntel(R) Core(TM)2 Quad CPU Q9550 @ 2.83GHz 8G\nFor dense matrices\nn\tm\trank\ttime (msec)\n500\t100\t10\t0.76\n500\t1000\t10\t3.24\n500\t10000\t10\t32.3\n500\t100000\t10\t306.3\nn\tm\trank\ttime (msec)\n500\t100\t100\t12.3\n500\t1000\t1000\t987.5\n500\t10000\t1000\t3850.0\n500\t100000\t1000\t32824.3\nn\tm\trank\ttime (msec)\n100\t100\t10\t0.20\n1000\t1000\t10\t6.34\n10000\t10000\t10\t578\nn\tm\trank\ttime (msec)\n100\t100\t500\t8.67\n1000\t1000\t500\t8654\n10000\t10000\t500\t45001\nFor sparse matrices\nn\tm\trank\tnonzero ratio (%)\ttime (msec)\n100\t100\t10\t0.1\t0.31\n1000\t1000\t10\t0.1\t1.17\n10000\t10000\t10\t0.1\t22.5\n100000\t100000\t10\t0.1\t1679.9\nn\tm\trank\tnonzero ratio (%)\ttime (msec)\n100\t100\t10\t1.0\t0.16\n1000\t1000\t10\t1.0\t2.0\n10000\t10000\t10\t1.0\t124.1\n100000\t100000\t10\t1.0\t12603.4\nLatent Semantic Analyasis (SVD for doc-term matrix) of English Wikipedia\nThe target rank is 10\n\n# doc\t# word\t# total words\ttime (msec)\n3560\t27106\t172823\t27\n46857\t147144\t2418406\t390\n118110\t261495\t6142438\t1073\n233717\t402239\t12026852\t1993\nInside of redsvd\nThe code redsvd.hpp is the core part of redsvd and self explanatory.\n\nLet A be a matrix to be analyzed with n rows and m columns, and r be the ranks of a truncated SVD (if you choose r = min(n, m), then this is the original SVD).\n\nFirst a random Gaussian matrix O with m rows and r columns is sampled and computes Y = At O. Then apply the Gram-Schmidt process to Y so that each column of Y is ortho-normalized. Then we compute B = AY with n rows and r columns. Although the size of Y is much smaller than that of A, Y holds the informatin of A; that is AYYt = A. Intuitively, the row informatin is compresed by Y and can be decompressed by Yt\n\nSimilarly, we take another random Gaussian matrix P with r rows and r columns, and compute Z = BP. As in the previous case, the columns of Z are ortho-normalized by the Gram-Schmidt process. ZZtt B = B. Then compute C = Zt B.\n\nFinally we compute SVD of C using the traditional SVD solver, and obtain C = USVt where U and V are orthonormal matrices, and S is the diagonal matrix whose entriesa are singular values. Since a matrix C is very small, this time is negligible.\n\nNow A is decomposed as A = AYYt = BYt = ZZtBYt = ZCYt = ZUSVtYt. Both ZU and YV are othornormal, and ZU is the left singular vectors and YV is the right singular vector. S is the diagonal matrix with singular values.\n\nThanks\nredsvd uses Eigen 3.0-beta1\nredsvd uses the algorithm based on the randomized algorithm described in the following paper.\nHowever, although the algorithm in redsvd samples both rows and columns, the original algorithm samples in one way (this would be because the performance analysis becomes complex).\n\n\"Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions\", N. Halko, P.G. Martinsson, J. Tropp, arXiv 0909.4061\nredsvd is developed in 20% project of Preferred Infrastructure(Japanese)\n\n", 
  "id": 32831614
}