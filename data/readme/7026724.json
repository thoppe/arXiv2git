{
  "read_at": 1462546516, 
  "README.org": "\n\n* mwumkl2\n\n  Latest code for MWU-MKL project.\n\n** Description\n\n   This code contains a native C++ implementation and\n   some python bindings aimed toward use with numpy and\n   scikit-learn, along with some older MATLAB bindings\n   (although I recommend using the newer python\n   interface).\n\n   You can find an arXiv preprint of the relevant paper\n   at: \n\n   http://arxiv.org/abs/1206.5580\n\n** Algorithm Overview\n\n   This algorithm is built by combining\n   - Arora & Kale's work on matrix multiplicative\n     weight updates for solving /semidefinite programs/\n     (SDPs) and\n   - Lanckriet et al.'s positive linear combination\n     formulation of the /multiple kernel learning/\n     problem; this can be expressed as a /quadratically\n     constrained quadratic program/ (QCQP), which can\n     be transformed into an SDP.\n\n   Arora & Kale's framework requires computing a\n   /matrix exponential/, which can be expensive unless\n   approximated. The beauty of our algorithm is that we\n   have a closed form of the exponential that takes\n   linear time in the number of input points to\n   compute. This is a huge win because now the\n   bottleneck lies in updating the scratch space, which\n   only takes $O(mn \\log(mn))$ time and $O(mn)$ space.\n\n** TODO List of todos: [0/2]\n   - [ ] Update for C++11\n   - [ ] Add parallel implementation (using a BSP\n     framework)\n\n** Parallel notes:\n\n*** Graph (BSP), vertex for every point\n    Hopefully is broadcast-capable and does not need to\n    be made into a clique; also possible to make a\n    \"broadcast node\" but hopefully there is no\n    \"bottlenecking\" effect in the underlying\n    implementation\n\n**** Constructs:\n     - primal_var: basically needs to be broadcast to\n       every vertex -- this is how the vertices update\n       their weights and get what they need for the\n       oracle\n     - is_pos, is_neg, entropy: utility funs\n     - oracle: this is an aggregation/reduction -- it\n       takes g and y values from each vertex and\n       produces the top g corresponding to +y and the\n       top g corresponding to -y. It produces the\n       corresponding vertices that maximize g for +/-\n       y.\n       - Idea: could probably implement two separate\n         aggreagators for this.\n       - if the maxima sum to less than -2, all\n         vertices should vote to finish and produce\n         failure.\n     - exponentiateM: another aggregation/reduction --\n       produces the primal variable\n     - scratch (Galpha/alGal): the complicated part of\n       the parallel version\n       - vertex computes its elements of each gram\n         column (+/-, for every kernel)\n       - produces an update for all the alGal that gets\n         aggregated and added to the old values\n       - maintains its own row of Galpha\n", 
  "description": "", 
  "id": 7026724
}