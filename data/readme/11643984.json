{
  "read_at": 1462556905, 
  "description": "Shotgun is a C++ parallel coordinate descent algorithm (standalone and Matlab MEX) for solving L1-regularized least squares and logistic regression problems. See http://arxiv.org/abs/1105.5379 ", 
  "README.md": " \n\n## REFERENCE  \nJoseph K. Bradley, Aapo Kyrola, Danny Bickson, and Carlos Guestrin (2011). \n\"Parallel Coordinate Descent for L1-Regularized Loss Minimization.\" \nInternational Conference on Machine Learning (ICML 2011).\nhttp://arxiv.org/abs/1105.5379\n\n## INSTALLATION  \n1) For running as a mex code called from Matlab\nJust run:\n```\n     make\n```\n\n2) For running as a C application, using MatrixMarket input format:\n```\n     make cversion_debug\n```\n    OR\n```\n     make cversion_release\n```\n\nCurrent build is only tested on Linux, so you might need to modify the Makefile\nto suit your system.\n\n\n\n## COST FUNCTION \nWe use the following cost function formulation. \nFor Lasso:\nargmin_x sum_i [(A_i*x - y_i)^2 + lambda * |x|_1]\nFor sparse logistic regression:\nargmin_x sum_i [-log(1 + exp(-y_i * x* A_i) ) + lambda * |x|_1]\n\nwhere |x|_1 is the first norm (sum of absolute value of the vector x).\n\n##  USAGE  \n\n1) \nDo not call the mex-library directly. Instead use the provided Matlab-scripts\nshotgun_logreg.m and shotgun_lasso.m.\n\nBoth have same signature:\n```cpp\n     shotgun_logreg(A,y,lambda)\n     shotgun_lasso(A,y,lambda)\n```\n\nThey return the optimized feature/weight-vector. For tuning the parameters, please\nmodify the scripts. A more user-friendly options-passing will be provided later.\n\nFor an example, see example/ directory.\n\n\n2) RUNNING AS A STANDALONE C PROGRAM:\nMatrix and vector files are mandaroty inputs\n```\nUsage: ./mm_lasso\n\t-m matrix A in sparse matrix market format\n\t -v vector y in sparse matrix market format\n\t -o output file name (will contain solution vector x, default is\nx.mtx)\n\t -a algorithm (1=lasso, 2=logitic regresion, 3 = find min lambda for\nall zero solution)\n\t -t convergence threshold (default 1e-5)\n\t -k solution path length (for lasso)\n\t -i  max_iter (default 100)\n\t -n num_threads (default 2)\n\t -l lammbda - positive weight constant (default 1)\n\t -V verbose: 1=verbose, 0=quiet (default 0) \n```\n\n## REMARKS \n\nProvided code is not exactly same as the one we used for running our experiments for\nthe ICML 2011 paper. Particularly this code runs slower *sequentially*, because special\ncode for running with only one cpu has been removed for clarity. Parallel code needs to do\nsome extra work compared to sequential algorithm, and therefore for fairness we had special\nversions for the sequential tests.\n\nThis version uses OpenMP for parallel execution. For the paper, we used CILK++. Since CILK\nis not as widely available as OpenMP, we decided to switch for the source code release.\n\n\n##  MORE INFO  \n\nThis code is is not well tested and you should not rely on it on any mission-critical tasks.\n\nFor bug-fixes or other questions, please contact Aapo Kyrola : akyrola@cs.cmu.edu or \nDanny Bickson: danny.bickson@gmail.com\n\n\n", 
  "id": 11643984
}