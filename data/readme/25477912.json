{
  "read_at": 1462511466, 
  "description": "upcoming distributed neural network using curated utterance-response data and word vector features", 
  "README.md": "[![project abstraction](http://img.youtube.com/vi/v9zJ9noLeok/0.jpg)](https://www.youtube.com/watch?v=v9zJ9noLeok)\n\n# NOTE\n\nPlease note that abstraction is a *project*, not a finished product.\n\n# setup\n\nThe following Bash commands, that have been tested on Ubuntu 15.10, should install prerequisites and check out abstraction.\n\n```Bash\n# Install ROOT.\nsudo apt-get -y install sqlite\nsudo apt-get -y install python-nltk\nsudo python -m nltk.downloader all\nsudo easy_install -U gensim\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\nsudo pip install git+git://github.com/google/skflow.git\nsudo pip install abstraction\ngit clone https://github.com/wdbm/abstraction.git\n```\n\nThe function `abstraction.setup()` should be run.\n\n# upcoming\n\nUnder consideration is a requirement for arcodex to ensure the existence of a response to an utterance before saving to database.\n\n# logging\n\nUpdating logging procedures is under consideration because of possible logging conflicts. It could be beneficial currently to run using Bash anonymous pipes, in a way like the following:\n\n```Bash\npython script.py 2> >(grep -E -v \"INFO|DEBUG\")\n```\n\n# data\n\n## feature scaling\n\nStandardization of datasets is a common requirement for many machine learning estimators implemented in the scikit; they might behave badly if the individual features do not more or less look like standard normally-distributed data: Gaussian with zero mean and unit variance -- often called a standard scores. Many machine learning algorithms assume that all features are centered around zero and have variance of the same order. A feature with a variance that is orders of magnitude larger that others might dominate the objective function and make the estimator unable to learn from other features. The scikit function `scale` provides a quick way to perform this operation on a single array-like dataset.\n\n## SUSY Data Set\n\n- <https://archive.ics.uci.edu/ml/datasets/SUSY>\n- <http://arxiv.org/abs/1402.4735>\n\nThe SUSY Data Set is a classification problem to distinguish between a signal process which produces supersymmetric particles and a background process which does not. In the data, the first column is the class label (1 for signal, 0 for background), followed by 18 features (8 low-level features and 10 high-level features):\n\n- lepton 1 pT\n- lepton 1 eta\n- lepton 1 phi\n- lepton 2 pT\n- lepton 2 eta\n- lepton 2 phi\n- missing energy magnitude\n- missing energy phi\n- MET_rel\n- axial MET\n- M_R\n- M_TR_2\n- R\n- MT2\n- S_R\n- M_Delta_R\n- dPhi_r_b\n- cos(theta_r1)\n\nThis data has been produced by MadGraph5 Monte Carlo simulations of 8 TeV proton collisions, with showering and hadronisation performed by Pythia 6 and detector response simulated by Delphes. The first 8 features are kinematic properties measured by simulated particle detectors. The next 10 features are functions of the first 8 features; they are high-level features derived by physicists to help discriminate between the two classes. There are 46% positive examples in the SUSY data set. The features were standardised over the entire training/testing sets with mean zero and standard deviation one, except for those features with values strictly greater than zero; these were scaled such that the mean value was one.\n\n# Caffe \n\n## introduction\n\nCaffe is a deep learning framework developed by the Berkeley Vision and Learning Center (BVLC) with cleanliness, readability and speed in mind. It has a clean architecture which enables rapid deployment. It is readable and modifiable, encouraging active development. It is a fast CNN implementation. It has command line, Python and MATLAB interfaces for day-to-day usage, interfacing with research code and rapid prototyping. While Caffe is essentially a C++ library, it has a modular interface for development with cmdcaffe, pycaffe and matcaffe.\n\nThe Caffe core software packages are as follows:\n\n- Caffe\n- CUDA\n- cuDNN\n- OpenBLAS\n- OpenCV\n- Boost\n\nCaffe other dependencies are as follows:\n\n- protobuf\n- google-glog\n- gflags\n- snappy\n- leveldb\n- lmdb\n- hdf5\n\nThe Caffe build tools are CMake and make.\n\n## command line\n\nThe command line interface cmdcaffe is a Caffe tool for model training, scoring and diagnostics. Run it without arguments for help. It is at directory `caffe/build/tools`.\n\n### train\n\n`caffe train` learns models from scratch, resumes learning from saved snapshots and fine-tunes models to new data and tasks. All training requires a solver configuration through the option `-solver solver.prototxt`. Resuming requires the option `snapshot model_item_1000.solverstate` argument to load the solver snapshot.\n\n```Bash\n# train LeNet\ncaffe train -solver examples/mnist/lenet_solver.prototxt\n# train on GPU 2\ncaffe train -solver examples/mnist/lenet_solver .prototxt -gpu 2\n```\n\n### test\n\n`caffe test` scores models by running them in the test phase and resport the network output as its score. The network architecture must be defined properly to output an accuracy measure or loss as its output. The per-batch score is reported and then the grand average is reported last.\n\n```Bash\n# score the learned LeNet model on the validation set\nas defined in the model architecture lenet_train_test.prototxt\ncaffe test - model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000 -gpu 0 -iterations 100\n```\n\n### benchmark\n\n`caffe time` benchmarks model execution layer-by-layer through timing and synchronisation. This is useful to check system performance and measure relative execution times for models.\n\n```Bash\n# time LeNet training on CPU for 10 iterations\ncaffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10\n# time LeNet training on GPU for the default 50 iterations\ncaffe time -model examples/mnist/lenet_train_test.prototxt - gpu 0\n```\n\n### diagnose\n\n`caffe device_query` reports GPU details for reference and checking device ordinals for running on a device in multi-GPU machines.\n\n```Bash\n# query the first device\ncaffe device_query -gpu 0\n```\n\n## pycaffe\n\nThe Python interface `pycaffe` is the caffe module and its scripts are at the directory `caffe/python`. Run `import caffe` to load models, do forward and backward, handle IO, visualise networks and instrument model-solving. All model data, derivatives and parameters are exposed for reading and writing.\n\n`caffe.Net` is the central interface for loading, configuring and running models. `caffe.Classifier` and `caffe.Detector` provide convenience interfaces for common tasks. `caffe.SGDSolver` exposes the solving interface. `caffe.io` handles input and output with preprocessing and protocol buffers. `caffe.draw` visualises network architectures. Caffe blobs are exposed as numpy ndarrays for ease-of-use and efficiency.\n\n## MATLAB\n\nThe MATLAB interface `matcaffe` is the Caffe MATLAB MEX file and its helper m-files are at the directory caffe/matlab. There is example code `caffe/matlab/caffe/matcaffe_demo.m`.\n\n## models\n\nThe directory structure of models is as follows:\n\n```Bash\n.\n+-- bvlc_alexnet\n|   +-- deploy.prototxt\n|   +-- readme.md\n|   +-- solver.prototxt\n|   +-- train_val.prototxt\n+-- bvlc_googlenet\n|   +-- bvlc_googlenet.caffemodel\n|   +-- deploy.prototxt\n|   +-- quick_solver.prototxt\n|   +-- readme.md\n|   +-- solver.prototxt\n|   +-- train_val.prototxt\n+-- bvlc_reference_caffenet\n|   +-- deploy.prototxt\n|   +-- readme.md\n|   +-- solver.prototxt\n|   +-- train_val.prototxt\n+-- bvlc_reference_rcnn_ilsvrc13\n|   +-- deploy.prototxt\n|   +-- readme.md\n+-- finetune_flickr_style\n    +-- deploy.prototxt\n    +-- readme.md\n    +-- solver.prototxt\n    +-- train_val.prototxt\n```\n\n## draw a graph of network architecture\n\n```Bash\n\"${CAFFE}\"/python/draw_net.py \"${CAFFE}\"/models/bvlc_googlenet/deploy.prototxt bvlc_googlenet_deploy.png\n```\n\n## setup\n\n```Bash\nsudo apt-get -y install libprotobuf-dev\nsudo apt-get -y install libleveldb-dev\nsudo apt-get -y install libsnappy-dev\nsudo apt-get -y install libopencv-dev\nsudo apt-get -y install libhdf5-dev\nsudo apt-get -y install libhdf5-serial-dev\nsudo apt-get -y install protobuf-compiler\nsudo apt-get -y install --no-install-recommends libboost-all-dev\nsudo apt-get -y install libatlas-base-dev\nsudo apt-get -y install python-dev\nsudo apt-get -y install libgflags-dev\nsudo apt-get -y install libgoogle-glog-dev\nsudo apt-get -y install liblmdb-dev\nsudo apt-get -y install python-pydot\n```\n\n```Bash\nsudo pip install protobuf\nsudo pip install scikit-image\n```\n\n```Bash\ncd\ngit clone https://github.com/BVLC/caffe.git\ncd caffe\ncp Makefile.config.example Makefile.config\n```\n\nEdit the makefile. Uncomment `CPU_ONLY := 1` for a non-GPU compilation (without CUDA). It may be necessary to include the following lines:\n\n```\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial\n```\n\n```Bash\ntime make all\ntime make test\ntime make runtest\ntime make pycaffe\n```\n\n```Bash\nPYTHONPATH=\"/home/\"${USER}\"/caffe/python:${PYTHONPATH}\"\nCAFFE=\"/home/\"${USER}\"/caffe\"\n```\n\nDownload Caffe models from the Model Zoo.\n\n- <http://caffe.berkeleyvision.org/model_zoo.html>\n- <https://github.com/BVLC/caffe/wiki/Model-Zoo>\n\n```Bash\n~/caffe/scripts/download_model_binary.py models/bvlc_googlenet\n```\n\n# Torch\n\n## setup\n\n```Bash\ncurl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash\ngit clone https://github.com/torch/distro.git ~/torch --recursive\ncd ~/torch; ./install.sh\n```\n\n# CPU versus GPU for deep learning\n\nRoelof Pieters set some benchmarks in 2015-07 for deep dreaming video processing using CPU and GPU hardware. The CPU hardware was Amazon EC2 g2.2xlarge Intel Xeon E5-2670 (Sandy Bridge) 8 cores 2.6 GHz/3.3 GHz turbo and the GPU hardware was Amazon EC2 g2.2xlarge 2 x 4 Gb GPU.\n\n|**input image resolution (pixels)**|**CPU processing time for 1 image**|**GPU processing time for 1 image**|**CPU processing time for 2 minute video**|**GPU processing time for 2 minute video**|\n|---|---|---|---|---|\n|540 x 360|45 s|1 s|1 d 21 h|60 minutes|\n|1024 x 768|144 s|3 s|6 d|3 h|\n\nSo, the GPU hardware was ~45 -- ~48 times faster than the CPU hardware.\n\n# introduction\n\nProject abstraction is a natural language processing project utilising curated conversation data as neural network training data.\n\n# bags of words, skip-grams and word vectors\n\nWord vectors are an efficient implementation of bag-of-words and skip-gram architectures for computing vector representations of words. These representations can be used in natural language processing applications and research.\n\nAn n-gram is a contiguous sequence of n items from a sequence of text or speech. The items can be phonemes, syllabels, letters, words or base pairs depending on the application. Skip-grams are a generalisation of n-grams in which the components (typically words) need not be consecutive in the text under consideration, but may have gaps that are skipped. They are one way of overcoming the data sparsity problem found in conventional n-gram analysis.\n\nFormally, an n-gram is a consecutive subsequence of length n of some sequence of tokens w_n. A k-skip-n-gram is a length-n subsequence in which components occur at a distance of at most k from each other. For example, in the text\n\n```\nthe rain in Spain falls mainly on the plain\n```\n\nthe set of 1-skip-2-grams includes all of the 2-grams and, in addition, the following sequences:\n\n```\nthe in,\nrain Spain,\nin falls,\nSpain mainly,\nmainly the,\non plain\n```\n\nIt has been demonstrated that skip-gram language models can be trained such that it is possible to perform 'word arithmetic'. For example, with an appropriate model, the expression `king - man + woman` evaluates to very close to `queen`.\n\n- \"Efficient Estimation of Word Representations in Vector Space\", Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean <http://arxiv.org/abs/1301.3781>\n\nThe bag-of-words model is a simplifying representation used in natural language processing. In this model, a text is represented as a bag (multiset -- a set in which members can appear more than once) of its words, disregarding grammar and word order but keeping multiplicity. The bag-of-words model is used commonly in methods of document classification, for which the frequency of occurrence of each word is used as a feature for training a classifier.\n\nWord vectors are continuous distributed representations of words. The tool word2vec takes a text corpus as input and produces word vectors as output. It constructs a vocabulary from the training text data and then learns vector representations of words. A word2vec model is formed by training on raw text. It records the context, or usage, of each word encoded as word vectors. The significance of a word vector is defined as its usefulness as an indicator of certain larger meanings or labels.\n\n# curated conversation data\n\nCurated conversation data sourced from Reddit is used for the conversation analysis and modelling. Specifically, conversational exchanges on Reddit are recorded. An exchange consists of an utterance and a response to the utterance, together with associated data, such as references and timestamps. A submission to Reddit is considered as an utterance and a comment on the submission is considered as a response to the utterance. The utterance is assumed to be of good quality and the response is assumed to be appropriate to the utterance based on the crowd-curated quality assessment inherent in Reddit.\n\n# translation with word vectors\n\nIn the paper [\"Exploiting Similarities among Languages for Machine Translation\"](http://arxiv.org/abs/1309.4168), Tomas Milokov describes how after training two monolingual modes, a translation matrix is generated on the most frequently occurring 5000 words. Using this translation matrix, the accuracy of the translations was tested on 1000 words. A description Milokov gave of the general procedure is as follows:\n\n- Create matrix `M` with dimensionality `I` times `O`, where `I` is the size of input vectors and `O` is the size of the output vectors.\n- Iterate over the training set several times with decreasing learning rate and update `M`.\n    - For each training sample, compute outputs by multiplying the input vector by `M`.\n    - Compute the gradient of the error (target vector - output vector).\n    - Update the weights in `M` (with reference to how the weights are updated between the hidden layer and the output layer in word2vec code).\n\n# abstraction code picture\n\n![](packages_abstraction.png)\n\n# module abstraction\n\nThe module abstraction contains functions used generally for project abstraction. Many of the programs of the project use its functions.\n\n# arcodex: archive collated exchanges\n\nThe program arcodex is a data collation and archiving program specialised to conversational exchanges. It can be used to archive to database exchanges on Reddit.\n\nThe following example accesses 2 utterances from the subreddit \"worldnews\" with verbosity:\n\n```Bash\narcodex.py --numberOfUtterances 2 --subreddits=worldnews --verbose\n```\n\nThe following example accesses 2 utterances from each of the subreddits \"changemyview\" and \"worldnews\" with verbosity:\n\n```Bash\narcodex.py --numberOfUtterances 2 --subreddits=changemyview,worldnews --verbose\n```\n\nThe following example accesses 30 utterances from all of the listed subreddits with verbosity:\n\n```Bash\narcodex.py --numberOfUtterances 30 --subreddits=askreddit,changemyview,lgbt,machinelearning,particlephysics,technology,worldnews --verbose\n```\n\nThe standard run 2014-10-28T202832Z is as follows:\n\n```Bash\narcodex.py --numberOfUtterances 200 --subreddits=askreddit,changemyview,lgbt,machinelearning,particlephysics,technology,worldnews --verbose\n```\n\n# vicodex: view collated exchanges\n\nThe program vicodex is a viewing program specialised to conversational exchanges. It can be used to access and view a database of exchanges.\n\nThe following example accesses database \"database.db\" and displays its exchanges data:\n\n```Bash\nvicodex.py --database=\"database.db\"\n```\n\n# inspect-database: quick printout of database\n\nThe program inspect-database provides a simple, comprehensive printout of the contents of a database. Specifically, for every table in the database it prints all of the column contents for every entry.\n\n```Bash\ninspect-database.py --database=\"database.db\"\n```\n\n# vcodex: word vectors \n\nThe program vcodex converts conversational exchanges in an abstraction database to word vector representations and adds or updates an abstraction database with these vectors.          \n\n```Bash\nvcodex.py --database=\"database.db\" --wordvectormodel=Brown_corpus.wvm\n```\n\nThe program vcodex increases the file size of abstraction database version 2015-01-06T172242Z by a factor of ~5.49. On an i7-5500U CPU running at 2.40 GHz, the conversion rate is ~25 exchanges per second.\n\n# reducodex: remove duplicate collated exchanges\n\nThe program reducodex inspects an existing database of conversational exchanges, removes duplicate entries, creates simplified identifiers for entries and then writes a new database of these entries.          \n\nThe following examples access database \"database.db\", remove duplicate entries, create simplified identifiers for entries and output database \"database_1.db\":\n\n```Bash\nreducodex.py --inputdatabase=\"database.db\"\n```\n\n```Bash\nreducodex.py --inputdatabase=\"database.db\" --outputdatabase=\"database_1.db\"\n```\n\n# abstraction development testing\n\n```Bash\n./arcodex.py --numberOfUtterances 10 --subreddits=askreddit,changemyview,lgbt,machinelearning,particlephysics,technology,worldnews --database=2015-10-12T1612Z.db --verbose\n```\n\n```Bash\n./vicodex.py --database=2015-10-12T1612Z.db\n```\n\n# saving models\n\nNote that the file `checkpoint` in the saved model directory contains full paths.\n", 
  "id": 25477912
}