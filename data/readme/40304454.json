{
  "read_at": 1462545624, 
  "description": "Places205-VGGNet models for scene recognition", 
  "README.md": "# VGGNets for Scene Recognition\n\nHere we release our trained VGGNet models on the large-scale Places205 dataset, called **Places205-VGGNet** models, from the following report:\n\nhttp://arxiv.org/abs/1508.01667\n\n    Places205-VGGNet Models for Scene Recognition\n    Limin Wang, Sheng Guo, Weilin Huang, and Yu Qiao, in arXive 1508.01667, 2015\n    \n#### Performance on the Places205 dataset\n\n|        Model        | top-1 val/test | top-5 val/test |\n|:-------------------:|:--------------:|:--------------:|\n| Places205-VGGNet-11 |    58.6/59.0   |    87.6/87.6   |\n| Places205-VGGNet-13 |    60.2/60.1   |    88.1/88.5   |\n| Places205-VGGNet-16 |    60.6/60.3   |    88.5/88.8   |\n| Places205-VGGNet-19 |    61.3/61.2   |    88.8/89.3   |\n\n\nWe use 5 crops and their horizontal flippings of each image for testing.\n\n#### Performance on the MIT67 and SUN397 dataset\n\n|        Model        | MIT67 | SUN397 |\n|:-------------------:|:-----:|:------:|\n| Places205-VGGNet-11 |  82.0 |  65.3  |\n| Places205-VGGNet-13 |  81.9 |  66.7  |\n| Places205-VGGNet-16 |  81.2 |  66.9  |\n\nWe extract the fc6-layer features of our trained Places205-VGGNet models, which are further normalized by L2-norm.\n\n#### Download\n- Places205-VGGNet-11: <br />\n  http://mmlab.siat.ac.cn/Places205-VGGNet/siat_scene_vgg_11.caffemodel\n- Places205-VGGNet-13: <br />\n  http://mmlab.siat.ac.cn/Places205-VGGNet/siat_scene_vgg_13.caffemodel\n- Places205-VGGNet-16: <br />\n  http://mmlab.siat.ac.cn/Places205-VGGNet/siat_scene_vgg_16.caffemodel\n- Places205-VGGNet-19: <br />\n  http://mmlab.siat.ac.cn/Places205-VGGNet/siat_scene_vgg_19.caffemodel\n- Mean file: <br />\n  http://mmlab.siat.ac.cn/Places205-VGGNet/places205_mean.mat\n\nThese models are relased for non-conmercial use. If you use these models in your research, thanks to cite our above report.\n\n#### Multi-GPU Implementation\n\nIn order to speed up the training procedure of VGGNets, we use a Multi-GPU extension of Caffe toolbox:\n\nhttps://github.com/yjxiong/caffe/tree/action_recog\n\nMeanwhile, we add the strategies of _multi-scale cropping_ and _corner cropping_ provided by this extension, which has been proved to be effective for action recognition in videos.\n\n#### Questions\nContact \n- [Limin Wang](http://wanglimin.github.io/)\n- [Sheng Guo] (mailto:sheng.guo@siat.ac.cn)\n- [Weilin Huang](http://www.wlhuang.com/)\n\n", 
  "id": 40304454
}