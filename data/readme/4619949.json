{
  "read_at": 1462546877, 
  "description": "Hogg's playground for understanding interferometry", 
  "README.md": "# Radio Array Model\n\nA playground to explore the probabilistic and inference properties of\nradio interferometry arrays.  The hope is to evolve into a system for\ncomputing likelihoods or posterior probabilities over scenes that\nexplain a set of radio interferometry data.\n\n### Authors: ###\n\n* [**David W. Hogg**](http://cosmo.nyu.edu/hogg/), New York University\n\n### License: ###\n\nCopyright 2012 the author.  **All rights reserved.**\n\nIf you have interest in using or re-using any of this content, get in\ntouch with Hogg.\n\n### Contributors: ###\n\n* **Frank Bigiel**, Universitat Heidelberg\n* **Brendon Brewer**, UC Santa Barbara\n* **Tom Herbst**, Max-Planck-Institut fur Astronomie\n* **Hans-Walter Rix**, Max-Planck-Institut fur Astronomie\n* **Fabian Walter**, Max-Planck-Institut fur Astronomie\n\n### Things to think about: ###\n\n* You have a faint blob in your cleaned image.  Is it significant?\n  Surely this is a question that should or could be answered in the\n  space of visibilities.\n\n* Can we write down a good noise model for visibilities; that is,\n  can we take things known about the antennae and correlator and\n  predict the magnitudes of the residuals in the visibilities away\n  from the best-fit \"true scene\" model (convolved with the dirty\n  beam)?\n\n* Related to the above, is it possible to project the scene inferred\n  by CLEAN back into the visibilities and test the noise model?\n\n* There are N radio telescopes and ~N^2 baselines; does this mean that\n  you can infer the phase delays you get from your phase calibrator\n  from the science data themselves?  That is, can you self-calibrate\n  always when N is large?\n\n* Related to the above, shouldn't we be marginalizing over the phase\n  calibration information, since (a) it is noisy and (b) it requires\n  interpolation between calibration measurements?\n\n* Bandwidth-smearing is something that needs to be a part of any real\n  generative model.  That is, we might be able to account for this in\n  a proper model.\n\n* Can we go \"fully probilistic\"?  Is it possible to return a posterior\n  PDF over scenes that could have created the data?\n\n* Should we be looking for and using interesting and astronomy-informed\n  prior information on the scene we infer?\n\n* Would a generative model help usefully with RFI identifcation and\n  elimination?\n\n### Related projects and bibliography: ###\n\n* **Peter Williams** (Berkeley) is developing Python code to do\n    analysis of interferometry data, with an emphasis on transient\n    science; see [arXiv:1203.0330](http://arxiv.org/abs/1203.0330)\n* **John Monnier** (Michigan) is working on sensible regularizers\n    (which are like priors, of course) for optical interferometry\n    problems.\n* **Sutton** and **Wandelt** (2006)\n    [Optimal image reconstruction in radio interferometry](http://arxiv.org/abs/astro-ph/0604331)\n    is close to the whole enchilada; includes likelihood function and sophisticated priors.\n    *This is the project to outperform or out-code.*\n* **Kemball** *et al* (2010)\n    [Further evaluation of bootstrap resampling as a tool for radio-interferometric imaging fidelity assessment](http://arxiv.org/abs/0911.2007)\n    looks at bootstrap methods to put uncertainties on radio maps generated from interferometry.\n", 
  "id": 4619949
}