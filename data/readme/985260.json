{
  "read_at": 1462543104, 
  "description": "Bayesian haplotype-based polymorphism discovery and genotyping.", 
  "README.md": "# *freebayes*, a haplotype-based variant detector\n## user manual and guide\n\n[![Build Status](https://travis-ci.org/ekg/freebayes.svg)](https://travis-ci.org/ekg/freebayes)\n[![Gitter](https://badges.gitter.im/Join Chat.svg)](https://gitter.im/ekg/freebayes?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n--------\n\n## Overview\n\n[*FreeBayes*](http://arxiv.org/abs/1207.3907) is a \n[Bayesian](http://en.wikipedia.org/wiki/Bayesian_inference) genetic variant \ndetector designed to find small polymorphisms, specifically SNPs \n(single-nucleotide polymorphisms), indels (insertions and deletions), MNPs \n(multi-nucleotide polymorphisms), and complex events (composite insertion and \nsubstitution events) smaller than the length of a short-read sequencing \nalignment.\n\n*FreeBayes* is haplotype-based, in the sense that it calls variants based on \nthe literal sequences of reads aligned to a particular target, not their \nprecise alignment.  This model is a straightforward generalization of previous \nones (e.g. PolyBayes, samtools, GATK) which detect or report variants based on \nalignments.  This method avoids one of the core problems with alignment-based \nvariant detection--- that identical sequences may have multiple possible \nalignments:\n\n<img src=\"http://hypervolu.me/freebayes/figures/haplotype_calling.png\" \nwidth=500/>\n\n*FreeBayes* uses short-read alignments \n([BAM](http://samtools.sourceforge.net/SAMv1.pdf) files with \n[Phred+33](http://en.wikipedia.org/wiki/Phred_quality_score) encoded quality \nscores, now standard) for any number of individuals from a population and a \n[reference genome](http://en.wikipedia.org/wiki/Reference_genome) (in \n[FASTA](http://en.wikipedia.org/wiki/FASTA_format) format)\nto determine the most-likely combination of genotypes for the population at \neach position in the reference.  It reports positions which it finds putatively \npolymorphic in variant call file ([VCF](http://www.1000genomes.org/node/101)) \nformat.  It can also use an input set of variants (VCF) as a source of prior \ninformation, and a copy number variant map (BED) to define non-uniform ploidy \nvariation across the samples under analysis.\n\n\n## Citing freebayes\n\nA preprint [Haplotype-based variant detection from short-read \nsequencing](http://arxiv.org/abs/1207.3907) provides an overview of the \nstatistical models\nused in FreeBayes.  We ask that you cite this paper if you use FreeBayes in\nwork that leads to publication.\n\nPlease use this citation format:\n\nGarrison E, Marth G. Haplotype-based variant detection from short-read sequencing.\n*arXiv preprint arXiv:1207.3907 [q-bio.GN]* 2012\n\nIf possible, please also refer to the version number provided by freebayes when \nit is run without arguments or with the `--help` option.  For example, you \nshould see something like this:\n\n    version:  v0.9.10-3-g47a713e\n\nThis provides both a point release number and a git commit id, which will \nensure precise reproducibility of results.\n\n\n## Obtaining\n\nTo download FreeBayes, please use git to download the most recent development\ntree.  Currently, the tree is hosted on github, and can be obtained via:\n\n    git clone --recursive git://github.com/ekg/freebayes.git\n\nNote the use of --recursive.  This is required in order to download all \nnested git submodules for external repositories.\n\n### Resolving proxy issues with git\n\nDepending on your local network configuration, you may have problems obtaining\nfreebayes via git.  If you see something like this you may be behind a proxy\nthat blocks access to standard git:// port (9418).\n\n    $ git clone --recursive git://github.com/ekg/freebayes.git\n    Cloning into 'freebayes'...\n    fatal: Unable to look up github.com (port 9418) (Name or service not known)\n\nLuckily, if you have access to https:// on port 443, then you can use this\n'magic' command as a workaround to enable download of the submodules:\n\n    git config --global url.https://github.com/.insteadOf git://github.com/\n\n\n## Compilation\n\nFreeBayes requires g++ and the standard C and C++ development libraries.\nAdditionally, cmake is required for building the BamTools API.\n\n    make\n\nWill build the executable freebayes, as well as the utilities bamfiltertech and \nbamleftalign.  These executables can be found in the `bin/` directory in the \nrepository.\n\nUsers may wish to install to e.g. /usr/local/bin (default), which is \naccomplished via\n\n    sudo make install\n\n\n## Usage\n\nIn its simplest operation, freebayes requires only two inputs: a FASTA reference\nsequence, and a BAM-format alignment file sorted by reference position.  For\ninstance:\n\n    freebayes --fasta-reference h.sapiens.fasta NA20504.bam\n\n... produce (on standard output) a VCF file on standard out describing\nall SNPs, INDELs, MNPs, and Complex events between the reference and the\nalignments in NA20504.bam.  In order to produce correct output, the reference\nsupplied must be the reference to which NA20504.bam was aligned.\n\nUsers may specify any number of BAM files on the command line.  FreeBayes uses \nthe [BamTools API](http://github.com/pezmaster31/bamtools) to open and parse \nthese files in parallel, virtually merging them at runtime into one logical \nfile with a merged header.\n\nFor a description of available command-line options and their defaults, run:\n\n    freebayes --help\n\n\n## Examples\n\nCall variants assuming a diploid sample:\n\n    freebayes -f ref.fa aln.bam >var.vcf\n\nRequire at least 5 supporting observations to consider a variant:\n\n    freebayes -f ref.fa -C 5 aln.bam >var.vcf\n\nUse a different ploidy:\n\n    freebayes -f ref.fa -p 4 aln.bam >var.vcf\n\nAssume a pooled sample with a known number of genome copies.  Note that this\nmeans that each sample identified in the BAM file is assumed to have 32 genome\ncopies.  When running with highh --ploidy settings, it may be required to set\n`--use-best-n-alleles` to a low number to limit memory usage.\n\n    freebayes -f ref.fa -p 32 --use-best-n-alleles 4 --pooled-discrete aln.bam >var.vcf\n\nGenerate frequency-based calls for all variants passing input thresholds. You'd do\nthis in the case that you didn't know the number of samples in the pool.\n\n    freebayes -f ref.fa -F 0.01 -C 1 --pooled-continuous aln.bam >var.vcf\n\nUse an input VCF (bgzipped + tabix indexed) to force calls at particular alleles:\n\n    freebayes -f ref.fa -@ in.vcf.gz aln.bam >var.vcf\n\nGenerate long haplotype calls over known variants:\n\n    freebayes -f ref.fa --haplotype-basis-alleles in.vcf.gz \\\n                        --haplotype-length 50 aln.bam\n\nNaive variant calling: simply annotate observation counts of SNPs and indels:\n\n    freebayes -f ref.fa --haplotype-length 0 --min-alternate-count 1 \\\n        --min-alternate-fraction 0 --pooled-continuous --report-monomorphic >var.vcf\n\nParallel operation (use 36 cores in this case):\n\n    freebayes-parallel <(fasta_generate_regions.py ref.fa.fai 100000) 36 \\\n        -f ref.fa aln.bam >var.vcf\n\nNote that any of the above examples can be made parallel by using the\nscripts/freebayes-parallel script.  If you find freebayes to be slow, you\nshould probably be running it in parallel using this script to run on a single\nhost, or generating a series of scripts, one per region, and run them on a\ncluster.\n\n\n## Calling variants: from fastq to VCF\n\nYou've sequenced some samples.  You have a reference genome or assembled set of \ncontigs, and you'd like to determine reference-relative variants in your \nsamples.  You can use freebayes to detect the variants, following these steps:\n\n* **Align** your reads to a suitable reference (e.g. with \n[bwa](http://bio-bwa.sourceforge.net/) or \n[MOSAIK](https://github.com/wanpinglee/MOSAIK))\n* Ensure your alignments have **read groups** attached so their sample may be \nidentified by freebayes.  Aligners allow you to do this, but you can also use \n[bamaddrg](http://github.com/ekg/bamaddrg) to do so post-alignment.\n* **Sort** the alignments (e.g. bamtools sort).\n* **Mark duplicates**, for instance with [samtools \nrmdup](http://samtools.sourceforge.net/) (if PCR was used in the preparation of \nyour sequencing library)\n* ***Run freebayes*** on all your alignment data simultaneously, generating a \nVCF.  The default settings should work for most use cases, but if your samples \nare not diploid, set the `--ploidy` and adjust the `--min-alternate-fraction` \nsuitably.\n* **Filter** the output e.g. using reported QUAL and/or depth (DP) or \nobservation count (AO).\n* **Interpret** your results.\n* (possibly, **Iterate** the variant detection process in response to insight \ngained from your interpretation)\n\nFreeBayes emits a standard VCF 4.1 output stream.  This format is designed for the\nprobabilistic description of allelic variants within a population of samples,\nbut it is equally suited to describing the probability of variation in a single\nsample.\n\nOf primary interest to most users is the QUAL field, which estimates the\nprobability that there is a polymorphism at the loci described by the record.\nIn freebayes, this value can be understood as 1 - P(locus is homozygous given\nthe data).  It is recommended that users use this value to filter their\nresults, rather than accepting anything output by freebayes as ground truth.\n\nBy default, records are output even if they have very low probability of\nvariation, in expectation that the VCF will be filtered using tools such as\n[vcffilter](http://github.com/ekg/vcflib#vcffilter) in \n[vcflib](http://github.com/ekg/vcflib), which is also included in the \nrepository under `vcflib/`.  For instance,\n\n    freebayes -f ref.fa aln.bam | vcffilter -f \"QUAL > 20\" >results.vcf\n\nremoves any sites with estimated probability of not being polymorphic less than \nphred 20 (aka 0.01), or probability of polymorphism &gt; 0.99.\n\nIn simulation, the [receiver-operator \ncharacteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n (ROC) tends to have a very sharp inflection between Q1 and Q30, depending on \ninput data characteristics, and a filter setting in this range should provide \ndecent performance.  Users are encouraged to examine their output and both \nvariants which are retained and those they filter out.  Most problems tend to \noccur in low-depth areas, and so users may wish to remove these as well, which \ncan also be done by filtering on the DP flag.\n\n\n## Calling variants in a population\n\nFreeBayes is designed to be run on many individuals from the same population\n(e.g. many human individuals) simultaneously.  The algorithm exploits a neutral\nmodel of allele diffusion to impute most-confident genotypings\nacross the entire population.  In practice, the discriminant power of the \nmethod will improve if you run multiple samples simultaneously.  In other \nwords, if your\nstudy has multiple individuals, you should run freebayes against them at the\nsame time.  This also ensures consistent reporting of information about \nevidence for all samples at any locus where any are apparently polymorphic.\n\nTo call variants in a population of samples, each alignment must have a read\ngroup identifier attached to it (RG tag), and the header of the BAM file in\nwhich it resides must map the RG tags to sample names (SM).  Furthermore, read\ngroup IDs must be unique across all the files used in the analysis.  One read\ngroup cannot map to multiple samples.  The reason this is required is that\nfreebayes operates on a virtually merged BAM stream provided by the BamTools\nAPI.  If merging the files in your analysis using bamtools merge would generate\na file in which multiple samples map to the same RG, the files are not suitable\nfor use in population calling, and they must be modified.\n\nUsers may add RG tags to BAM files which were generated without this\ninformation by using (as mentioned in \"Calling variants\" above) \n[bamaddrg](http://github.com/ekg/bamaddrg).\nIf you have many files corresponding to\nmany individuals, add a unique read group and sample name to each, and then\nopen them all simultaneously with freebayes.  The VCF output will have one\ncolumn per sample in the input.\n\n\n## Performance tuning\n\nIf you find freebayes to be slow, or use large amounts of memory, consider the\nfollowing options:\n\n- Set `--use-best-n-alleles 4`: this will reduce the number of alleles that are\n  considered, which will decrease runtime at the cost of sensitivity to\nlower-frequency alleles at multiallelic loci.  Calculating site qualities\nrequires O(samples\\*genotypes) runtime, and the number of genotypes is\nexponential in ploidy and the number of alleles that are considered, so this is\nvery important when working with high ploidy samples (and also\n`--pooled-discrete`). By default, freebayes puts no limit on this.\n\n- Remove `--genotype-qualities`: calculating genotype qualities requires\n  O(samples\\*genotypes) memory.\n\n- Set higher input thresholds. Require that N reads in one sample support an\n  allele in order to consider it: `--min-alternate-count N`, or that the allele\nfraction in one sample is M: `--min-alternate-fraction M`. This will filter\nnoisy alleles.  The defaults, `--min-alternate-count 2 --min-alternate-fraction\n0.2`, are most-suitable for diploid, moderate-to-high depth samples, and should\nbe changed when working with different ploidy samples. Alternatively,\n`--min-alternate-qsum` can be used to set a specific quality sum, which may be\nmore flexible than setting a hard count on the number of observations.\n\n\n## Observation filters and qualities\n\n### Input filters\nFreeBayes filters its input so as to ignore low-confidence alignments and\nalleles which are only supported by low-quality sequencing observations (see\n`--min-mapping-quality` and `--min-base-quality`).  It also will only evaluate a\nposition if at least one read has mapping quality of\n`--min-supporting-mapping-quality` and one allele has quality of at least\n`--min-supporting-base-quality`.\n\nReads with more than a fixed number of high-quality mismatches can be excluded\nby specifying `--read-mismatch-limit`.  This is meant as a workaround when \nmapping quality estimates are not appropriately calibrated.\n\nReads marked as duplicates in the BAM file are ignored, but this can be \ndisabled for testing purposes by providing `--use-duplicate-reads`.  FreeBayes \ndoes not mark duplicates on its own, you must use another process to do this.\n\n### Observation thresholds\nAs a guard against spurious variation caused by sequencing artifacts, positions\nare skipped when no more than `--min-alternate-count` or \n`--min-alternate-fraction`\nnon-clonal observations of an alternate are found in one sample.  These default \nto 2 and 0.2 respectively.  The default setting of `--min-alternate-fraction \n0.2` is suitable for diploid samples but should be changed for ploidy > 2.\n\n### Allele type exclusion\nFreeBayes provides a few methods to ignore certain classes of allele, e.g. \n`--no-indels` and `--no-mnps`.  Users are *strongly cautioned against using \nthese*, because removing this information is very likely to reduce detection \npower.  To generate a report only including SNPs, use vcffilter post-call as \nsuch:\n\n    freebayes ... | vcffilter -f \"TYPE = snp\"\n\n### Observation qualities\n\nFreeBayes estimates observation quality using several simple heuristics based \non manipulations of the phred-scaled base qualities:\n\n* For single-base observations, *mismatches* and *reference observations*: the \nun-adjusted base quality provided in the BAM alignment record.\n* For *insertions*: the mean quality of the bases inside of the putatively \ninserted sequence.\n* For *deletions*: the mean quality of the bases flanking the putatively \ndeleted sequence.\n* For *haplotypes*: the mean quality of allele observations within the \nhaplotype.\n\n### Effective base depth\n\nBy default, filters are left completely open.\nUse `--experimental-gls` if you would like to integrate both base and mapping \nquality are into the reported site quality (QUAL in the VCF) and \ngenotype quality (GQ, when supplying `--genotype-qualities`).  This integration \nis driven by the \"Effective Base Depth\" metric first developed in \n[snpTools](http://www.hgsc.bcm.edu/software/snptools), which scales observation \nquality by mapping quality.  When `--experimental-gls` is given, *P(Obs|Genotype) ~ \nP(MappedCorrectly(Obs))P(SequencedCorrectly(Obs))*.\n\n\n## Stream processing\n\nFreeBayes can read BAM from standard input `--stdin` instead of directly from\nfiles.  This allows the application of any number of streaming BAM filters and\ncalibrators to its input.\n\n    bam_merger.sh | streaming_filter_or_process.sh | freebayes --stdin ...\n\nThis pattern allows the adjustment of alignments without rewriting BAM files, \nwhich could be expensive depending on context and available storage.  A prime \nexample of this would be graph-based realignment of reads to known variants as \nimplemented in [glia](http://github.com/ekg/glia).\n\nUsing this pattern, you can filter out reads with certain criteria using\nbamtools filter without having to modify the input BAM file.  You can also use\nthe bamtools API to write your own custom filters in C++.  An example filter is\nbamfiltertech \n[src/bamfiltertech.cpp](http://github.com/ekg/freebayes/blob/master/src/bamfilte\nrtech.cpp), which could be used to filter out\ntechnologies which have characteristic errors which may frustrate certain types\nof variant detection.\n\n## INDELs\n\nIn principle, any gapped aligner which is sensitive to indels will\nproduce satisfactory input for use by freebayes.  Due to potential ambiguity, \nindels are\nnot parsed when they overlap the beginning or end of alignment boundaries.\n\nWhen calling indels, it is important to homogenize the positional distribution\nof insertions and deletions in the input by using left realignment.  This is \nnow done automatically by freebayes, but the behavior can be turned off via \n`--dont-left-align-indels` flag.  You probably don't want to do this.\n\nLeft realignment will place all indels in homopolymer and microsatellite\nrepeats at the same position, provided that doing so does not introduce\nmismatches between the read and reference other than the indel.  This method \ncomputationally inexpensive and handles the most common classes of alignment \ninconsistency.\n\n## Haplotype calls\n\nAs freebayes is haplotype-based, left-alignment is necessary only for the \ndetermination of candidate polymorphic loci.  Once such loci are determined, \nhaplotype observations are extracted from reads where:\n\n1. putative variants lie within `--haplotype-window` bases of each other \n(default 3bp),\n2. the reference sequence has repeats (e.g. microsatellites or STRs are called \nas one haplotype),\n3. the haplotype which is called has Shannon entropy less than \n`--min-repeat-entropy`, which is off by default but can be set to ~1 for \noptimal genotyping of indels in lower-complexity sequence.\n\nAfter a haplotype window is determined by greedily expanding the window across \noverlapping haplotype observations, all reads overlapping the window are used \nto establish data likelihoods, *P(Observations|Genotype)*, for all haplotypes \nwhich have sufficient support to pass the input filters.\n\nPartial observations are considered to support those haplotypes which they \ncould match exactly.  For expedience, only haplotypes which are contiguously \nobserved by the reads are considered as putative alleles in this process.  This \ndiffers from other haplotype-based methods, such as \n[Platypus](http://www.well.ox.ac.uk/platypus), which consider all possible \nhaplotypes composed of observed component alleles (SNPs, indels) in a given \nregion when generating likelihoods.\n\nThe primary adantages of this approach are conceptual simplicity and \nperformance, and it is primarily limited in the case of short reads, an issue \nthat is mitigated by increasing read lengths.  Also, a hybrid approach must be \nused to call haplotypes from high-error rate long reads.\n\n### Re-genotyping known variants and calling long haplotypes\n\nFor longer reads with higher error rates, it is possible to generate long \nhaplotypes in two passes over the data.  For instance, if we had very long \nreads (e.g. >10kb) at moderate depth and high error rate (>5%) such as might be \nproduced by PacBio, we could do something like:\n\n    freebayes -f ref.fa aln.bam | vcffilter -f \"QUAL > 20\" >vars.vcf\n\n... thus generating candidate variants of suitable quality using the default \ndetection window.  We can then use these as \"basis alleles\" for the observation \nof haplotypes, considering all other putative variants supported by the \nalignment to be sequencing errors:\n\n    freebayes -f ref.fa --haplotype-window 500 \\\n        --haplotype-basis-alleles vars.vcf aln.bam >haps.vcf\n\nThese steps should allow us to read long haplotypes directly from input data \nwith high error rates.\n\nThe high error rate means that beyond a small window each read will contain a \ncompletely different literal haplotype.  To a point, this property improves our \nsignal to noise ratio and can effectively filter out sequencing errors at the \npoint of the input filters, but it also decreases the effective observation \ndepth will prevent the generation of any calls if a long `--haplotype-window` \nis combined with high a sequencing error rate.\n\n\n## Best practices and design philosophy\n\nFreeBayes follows the patterns suggested by the [Unix \nphilosophy](https://en.wikipedia.org/wiki/Unix_philosophy), which promotes the \ndevelopment of simple, modular systems that perform a single function, and can \nbe combined into more complex systems using stream processing of common \ninterchange formats.\n\nFreeBayes incorporates a number of features in order to reduce the complexity \nof variant detection for researchers and developers:\n\n* **Indel realignment is accomplished internally** using a read-independent \nmethod, and issues resulting from discordant alignments are dramatically \nreducedy through the direct detection of haplotypes.\n* The need for **base quality recalibration is avoided** through the direct \ndetection of haplotypes. Sequencing platform errors tend to cluster (e.g. at \nthe ends of reads), and generate unique, non-repeating haplotypes at a given \nlocus.\n* **Variant quality recalibration is avoided** by incorporating a number of \nmetrics, such as read placement bias and allele balance, directly into the \nBayesian model.  (Our upcoming publication will discuss this in more detail.)\n\nA minimal pre-processing pipeline similar to that described in \"Calling \nvariants\" should be sufficient for most uses.  For more information, please \nrefer to a recent post by Brad Chapman [on minimal BAM preprocessing \nmethods](http://bcbio.wordpress.com/2013/10/21/updated-comparison-of-variant-detection-methods-ensemble-freebayes-and-minimal-bam-preparation-pipelines/).\n\nFor a push-button solution to variant detection, from reads to variant calls, \nlook no further than the [gkno genome analysis platform](http://gkno.me/).\n\n## Contributors\n\nFreeBayes is made by:\n\n- Erik Garrison \n- Thomas Sibley \n- Dillon Lee \n- Patrick Marks \n- Noah Spies \n- Joshua Randall \n- Jeremy Anderson\n\n## Support\n\n### email\n\nPlease report any issues or questions to the [freebayes mailing \nlist](https://groups.google.com/forum/#!forum/freebayes), [freebayes issue \ntracker](https://github.com/ekg/freebayes/issues), or by email to \n<erik.garrison@gmail.com>.\n\n### IRC\n\nIf you would like to chat real-time about freebayes, join #freebayes on\nfreenode. A gittr.im chat is also available.\n\n### reversion\n\nNote that if you encounter issues with the development HEAD and you would like \na quick workaround for an issue that is likely to have been reintroduced \nrecently, you can use `git checkout` to step back a few revisions.\n\n    git checkout [git-commit-id]\n\nIt will also help with debugging to know if a problem has arisen in recent \ncommits!\n", 
  "id": 985260
}