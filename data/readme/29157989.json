{
  "read_at": 1462551765, 
  "description": "Experiments with memory performance", 
  "README.md": "# HPC Performance Analysis - Memory\n\nThis repository will be used for experiments with memory performance.\n\nModern CPU architectures have several levels of cache, each with different semantics.\n\n## Experiments\n\n### Day 1: 2015-01-12\n\n#### 0. Setup and clone\n\nCreate a GitHub account, clone this repository, and configure your Git environment\n\n    git clone https://yourname@github.com/CUBoulder-HPCPerfAnalysis/memory.git\n    git config --global user.name 'Your Name'\n    git config --global user.email your.email@colorado.edu\n\nFeel free to use SSH instead on HTTPS.\nIf you use bash, I recommend downloading and sourcing [git-prompt](https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh) and [git-completion.bash](https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash).\nGit resources:\n\n* [Official Git Documentation](http://git-scm.com/documentation)\n* [Git for Computer Scientists](http://eagain.net/articles/git-for-computer-scientists/)\n* [Learn Git Branching (interactive)](https://pcottle.github.io/learnGitBranching/)\n* https://try.github.io/\n* [Interactive Cheat Sheet](http://ndpsoftware.com/git-cheatsheet.html)\n\n#### 1. Compile and run the included [STREAM benchmark](http://www.cs.virginia.edu/stream/).\n\n    make CC=gcc CFLAGS='-O3 -march=native' stream\n    ./stream\n\n#### 2. Add Dot to the results\n\nImplement a \"dot product\" test (x [?] y = sum_i x_i y_i) and commit your changes.\n\n#### 3. Create a CSV file at `results/yourname.csv` with the format\n\n```\n    # Username, Machinename, CPU name, CPU GHz, CPU Cores, CPU Cores used, Private cache/core (MB), Shared cache (MB), Array Length (MB), Peak MB/s, Copy MB/s, Scale MB/s, Add MB/s, Triad MB/s, Dot MB/s\n    jed, batura, i7-4500U, 1.8, 2, 1, 0.256, 4.096, 76.3, 25600, 19555, 12784, 13483, 13677, ?\n    ...\n```\n\nReport the \"best rate\".\nOn Linux systems, look in `/proc/cpuinfo`.\nFor theoretical peak bandwidth, try http://ark.intel.com.\nLeave a `?` for missing data (but try not to have missing data).\nCommit this new file:\n\n    git add results/yourname.csv\n    git commit\n\nUse the commit message to explain your workflow creating the results file.\nWe're going to add more tests in the future, so automation would be good here (collaboration encouraged).\n\n#### 4. Submit your changes as a pull request\n\nMake a GitHub Fork [this repository](https://github.com/CUBoulder-HPCPerfAnalysis/memory/fork) on GitHub, push changes to your fork, and submit a pull request to the main repository.\n\n#### 5. Open issues\nThere may be ambiguities in the specification.\nIf you spot any, [open an issue](https://github.com/CUBoulder-HPCPerfAnalysis/memory/issues).\nAlso open issues for ways to improve the workflow and provenance for running experiments and reporting data.\n\n### Day 2: 2015-01-14\n\n#### 0. Postmortem from Day 1\n\n* How machine-readable is our data?\n* Is all our data accurate?\n* Are these results reproducible?\n  * Did everyone use the same compiler?\n  * Same compilation flags?  (Do compilation flags matter?)\n  * Was anything else running?\n* How well do humans follow instructions?\n  * How much can we automate?\n\n#### 1. Visualizing data\n\nIt is useful to have a modern statistical environment for analyzing and plotting data.\nThe [R Project](http://www.r-project.org/) is a widely used open source statistical package that compares well with commercial packages and has a great user repository (new statistical methods tend to show up here first).\nUnfortunately, the R language has some shortcomings and is not general purpose.\n[Pandas](http://pandas.pydata.org/) is an up-and-coming Python package that provides a \"data frame\", a suite of common statistical tools, and plotting similar to R.\nI recommend Pandas for this class, but welcome you to use any package you feel comfortable with.\nExperiment with plotting interesting relationships using the `stream-analyze.py` script.\nThe [Pandas visualization documentation](http://pandas.pydata.org/pandas-docs/stable/visualization.html) may be useful, as is the [IPython interpreter](http://ipython.org/).\n\n#### 2. Effect of non-contiguous access\n\nPrefetchers like to follow contiguous memory streams.\nWhat happens to performance if we interleave threads?\nThe block-cyclic mapping of the range `0,1,...,N-1` defined by `j(i) = (i*b)%N + (i*b)//N` may be useful.\nWhat happens if many threads try to write to the same cache line?\nCan you measure the effect of [false sharing](https://en.wikipedia.org/wiki/False_sharing) ([longer article](http://simplygenius.net/Article/FalseSharing)), sometimes called \"cache line contention\".\n\nDesign an experiment to test cache behavior with multiple threads, run it to produce data, and make a plot using Pandas, R, or another plotting system.\nCommit the source code changes, your data, the plotting script, and any figures you produce.\nDescribe what your experiment is testing and your interpretation of the data and figures in your commit message and submit as a pull request.\nPlan to present these results (~5 minutes each) next class period (Wednesday, 2015-01-21).\n\n### Day 3: 2015-01-21\n\n#### 0. Postmortem and presentations\n\n* Effect of array sizes\n* Effect of interlacing/striding\n* Relative cost of moving a cache line into memory multiple times versus having multiple cores write to it concurrently\n* Practical issues\n\n#### 1. Introduction to stencil operations\n\n* Modeling reusable and non-reusable memory accesses\n* Arithmetic Intensity\n* Multiplicative (Gauss-Seidel) versus additive (Jacobi)\n* Boundary conditions\n\n### Day 4: 2015-01-26\n\n#### 0. Experiences with stencil.c\n\n* What experiments did you run?\n* Did you try simplifying/modifying the code?\n* Are boundary conditions a problem?\n* Were divisions hoisted out of the inner loop?\n\n#### 1. Introduction to profiling tools\n\n* Gprof (comes with binutils, gcc support)\n\n  * A simple tool with compiled-in function-level instrumentation.\n  * Usage: compile with `-pg`, run application (which now writes `gmon.out`), and use `gprof executable gmon.out`\n  * Good performance, accurate measure of function calls.\n  * What was inlined?\n  * Ways to prevent inlining.\n  * [Gprof2Dot](https://code.google.com/p/jrfonseca/wiki/Gprof2Dot)\n\n* [Valgrind](http://valgrind.org) (start with Callgrind)\n\n  * Simulator -- accurate, reproducible, fine-grained, very slooooow\n  * Usage: `valgrind --tool=callgrind ./program -args`\n  * Nice visualizations with [KCachegrind](http://kcachegrind.sourceforge.net/html/Home.html)\n  * Annotated source and assembly (`--dump-instr=yes`)\n\n* [Linux Perf](https://perf.wiki.kernel.org/index.php/Main_Page)\n\n  * Interrupt-based profiler, does not need special compilation.\n  * [Brendan Gregg's Examples](http://www.brendangregg.com/perf.html) -- best place to start\n  * Usage: `perf record ./program -args`, then `perf report`\n  * Annotates assembly\n  * Good for drilling into system issues.\n\n* Other instrumentation systems\n\n  * [Scalasca](http://www.scalasca.org/) -- open source, parallel support\n  * [TAU](https://www.cs.uoregon.edu/research/tau/about.php) -- open source, parallel support\n  * [Intel VTune](https://software.intel.com/en-us/intel-vtune-amplifier-xe/)\n  * Sun Studio used to be freely distributed and include a profiler.\n\n### Day 5: 2015-01-28\n\n#### 0. Discussion\n\n* Divisions not hoisted out of loop\n* Can streamline conditionals\n* Use attributes for fine-grained control of inlining\n* Used Perf to check assembly\n\n#### 1. How to optimize further\n\n* Performance model is not in the ballpark for memory bandwidth\n* Only smaller problem sizes can benefit much\n* Vectorization should be able to speed up small sizes\n\n### Day 6: 2015-02-02\n\n#### 0. Experiments with stencils\n\n#### 1. Performance models\n\n* Express resource constraints as a linear program\n* Start with floating point and memory bandwidth, related by arithmetic intensity\n* Multiple phases\n* Amdahl's Law\n\n#### 2. Intro to iterative solvers\n\n* (At least) two phases: matrix application and orthogonalization\n* Preconditioning\n* Scalability of local methods\n\n#### 3. PETSc and Janus\n\n* Install locally (if convenient). http://mcs.anl.gov/petsc\n* Request an account and OTP device. https://rc.colorado.edu/support/userguide/accountrequest\n\n## References\n\n* [STREAM Benchmark](http://www.cs.virginia.edu/stream/)\n* [Ulrich Drepper, *What Every Programmer Should Know About Memory*, 2007](http://www.akkadia.org/drepper/cpumemory.pdf)\n* [Gustavo Duartes, *Cache: A Place for Concealment and Safekeeping*, 2009](http://duartes.org/gustavo/blog/post/intel-cpu-caches/)\n* [Gustavo Duartes, *Getting Physical With Memory*, 2009](http://duartes.org/gustavo/blog/post/getting-physical-with-memory/)\n* [John McCalpin's blog](http://sites.utexas.edu/jdm4372/) (mostly about memory performance)\n* [Datta et al, *Optimization and Performance Modeling of Stencil Computations on Modern Microprocessors*, 2009](http://epubs.siam.org/doi/abs/10.1137/070693199)\n* [Malas et al, *Optimizing the performance of streaming numerical kernels on the IBM Blue Gene/P PowerPC 450 processor*, 2012](http://dx.doi.org/10.1177/1094342012444795) ([arXiv](http://arxiv.org/pdf/1201.3496.pdf))\n\n## Tools\n\n* [hwloc](http://www.open-mpi.org/projects/hwloc/): Portable Hardware Locality\n* [likwid](https://code.google.com/p/likwid/): x86 performance tools\n* [Intel Intrinsics Guide](https://software.intel.com/sites/landingpage/IntrinsicsGuide/)\n", 
  "id": 29157989
}