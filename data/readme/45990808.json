{
  "read_at": 1462554140, 
  "description": "", 
  "Readme.md": "# Neural Caption Generator\n* Tensorflow implementation of \"Show and Tell\" http://arxiv.org/abs/1411.4555\n * Borrowed some code and ideas from Andrej Karpathy's NeuralTalk.\n* You need flickr30k data (images and annotations)\n \n### Code\n* make_flickr_dataset.py : Extracting feats of flickr30k images, and save them in './data/feats.npy' \n* model.py : TensorFlow Version\n \n#### Usage\n* Flickr30k Dataset Download\n* Extract VGG Featues of Flicker30k images (make_flickr_dataset.py)\n* Train: run train() in  model.py\n* Test: run test() or test_tf() in model.py\n * parameters: VGG FC7 feature of test image, trained model path\n * Once you download Tensorflow VGG Net (one of the links below), you don't need Caffe when testing.\n\n#### Downloading data/trained model\n* Extraced FC7 data: [download](https://drive.google.com/file/d/0B5o40yxdA9PqTnJuWGVkcFlqcG8/view?usp=sharing)\n * This is used in train() function in model.py. You can skip feature extraction part by using this.\n* Pretrained model [download](https://drive.google.com/file/d/0B5o40yxdA9PqeW4wY0wwZXhrZkE/view?usp=sharing)\n * This is used in test() and test_tf() in model.py. If you do not have time for training, or if you just want to check out captioning, download and test the model.\n* Tensorflow VGG net [download](https://drive.google.com/file/d/0B5o40yxdA9PqSGtVODN0UUlaWTg/view?usp=sharing)\n * This file is used in test_tf() in model.py\n* Along with the files above, you might want to download flickr30k annotation data from [link](http://shannon.cs.illinois.edu/DenotationGraph/) \n\n![alt tag](https://github.com/jazzsaxmafia/show_and_tell.tensorflow/blob/master/result.jpg)\n\n### License\n* BSD license\n", 
  "id": 45990808
}