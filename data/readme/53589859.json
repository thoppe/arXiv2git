{
  "read_at": 1462555431, 
  "description": "", 
  "README.md": "# arctic-captions\n\nSource code for [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](http://arxiv.org/abs/1502.03044)\nrunnable on GPU and CPU.\n\nJoint collaboration between the Universite de Montreal & University of Toronto.\n\n## Dependencies\n\nThis code is written in python. To use it you will need:\n\n* Python 2.7\n* A relatively recent version of [NumPy](http://www.numpy.org/)\n* [scikit learn](http://scikit-learn.org/stable/index.html)\n* [skimage](http://scikit-image.org/docs/dev/api/skimage.html)\n* [argparse](https://www.google.ca/search?q=argparse&oq=argparse&aqs=chrome..69i57.1260j0j1&sourceid=chrome&es_sm=122&ie=UTF-8#q=argparse+pip)\n\nIn addition, this code is built using the powerful\n[Theano](http://www.deeplearning.net/software/theano/) library. If you\nencounter problems specific to Theano, please use a commit from around\nFebruary 2015 and notify the authors.\n\nTo use the evaluation script (metrics.py): see\n[coco-caption](https://github.com/tylin/coco-caption) for the requirements.\n\n## Reference\n\nIf you use this code as part of any published research, please acknowledge the\nfollowing paper (it encourages researchers who publish their code!):\n\n**\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.\"**  \nKelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan\nSalakhutdinov, Richard Zemel, Yoshua Bengio. *To appear ICML (2015)*\n\n    @article{Xu2015show,\n        title={Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},\n        author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},\n        journal={arXiv preprint arXiv:1502.03044},\n        year={2015}\n    } \n\n## License\n\nThe code is released under a [revised (3-clause) BSD License](http://directory.fsf.org/wiki/License:BSD_3Clause).\n", 
  "id": 53589859
}