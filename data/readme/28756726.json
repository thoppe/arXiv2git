{
  "read_at": 1462551511, 
  "description": "Java OAI Harvester for the arXiv", 
  "README.md": "arXiv OAI Harvester\n=================\n\nCopyright (c) 2015 Mike Saelim, mike.saelim@gmail.com\n\n[**Current version**](http://semver.org/): 0.1.0\n\nThis is an OAI Harvester library for the arXiv preprint repository, written in Java.  At this point, it is still a work\nin progress.\n\nUpon completion, this library will allow its users to query the arXiv OAI repository for items in the \"arXivRaw\" metadata\nformat, giving them access to all the metadata of all the articles on the arXiv.\n\nInformational links:\n\n* [arXiv](http://arxiv.org/)\n* [arXiv OAI interface](http://arxiv.org/help/oa/index)\n* [OAI-PMH: Open Archives Initiative - Protocol for Metadata Harvesting](http://www.openarchives.org/pmh/)\n    * [Formal definition of the OAI protocol](http://www.openarchives.org/OAI/openarchivesprotocol.html)\n\n\n#####Covering my ass\n\nI mostly designed this library to support a future larger project of mine, and for educational purposes to give me more\npractice coding and designing.  No guarantees on current reliability and future support!  If you prioritize these things,\nI might suggest using one of the more general Java OAI Harvesters out there, which (hopefully) have reached some kind of\nstability.\n\n##Usage\n\nI strongly recommend reading up on the above links before using this library, because this library will not insulate you\nfrom all the peculiarities of the OAI protocol.  \n\nThe API is designed so that users construct a central harvester object, and then pass GetRecord and ListRecords requests\nto it.  The harvester issues the appropriate HTTP calls to the arXiv OAI repository, parses the result, and outputs the\nresponse to the user.  Responses contain all the data contained in the \"arXivRaw\" metadata format.  \n\nIt will probably take at least a few seconds, and possibly minutes, to process each request.  This is because a lot of\ndata may be transmitted by the repository, and because the repository throttles requests when they are coming in too\nfast.  Both of these reasons are out of the control of the harvester.  The harvester does have some parameters you can\nset to control how long it is allowed to wait before retrying, and how many times it will retry.  This also means that\nharvesting should be thought of as more of a bulk-retrieval-once-a-day-to-a-local-database thing, and not thought of as\na retrieval-on-demand thing.\n\n**A single harvester should be used for all of the requests, and this harvester should only be used by a single thread.**  \nCurrently, the implementation of the harvester is blocking and not thread-safe.  Furthermore, because the arXiv OAI\nrepository throttles your requests based on your IP, multiple harvesters or threads will end up blocking each other \nanyway.  In the future, I may rewrite the implementation to queue multiple requests and resolve them asynchronously.\n\n####Importing the library\n\nAt this point, while the library is still in development, you can just clone the repo, build a jar, and throw that jar\ninto your project.  Once this is ready for release, I will probably host the jar(s) somewhere.\n\n####Preparing the harvester\n\nThe simplest preparation is to pass a `CloseableHttpClient` into the constructor:\n\n    CloseableHttpClient httpClient = HttpClients.createDefault();  \n    ArxivOAIHarvester harvester = new ArxivOAIHarvester(httpClient);\n    \nThis will construct a harvester with the default settings for three important flow control parameters:\n\n* the maximum number of retries: 3,\n* the minimum wait time between retries: 10 seconds, and\n* the maximum wait time between retries: 5 minutes.\n\nThese are needed because the repository can respond to requests with a 503 Retry-After response, which says \"Yo, either\nI'm super busy right now or you've been requesting too frequently, chill for X seconds and try again.\"  And if you don't\nwait, you'll probably get another 503 Retry-After and have to wait longer.  The default harvester will respect the \nrepository's management of the flow control by retrying only 3 times, restricting its requests to no faster than 10\nseconds between requests, and timing out if the repository requests a wait longer than 5 minutes.  But you can set these\nvalues yourself - for example, for 5 retries between 20 seconds and 30 minutes,\n\n    CloseableHttpClient httpClient = HttpClients.createDefault();\n    ArxivOAIHarvester harvester = new ArxivOAIHarvester(httpClient, 5, Duration.ofSeconds(20), Duration.ofMinutes(30));\n    \nIt is also suggested that you supply \"User-Agent\" and \"From\" HTTP headers to identify to the repository who you are:\n\n    harvester.setUserAgentHeader(\"Dave's Super Curious Bot, v0.1\");\n    harvester.setFromHeader(\"dave@daves.io\");\n\n####Retrieving a single record from the repository\n\nTo retrieve a single record by its identifier, construct a `GetRecordRequest` and pass it into the harvester:\n\n    GetRecordRequest request = new GetRecordRequest(\"oai:arXiv.org:1302.2146\");\n    GetRecordResponse response = harvester.harvest(request);\n    ArticleMetadata record = response.getRecord();\n    \nThe identifier string will always be \"oai:arXiv.org:\" followed by the arXiv identifier you're probably more used to, so\nyou can even leave the \"oai:arXiv.org:\" part off.  See arXiv's pages about the OAI for more information.\n\nThe resulting `GetRecordResponse` will contain the record, if it exists, as an `ArticleMetadata` object.  If no record\nby that identifier was found, then `response.getRecord()` will return null.  If there are any issues sending the \nrequest, receiving the response, or parsing the response, the harvester will throw a runtime exception or error - see \nthe javadoc for `ArxivOAIHarvester` for a full list.\n\n####Retrieving a range of records from the repository\n\nTo retrieve a range of records between two dates, and/or of a specific set, construct a `ListRecordsRequest` and pass it\ninto the harvester.  Because many records may be returned, the repository will page the results (usually the pages are\nin sets of 1000 records), and you'll need to issue a new resumption request for each page.  But the API takes care of\nthe resumption token stuff for you, if you follow the recommended pattern:\n\n    ListRecordsRequest request = new ListRecordsRequest(LocalDate.of(2015, 6, 29), null, \"physics:hep-ph\");\n    while (request != ListRecordsRequest.NONE) {\n        ListRecordsResponse response = harvester.harvest(request);\n        List<ArticleMetadata> records = response.getRecords();\n        // do whatever\n        request = response.resumption();\n    }\n\nThe request takes three optional parameters: two `LocalDate` objects specifying the range, and the set to restrict the\nsearch to.  The date does not refer to the original submission date of the article, but rather the last time the OAI \nrecord for that article was updated.  Thus, a request to retrieve all the records between two dates will not necessarily\ngrab all the articles submitted between those dates.  The list of sets that the arXiv repository supports can be found\n[here](http://export.arxiv.org/oai2?verb=ListSets).  See arXiv's pages about the OAI for more information.\n\nThe resulting `ListRecordsResponse` objects will contain a list of records, if they exist, as `ArticleMetadata` objects.\nIf no records were found in that range and set, then `response.getRecords()` will return an empty list.  If there are \nany issues sending the request, receiving the response, or parsing the response, the harvester will throw a runtime \nexception or error - see the javadoc for `ArxivOAIHarvester` for a full list.\n\n## Try it out!\n\nI've supplied a `CommandLineInterface` class with an executable `main()` method that executes one request to the arXiv\nOAI repository.  You can run this either by building the jar and running it, or by typing\n\n    ./gradlew clean run\n    \nin the repository directory.  This should give you a feel for how it all behaves.\n\n", 
  "id": 28756726
}