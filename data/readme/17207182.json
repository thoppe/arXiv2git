{
  "read_at": 1462543236, 
  "description": "Counting small cliques in large graphs using MapReduce.", 
  "README.txt": "This software was compiled using version 2.2.0 of Apache(tm) Hadoop(r)!, available at\n\n\thttp://hadoop.apache.org/\n\nThis software requires the jCommander library, developed by Cedric Beust and available at\n\n\thttp://jcommander.org\n\nThe ideas behind this software are described in \n\n\tIrene Finocchi, Marco Finocchi, and Emanuele Guido Fusco, \n\t``Clique counting in MapReduce: theory and experiments'',\n\tarXiv:1403.0734 [cs.DC].\n\thttp://arxiv.org/abs/1403.0734\n\nPlease give us credits by citing this work if you make use of our software.\n\nHOW TO USE THIS TOOL\n\nUsage: yarn jar <program jar file> [options] [command] [command options]\n\nThere are three main commands provided by our tool.\n\n------------------------------------- computeDegrees -------------------------------------\n\nCommand computeDegrees computes the degrees of each node and decorates the endpoints of\neach edge with their degrees.\n\nIt takes a list of edges (one edge per line, each edge as a pair of node labels \nseparated by \\tab). Each edge must appear only in one direction.\nAn example file could be:\nb\ta\n1\t5\n2\t5\n\nCommand computeDegrees produces in output the same list, where nodes are decorated with \nas follows:\na:1\tb:1\n1:1\t5:2\n2:1\t5:2\n\n\n\nBelow is the list of options to the command computeDegrees. Required arguments are \nmarked with a \"*\".\n\n      Usage: computeDegrees [options]\n        Options:\n        * -in\n             Input File\n             Default: <empty string>\n          -logCpuTime\n             enable/disable detailed mappers and reducers cpu usage logs\n             Default: false\n        * -out\n             Output File\n             Default: <empty string>\n          -reducers\n             Number of reducers\n             Default: 4\n          -speculative\n             Enabe/disable speculative execution\n             Default: true\n          -splitSize\n             Set the split size for input files\n             Default: 64\n          -workingDir\n             HDFS Working dir (full path)\n             Default: /\n             \nExample: let graph.txt be the input file stored in the HDFS folder \"/dataset\" and let \nQkCount.jar be the jar file of the program. Consider the folling command:\n\n\tyarn jar QkCount.jar computeDegrees -in=graph.txt -out=degrees \n\t\t-workingDir=/dataset -speculative=false -reducers=2\n             \nThe command above would produce the HDFS folder /dataset/degrees/ containing (in two \nfiles, each produced by one of the two requested reducers) the list of edges decorated\nwith degrees. The folder \"/dataset/degrees/\" could then be used as input to commands \ncountCliques and countTriangles, described below.\n\nRunning times, if logged, are in nanoseconds.\n\n\n-------------------------------------- countCliques --------------------------------------\n\nCommand countCliques computes the number of cliques of size given by parameter cliqueSize.\nThe cliqueSize must be at least 3. The execution becomes more computationally intensive \nas the cliqueSize becomes larger. Parameters edgeSample and colorSample allow to apply \nsampling strategies that return an approximation of the actual number of cliques. \nThe input to this command should be the output folder produced by command computeDegrees.\n             \n      Usage: countCliques [options]\n        Options:\n        * -cliqueSize\n             Size of the cliques to be counted\n             Default: 4\n          -colorSample\n             Use coloring based sampling with the given number of colors\n             Default: -1\n          -edgeSample\n             Use edge sampling with the given probability\n             Default: -1.0\n        * -in\n             Input File\n             Default: <empty string>\n          -logCpuTime\n             enable/disable detailed mappers and reducers cpu usage logs\n             Default: false\n        * -out\n             Output File\n             Default: <empty string>\n          -reducers\n             Number of reducers\n             Default: 4\n          -speculative\n             Enabe/disable speculative execution\n             Default: true\n          -splitSize\n             Set the split size for input files\n             Default: 64\n          -useLPlusN\n             Use the LPlusN clique count algorithm if true, NodeIterator++ if\n             false\n             Default: true\n          -workingDir\n             HDFS Working dir (full path)\n             Default: /\n\nExample:\n\tyarn jar QkCount.jar countCliques -in=degrees -out=cliques -cliqueSize=4 \n\t\t\t-workingDir=/dataset\n\nThe command above would produce the HDFS folder /dataset/cliques-4/ containing a non-empty\nfile with the algorithms acronym, the sampling probability or the number of colors for the \napproximate algorithm, the cliqueSize given in input, and the computed number of cliques.\n\nAlgorithm acromyms are:\nX = exact\nC = approximation algorithm using color-based sampling\nE = approximation algorithm using simple edge sampling\nWe refer to our paper for details on these algorithms.\n\n\n------------------------------------- countTriangles -------------------------------------\n\nCommand countTriangles applies the algorithm NodeIterator++ described in \n\n\tSiddharth Suri and Sergei Vassilvitskii, \n\t\"Counting triangles and the curse of the last reducer\", \n\tProceedings of the 20th international conference on World wide web, ACM, 2011\n\nand returns the number of triangles in the input graph. The input to this command should \nbe the output folder produced by command computeDegrees.\n\n      Usage: countTriangles [options]\n        Options:\n        * -in\n             Input File\n             Default: <empty string>\n          -logCpuTime\n             enable/disable detailed mappers and reducers cpu usage logs\n             Default: false\n        * -out\n             Output File\n             Default: <empty string>\n          -reducers\n             Number of reducers\n             Default: 4\n          -runOnAmazon\n             Execution on Amazon EMR (sets IO on s3 filesystem)\n             Default: true\n          -speculative\n             Enabe/disable speculative execution\n             Default: true\n          -splitSize\n             Set the split size for input files\n             Default: 64\n          -useLazyPairs\n             Use the lazy pair explosion\n             Default: false\n          -workingDir\n             HDFS Working dir (full path)\n             Default: /\n             \nExample:\n\tyarn jar QkCount.jar countTriangles -in=degrees -out=triangles \n\t\t\t-workingDir=/dataset\n\n--------------------------------------- countByJoin --------------------------------------\nCommand countByJoin applies the multiway join algorithm described in\n\n\n\tFoto N. Afrati, Dimitris Fotakis, and Jeffrey D. Ullman\n\tEnumerating subgraph instances using map-reduce\n\tProceedings of the 29th IEEE International Conference on Data Engineering ICDE 2013\n\n      Usage: countByJoin [options]\n        Options:\n        * -cliqueSize\n             Size of the cliques to be counted\n             Default: 4\n        * -in\n             Input File\n             Default: <empty string>\n          -logCpuTime\n             enable/disable detailed mappers and reducers cpu usage logs\n             Default: false\n        * -nBuckets\n             Number of buckets to use for the multiway join\n             Default: 4\n        * -out\n             Output File\n             Default: <empty string>\n          -reducers\n             Number of reducers\n             Default: 4\n          -speculative\n             Enabe/disable speculative execution\n             Default: false\n          -splitSize\n             Set the split size for input files\n             Default: 64\n          -workingDir\n             HFS Working dir (full path)\n             Default: /\n\nExample:\n\tyarn jar QkCount.jar countByJoin -in=degrees -out=triangles -cliqueSize=4 \n\t\t\t-workingDir=/dataset -nBuckets=8\n", 
  "id": 17207182
}