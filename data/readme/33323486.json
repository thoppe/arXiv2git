{
  "read_at": 1462511486, 
  "description": "Tree-structured Long Short-Term Memory networks (http://arxiv.org/abs/1503.00075)", 
  "README.md": "Tree-Structured Long Short-Term Memory Networks\n===============================================\n\nAn implementation of the Tree-LSTM architectures described in the paper \n[Improved Semantic Representations From Tree-Structured Long Short-Term Memory\nNetworks](http://arxiv.org/abs/1503.00075) by Kai Sheng Tai, Richard Socher, and \nChristopher Manning.\n\n## Requirements\n\n- [Torch7](https://github.com/torch/torch7)\n- [penlight](https://github.com/stevedonovan/Penlight)\n- [nn](https://github.com/torch/nn)\n- [nngraph](https://github.com/torch/nngraph)\n- [optim](https://github.com/torch/optim)\n- Java >= 8 (for Stanford CoreNLP utilities)\n- Python >= 2.7\n\nThe Torch/Lua dependencies can be installed using [luarocks](http://luarocks.org). For example:\n\n```\nluarocks install nngraph\n```\n\n## Usage\n\nFirst run the following script:\n\n```\n./fetch_and_preprocess.sh\n```\n\nThis downloads the following data:\n\n  - [SICK dataset](http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools) (semantic relatedness task)\n  - [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html) (sentiment classification task)\n  - [Glove word vectors](http://nlp.stanford.edu/projects/glove/) (Common Crawl 840B) -- **Warning:** this is a 2GB download!\n\nand the following libraries:\n\n  - [Stanford Parser](http://nlp.stanford.edu/software/lex-parser.shtml)\n  - [Stanford POS Tagger](http://nlp.stanford.edu/software/tagger.shtml)\n\nThe preprocessing script generates dependency parses of the SICK dataset using the\n[Stanford Neural Network Dependency Parser](http://nlp.stanford.edu/software/nndep.shtml).\n\nAlternatively, the download and preprocessing scripts can be called individually.\n\n### Semantic Relatedness\n\nThe goal of this task is to predict similarity ratings for pairs of sentences. We train and evaluate our models on the [Sentences Involving Compositional Knowledge (SICK)](http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools) dataset.\n\nTo train models for the semantic relatedness prediction task on the SICK dataset,\nrun:\n\n```\nth relatedness/main.lua --model <dependency|constituency|lstm|bilstm> --layers <num_layers> --dim <mem_dim> --epochs <num_epochs>\n```\n\nwhere:\n\n  - `model`: the LSTM variant to train (default: dependency, i.e. the Dependency Tree-LSTM)\n  - `layers`: the number of layers (default: 1, ignored for Tree-LSTMs)\n  - `dim`: the LSTM memory dimension (default: 150)\n  - `epochs`: the number of training epochs (default: 10)\n\n### Sentiment Classification\n\nThe goal of this task is to predict sentiment labels for sentences. For this task, we use the [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html) dataset. Here, there are two sub-tasks: binary and fine-grained. In the binary sub-task, the sentences are labeled `positive` or `negative`. In the fine-grained sub-task, the sentences are labeled `very positive`, `positive`, `neutral`, `negative` or `very negative`.\n\nTo train models for the sentiment classification task on the Stanford Sentiment Treebank, run:\n\n```\nth sentiment/main.lua --model <constituency|dependency|lstm|bilstm> --layers <num_layers> --dim <mem_dim> --epochs <num_epochs>\n```\n\nThis trains a Constituency Tree-LSTM model for the \"fine-grained\" 5-class classification sub-task.\n\nFor the binary classification sub-task, run with the `-b` or `--binary` flag, for example:\n\n```\nth sentiment/main.lua -m constituency -b\n```\n\nPredictions are written to the `predictions` directory and trained model parameters are saved to the `trained_models` directory.\n\nSee the [paper](http://arxiv.org/abs/1503.00075) for more details on these experiments.\n", 
  "id": 33323486
}