{
  "read_at": 1462546089, 
  "description": "Bayesian Optimization using xgboost and sklearn API", 
  "README.md": "# BayesBoost\nBayesian Optimization using xgboost and sklearn API\n\nSimple test scripts for optimal hyperparameter of xgboost using bayesian optimization.\n\nOriginal bayesian optimization code is from https://github.com/fmfn/BayesianOptimization and all credit for this work goes to the original author.  \n\n\nTo run the examples below you will need to install this package (it is under constant development)\n\n```pip install git+https://github.com/fmfn/BayesianOptimization.git```\n\nExample 1. is based on the otto dataset from Kaggle, this remains in memory.\n(https://www.kaggle.com/c/otto-group-product-classification-challenge)\n\nExample 2. is based on Avazu click prediction dataset from Kaggle and requires the 'distributed' version of xgboost.\n(https://www.kaggle.com/c/avazu-ctr-prediction)\n\n### Run\nTo get this running create a data/otto and data/avazu dir and download the datasets into the respective directories and unzip / untar the files.\n\nDependencies:\n* BayesianOptimization (https://github.com/fmfn/BayesianOptimization)\n* Scipy\n* Numpy\n* Scikit-Learn\n* xgboost (https://github.com/dmlc/xgboost)\n\nReferences:\n* http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf\n* http://arxiv.org/pdf/1012.2599v1.pdf\n* http://www.gaussianprocess.org/gpml/\n* https://www.youtube.com/watch?v=vz3D36VXefI&index=10&list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6\n\n", 
  "id": 39878840
}