{
  "id": 44979576, 
  "read_at": 1462556070, 
  "README.rst": "..\n    This file is part of hepcrawl.\n    Copyright (C) 2015 CERN.\n\n    hepcrawl is a free software; you can redistribute it and/or modify it\n    under the terms of the Revised BSD License; see LICENSE file for\n    more details.\n\n\n==========\n HEPcrawl\n==========\n\nHEPcrawl is a harvesting library based on Scrapy (http://scrapy.org) for INSPIRE-HEP\n(http://inspirehep.net) that focuses on automatic and semi-automatic retrieval of\nnew content from all the sources the site aggregates. In particular content from\nmajor and minor publishers in the field of High-Energy Physics.\n\nThe project is currently in early stage of development.\n\nInstallation for developers\n===========================\n\nWe start by creating a virtual environment for our Python packages:\n\n.. code-block:: shell\n\n    mkvirtualenv hepcrawl\n    cdvirtualenv\n    mkdir src && cd src\n\n\nNow we grab the code and install it in development mode:\n\n.. code-block:: shell\n\n    git clone https://github.com/inspirehep/hepcrawl.git\n    cd hepcrawl\n    pip install -e .\n\n\nDevelopment mode ensures that any changes you do to your sources are automatically\ntaken into account = no need to install again after changing something.\n\nFinally run the tests to make sure all is setup correctly:\n\n.. code-block:: shell\n\n    python setup.py test\n\n\nRun example crawler\n===================\n\nThanks to the command line tools provided by Scrapy, we can easily test the\nspiders as we are developing them. Here is an example using the simple sample\nspider:\n\n.. code-block:: console\n\n    cdvirtualenv src/hepcrawl\n    scrapy crawl arXiv -a source_file=file://`pwd`/tests/responses/arxiv/sample_arxiv_record.xml\n\n\nThanks for contributing!\n", 
  "description": "Scrapy project for feeds into INSPIRE-HEP"
}