{
  "read_at": 1462547690, 
  "description": "THE Deep Learning Benchmarks", 
  "README.md": "# deepmark\nTHE Deep Learning Benchmarks\n\nSee: https://github.com/soumith/convnet-benchmarks/issues/101\n\nCome back here on June 15th, 2016.\n\n## Networks\n### Images\n- InceptionV3-batchnorm (http://arxiv.org/abs/1512.00567 , https://github.com/Moodstocks/inception-v3.torch)\n- Alexnet-OWT\n- VGG\n- ResNet-50 ( http://arxiv.org/abs/1512.03385 , https://github.com/facebook/fb.resnet.torch )\n\n### Video\n- C3D - A vgg-style 3D net ( http://vlg.cs.dartmouth.edu/c3d/ )\n\n### Audio\n- DeepSpeech2 - Convnet + RNN + FC ( http://arxiv.org/abs/1512.02595 )\n- MSR's 5 layer FC net ( https://github.com/Alexey-Kamenev/Benchmarks )\n\n### Text\n- Small RNN LSTM ( https://github.com/karpathy/char-rnn/blob/master/train.lua#L38-L48 )\n- Large RNN LSTM ( BIG-LSTM in http://arxiv.org/abs/1602.02410 )\n\n\n### Platform\n- Initially multi-GPU with (1 to 4 titan-X cards)\n- However, multi-machine, custom hardware, other GPU cards such as AMD, CPUs etc. can and should be accommodated, we will work this out after the initial push.\n\n## Metrics\n- Round-trip time for 1 epoch of training (will define an epoch size separately for each network)\n- Maximum batch-size that fits (to show and focus on the extra memory consumption that the framework uses)\n\n## Frameworks\nEveryone who wants to join-in, but I thought an initial set that is important to cover would be:\n- Caffe\n- Chainer\n- MXNet\n- Neon\n- Theano\n- TensorFlow\n- Torch\n\n## Scripts format\n- Emit JSON output (so that the README -- or jekyll website can be auto-generated, similar to http://autumnai.com/deep-learning-benchmarks )\n\n## Guarantees\n- I will personally to the best of my abilities make sure that the benchmarking is fair and unbiased. The hope is that the community at large will watch these and point-out / fix mistakes.\n\n## Governance\n- The benchmarks will be placed at https://github.com/DeepMark/deepmark and other key community members / organizations who want ownership will be welcome to join in proposing new benchmarks that get relevant as the field progresses.\n", 
  "id": 56276710
}