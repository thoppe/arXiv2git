{
  "id": 1484982, 
  "read_at": 1462510903, 
  "README.textile": "h1. TM2: Type-safe modeling in text mining\n\nThis is a very prototypical API for creating text mining experiments using Java and Scala.\n\nh2. Idea\n\nIt is based on the idea that every text mining task essentially is an annotation of text with some entities (e.g. this is a _word_, a _verb_, a _place_, _interesting_, etc). Different text mining components typically create annotations of different types (e.g. _token_, _type_, _part of speech_, _location_, _sentiment_, etc). This can be modeled as an @Annotation[T]@. The components or agents consume and produce these entities as input and output. This can be represented as @Agent[I, O]@, e.g. a POS tagger consumes annotations of _tokens_ and produces annotations of _part of speech_ - it is an @Agent[Token, POS]@. These agents interact in syntheses and analyses. An analysis is a linear interaction between agents, e.g. POS tagging involves analysing tokens: @Analysis[Token]@. A synthesis combines two annotation types - e.g. to train a classifier: @Synthesis[Token, Feature]@. By checking if the interaction types match the agent types, the compiler can check if experiment setups make any sense at all.\n\nh2. API\n\nTM2 can be used as a regular API from Java, or in a very concise way from Scala, e.g. to define an analysis:\n\n<pre lang=\"scala\">val a: Analysis[Token] = tokenizer -> gazetteer</pre>\n\nIn a similar way we can define syntheses:\n\n<pre lang=\"scala\">val s: Synthesis[Token, Frequency] = (tokenizer, indexer) -> index</pre>\n\nWith @|@, the interactions can be combined into experiments, which can be executed with @!@:\n\n<pre lang=\"scala\">val e: Experiment = corpus -> tokenizer | tokenizer -> ie !</pre>\n\nWe can combine analyses and syntheses, e.g. to add an evaluation:\n\n<pre lang=\"scala\">val e = corpus -> tok | tok -> (ie, gold) | (ie, gold) -> eval !</pre>\n\nCombining this Scala API with Scala's general features, we can easily define and run experiments with variable configuration parameters, using this general form:\n\n<pre lang=\"scala\">run { for { <configuration> } yield { <experiment> } }</pre>\n\nA simple example with two different corpora and two different tokenizers (i.e. 2*2=4 runs) could look like this:\n\n<pre lang=\"scala\">\nval ie = new Gazetteer\nval gold = new GazetteerGoldStandard\nval eval = new SimpleEvaluation\nrun {\n  for {\n    corpus <- List(new WorksOfShakespeare, new WorksOfGoethe)\n    tok <- List(new RuleBasedTokenizer, new TrainableTokenizer)\n  } yield {\n    corpus -> tok | tok -> (ie, gold) | (ie, gold) -> eval\n  }\n}\n</pre>\n\nWith this syntax we can set up complex experiment series, e.g. training and evaluating a classifier:\n\n<pre lang=\"scala\">\nval corpus = new Corpus\nobject trainData extends SensevalData(\"files/EnglishLS.train.xml\")\nobject testData extends SensevalData(\"files/EnglishLS.test.xml\")\nobject trainSense extends SensevalSense(\"files/EnglishLS.train.xml\")\nrun {\n  /* Variable configuration parameters: */\n  for {\n    algo <- List(new NaiveBayes, new BayesNet, new SMO, new HyperPipes, new IBk);\n    feat <- List(\"3-gram\", \"7-gram\", \"word\", \"length\");\n    grain <- List(\"fine\", \"mixed\", \"coarse\");\n    context <- List(2, 4, 8, 16);\n    trainFeat = new TrainFeatures(feat, context)\n    testFeat = new TestFeatures(feat, context)\n    classifier = new SensevalClassifier(context, 2f, algo, \"S0\", \"S1\")\n    evaluation = new SensevalEval(grain)\n  } \n  /* Fixed agent interaction: */\n  yield {\n    /* Preprocessing: */\n    corpus -> (trainData, trainSense) |\n    /* Training: */\n    trainData -> (trainFeat, trainSense) |\n    (trainFeat , trainSense) -> classifier |\n    /* Classification: */\n    testData -> testFeat |\n    testFeat -> classifier |\n    /* Evaluation: */\n    classifier -> evaluation\n  }\n}\n</pre>\n\nThis setup will run experiments with all permutations of the given configuration parameters (classifiers, features, context, etc.), i.e. here 5*4*3*4=240 runs. The definition above uses Scala's type inference and omits explicit type declarations. They can be used optionally:\n\n<pre lang=\"scala\">\nval corpus: Agent[String, String] = new Corpus\nval trainData: Agent[String, Context] = new TrainData()\nval testData: Agent[String, Context] = new TestData()\nval trainSense: Agent[Context, Ambiguity] = new TrainSense()\nrun {\n  for {\n    /* Configurations: */\n    algo: weka.classifiers.Classifier <- List(new NaiveBayes, new BayesNet, new SMO, new HyperPipes, new IBk);\n    feat: String <- List(\"3-gram\", \"7-gram\", \"word\", \"length\");\n    grain: String <- List(\"fine\", \"mixed\", \"coarse\");\n    context: Int <- List(2, 4, 8, 16);\n    /* Agents: */\n    trainFeat: Agent[Context, FeatureVector] = new TrainFeatures(feat, context)\n    testFeat: Agent[Context, FeatureVector] = new TestFeatures(feat, context)\n    classifier = new SensevalClassifier(context, 2f, algo, \"S0\", \"S1\")\n    classifierAgent: Agent[FeatureVector, Sense] = classifier\n    classifierModel: Model[FeatureVector, Ambiguity] = classifier\n    evaluation: Agent[Sense, String] = new SensevalEval(grain)\n    /* Interactions: */\n    corpusData: Analysis[String] = corpus -> (trainData, testData)\n    corpusContext: Analysis[Context] = trainData -> (trainFeat, trainSense)\n    trainClassifier: Synthesis[FeatureVector, Ambiguity] = (trainFeat, trainSense) -> classifierModel\n    testContext: Analysis[Context] = testData -> testFeat\n    classify: Analysis[FeatureVector] = testFeat -> classifierAgent\n    evaluate: Analysis[Sense] = classifierAgent -> evaluation\n  } /* Workflow: */ yield corpusData | corpusContext | trainClassifier | testContext | classify | evaluate\n}\n</pre>\n\nTM will generate some documentation about the experiments and their setup, e.g. for the definitions above we get this overview:\n\n<img src=\"https://github.com/fsteeg/tm2/raw/master/com.quui.tm2.scala/files/tm2-setup.png\" width=\"400px\"/>\n\nFor the complete run, an overview page with results is generated:\n\n<img src=\"https://github.com/fsteeg/tm2/raw/master/com.quui.tm2.scala/files/tm2-result.png\" width=\"600px\"/>\n\nFor a detailed description of the concepts and implementation of TM2 in German, check out this report: \"arXiv\":http://arxiv.org/abs/1108.0363, \"PDF\":https://github.com/fsteeg/tm2/raw/master/com.quui.tm2.scala/tex/tm2.pdf, \"TeX\":https://github.com/fsteeg/tm2/tree/master/com.quui.tm2.scala/tex/tm2.tex\n\nh2. Prerequisites\n\nJava 6, Ant (for building), GCC (to build Senseval evaluation scorer app)\n\nh2. Setup\n\n* Copy @com.quui.tm2/src/tm2.properties.template@ to @com.quui.tm2/src/tm2.properties@\n* Set the @project@ property to the location of your local @com.quui.tm2@ project\n* Set the @dot_home@ property to the folder containing your local @dot@ binary file\n* Compile the @scorer2@ app: @cd com.quui.tm2.scala/files@; @gcc -o scorer2 scorer2.c@\n\nh2. Build\n\n* Build the code and run the tests: @cd com.quui.tm2.scala@; @export ANT_OPTS=-Xmx1024m@; @ant@\n* Test result reports are generated at @com.quui.tm2.scala/build/tests/scala/summary@\n* Batch documentation is generated at @com.quui.tm2/output/batch-result.html@\n\n", 
  "description": "TM2: Type-safe modeling in text mining"
}