{
  "README": "######################################################################\nCS676A: Computer Vision and Image Processing\n######################################################################\n\n######################################################################\nProject: Pedestrian Detection using R-CNN\nInstructor: Prof. Vinay P. Namboodiri\nTA: Samrath Patidar\n\nMembers-\n\t1. Deepak Kumar (12228)\n\t2. Mohit Singh Solanki (12419)\n######################################################################\n\n\n\n######################################################################\nPAPERS FOLLOWED\n######################################################################\n\t1. Geoffrey E. Hinton Alex Krizhevsky, Ilya Sutskever. Imagenet classification with deep convolutional neural networks. NIPS, 2012.\n\t2. Ross Girshick. Fast r-cnn. In International Conference on Computer Vision (ICCV), 2015.\n\t3. Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Computer Vision and Pattern Recognition, 2014.\n\t4. Gevers2 J.R.R. Uijlings, van de Sande and A.W.M. Smeulders2. Selective search for object recognition. ICCV, 2011.\n\t5. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In Advances in Neural Information Processing Systems (NIPS), 2015.\n\n\n\n######################################################################\nPLATFORM SPECS \n######################################################################\nEC2 Linux Instance on Amazon Web Service\n\t1. OS - Ubuntu 14.04\n\t2. GPU - 1x NVIDIA GRID (Kepler G104) + 8 x hardware hyperthreads from Intel Xeon E5-2670\n\t3. Memory - 15GB\n\t4. HardDisk - 90GB SSD\n\n\tRefer to AWS documentation on creation of EC2 linux instance and setup\n\n\n\n######################################################################\nINSTALLATION STEPS\n######################################################################\n1. Login to your AWS instance\n2. Install OpenCV as described in this blog:\nhttp://www.pyimagesearch.com/2015/06/22/install-opencv-3-0-and-python-2-7-on-ubuntu/\n(Ignore the step-8. We don't want to install virtualenv. Also ignore all commands that have virtualenv usage in them)\n3. Install CAFFE as described in this blog:\nhttps://github.com/BVLC/caffe/wiki/Install-Caffe-on-EC2-from-scratch-(Ubuntu,-CUDA-7,-cuDNN)\nNote:\n\t- Don't forget to do \"make pycaffe\" at the end\n\t- Edit the Makefile.config and change 'WITH_PYTHON_LAYER := 1'\n\n4. Download the changed fast-rcnn files from the my github:\ngit clone --recursive  https://github.com/kumardeepakr3/fast-rcnn\n5. Download INRIA dataset.\n6. Install vnc4server (Matlab installation needs Display)\n7. Install Matlab on Linux Instance. (We used Matlab 2012. You know how to do it :p )\n\n\n\n######################################################################\nTRAINING\n######################################################################\n1. For training we use the images under the train/pos/ directory.\n2. Organise the train data as follows:\n3. /home/ubuntu/INRIA\n\t\t\t\t|-- data\n\t\t\t\t\t|-- Annotations\n\t\t\t\t\t\t|-- *.txt (Annotation Files)\n\t\t\t\t\t|-- Images\n\t\t\t\t\t\t|-- *.png (Image Files)\n\t\t\t\t\t|-- ImageSets\n\t\t\t\t\t\t|-- train.txt\n4. The train.txt contains all the names(without extensions) of images files that will be used for training.\nFor Eg:\n\tcrop_000011\n\tcrop_000603\n\tcrop_000606\n\tcrop_000607\n\tcrop_000608\n\n5. Construct IMDB\n\t- cd $FRCNN_ROOT/lib/datasets\n\t- Edit the file inria.py and set self._classes [Do nothing if using git cloned from my repo]\n\t- Create your own annotation function like _load_inria_annotation in inria.py. [Do nothing if using git cloned from my repo]\n\t- Add 'import inria' to the files [Do nothing if using git cloned from my repo]\n\t- Edit factory.py and set inria_devkit_path to point to the /home/ubuntu/INRIA directory.\n\n6. Run Selective Search\n\t- cd $FRCNN_ROOT/selective_search\n\t- Edit selective_search.m and add image_db = 'home/ubuntu/INRIA/'[Do nothing if using git cloned from my repo]\n\t- Change the last line to\n\tselective_search_rcnn(image_filenames, 'train.mat');\n\t- Run this matlab code\n\t- This generates train.mat [Takes around 15min for this]\n\t- Place it in /home/ubuntu/INRIA\n\n7. Modify Prototxt\n\t- Edit train.prototxt in $FRCNN_ROOT/models/VGG_CNN_M_1024.\n\t- Set num_classes to C [In INRIA data C=2, i.e. Pedestrian and Background]\n\t- Set num_output in the cls_score layer to C\n\t- Set num_output in the bbox_pred layer to 4 * C\n\n8. Run the followin g in $FRCNN_ROOT/\n\t./tools/train_net.py --gpu 0 --solver models/VGG_CNN_M_1024/solver.prototxt \\\n    --weights data/imagenet_models/VGG_CNN_M_1024.v2.caffemodel --imdb inria_train\n\n9. This creates the trained model in $FRCNN_ROOT/output/models folder\n\n\n\n#####################################################################\nTESTING\n#####################################################################\n1. Delete the contents in the INRIA folder created during training.\n2. Create New set of directories in the following way:\n/home/ubuntu/INRIA\n\t\t\t|-- data\n\t\t\t\t|-- Annotations\n\t\t\t\t\t|-- *.txt (Annotation Files)\n\t\t\t\t|-- Images\n\t\t\t\t\t|-- *.png (Image Files)\n\t\t\t\t|-- ImageSets\n\t\t\t\t\t|-- test.txt\n\t\t\t|-- results\n\t\t\t\t|-- test (Empty Directory)\n\t\t\t|-- VOCcode\n3. The test.txt contains all the names(without extensions) of images files that will be used for training.\nFor example:\n\tcrop_000001\n\tcrop_000002\n\tcrop_000003\n\tcrop_000004\n\tcrop_000005\n4. Copy the files from $FRCNN_ROOT/help/INRIA/VOCcode to the /home/ubuntu/INRIA/VOCcode folder.\n5. Run Selective Search again. (Rename the output to test.mat)\n6. Place the test.mat file in /home/ubuntu/INRIA folder\n7. Modify Prototxt\n\t- Edit test.prototxt in $FRCNN_ROOT/models/VGG_CNN_M_1024.\n\t- Set num_output in the cls_score layer to C [In INRIA data C=2, i.e. Pedestrian and Background]\n\t- Set num_output in the bbox_pred layer to 4 * C\n8. Run in $FRCNN_ROOT/ directory:\n\t./tools/test_net.py --gpu 0 --def models/VGG_CNN_M_1024/test.prototxt \\\n    --net output/default/train/vgg_cnn_m_1024_fast_rcnn_iter_40000.caffemodel --imdb inria_test\n\n\n\n\n#######################################################################\nVIEW YOUR RESULTS\n#######################################################################\n1. Look for the file in INRIA/results/test directory. This file has info about the bounding box in each image along with the probability with which it detects it as person\n2. Edit the file cvPlotBox.py:\n\t- Set fileName variable to the above file\n\t- Set imagePath to /home/ubuntu/INRIA/data/Images/\n\t- Set OutPath to the folder where you want to extract your resultant images with box around detected persons.\n\n\n\n\n\t\n\n", 
  "read_at": 1462548552, 
  "description": "", 
  "README.md": "### This code base is no longer maintained and exists as a historical artifact to supplement my ICCV 2015 paper. For more recent work that's faster and more accurrate, please see [Faster R-CNN](https://github.com/rbgirshick/py-faster-rcnn) (which also includes functionality for training Fast R-CNN).\n\n# *Fast* R-CNN: Fast Region-based Convolutional Networks for object detection\n\nCreated by Ross Girshick at Microsoft Research, Redmond.\n\n### Introduction\n\n**Fast R-CNN** is a fast framework for object detection with deep ConvNets. Fast R-CNN\n - trains state-of-the-art models, like VGG16, 9x faster than traditional R-CNN and 3x faster than SPPnet,\n - runs 200x faster than R-CNN and 10x faster than SPPnet at test-time,\n - has a significantly higher mAP on PASCAL VOC than both R-CNN and SPPnet,\n - and is written in Python and C++/Caffe.\n\nFast R-CNN was initially described in an [arXiv tech report](http://arxiv.org/abs/1504.08083) and later published at ICCV 2015.\n\n### License\n\nFast R-CNN is released under the MIT License (refer to the LICENSE file for details).\n\n### Citing Fast R-CNN\n\nIf you find Fast R-CNN useful in your research, please consider citing:\n\n    @inproceedings{girshickICCV15fastrcnn,\n        Author = {Ross Girshick},\n        Title = {Fast R-CNN},\n        Booktitle = {International Conference on Computer Vision ({ICCV})},\n        Year = {2015}\n    }\n    \n### Contents\n1. [Requirements: software](#requirements-software)\n2. [Requirements: hardware](#requirements-hardware)\n3. [Basic installation](#installation-sufficient-for-the-demo)\n4. [Demo](#demo)\n5. [Beyond the demo: training and testing](#beyond-the-demo-installation-for-training-and-testing-models)\n6. [Usage](#usage)\n7. [Extra downloads](#extra-downloads)\n\n### Requirements: software\n\n1. Requirements for `Caffe` and `pycaffe` (see: [Caffe installation instructions](http://caffe.berkeleyvision.org/installation.html))\n\n  **Note:** Caffe *must* be built with support for Python layers!\n\n  ```make\n  # In your Makefile.config, make sure to have this line uncommented\n  WITH_PYTHON_LAYER := 1\n  ```\n\n  You can download my [Makefile.config](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/Makefile.config) for reference.\n2. Python packages you might not have: `cython`, `python-opencv`, `easydict`\n3. [optional] MATLAB (required for PASCAL VOC evaluation only)\n\n### Requirements: hardware\n\n1. For training smaller networks (CaffeNet, VGG_CNN_M_1024) a good GPU (e.g., Titan, K20, K40, ...) with at least 3G of memory suffices\n2. For training with VGG16, you'll need a K40 (~11G of memory)\n\n### Installation (sufficient for the demo)\n\n1. Clone the Fast R-CNN repository\n  ```Shell\n  # Make sure to clone with --recursive\n  git clone --recursive https://github.com/rbgirshick/fast-rcnn.git\n  ```\n  \n2. We'll call the directory that you cloned Fast R-CNN into `FRCN_ROOT`\n\n   *Ignore notes 1 and 2 if you followed step 1 above.*\n   \n   **Note 1:** If you didn't clone Fast R-CNN with the `--recursive` flag, then you'll need to manually clone the `caffe-fast-rcnn` submodule:\n    ```Shell\n    git submodule update --init --recursive\n    ```\n    **Note 2:** The `caffe-fast-rcnn` submodule needs to be on the `fast-rcnn` branch (or equivalent detached state). This will happen automatically *if you follow these instructions*.\n\n3. Build the Cython modules\n    ```Shell\n    cd $FRCN_ROOT/lib\n    make\n    ```\n    \n4. Build Caffe and pycaffe\n    ```Shell\n    cd $FRCN_ROOT/caffe-fast-rcnn\n    # Now follow the Caffe installation instructions here:\n    #   http://caffe.berkeleyvision.org/installation.html\n\n    # If you're experienced with Caffe and have all of the requirements installed\n    # and your Makefile.config in place, then simply do:\n    make -j8 && make pycaffe\n    ```\n    \n5. Download pre-computed Fast R-CNN detectors\n    ```Shell\n    cd $FRCN_ROOT\n    ./data/scripts/fetch_fast_rcnn_models.sh\n    ```\n\n    This will populate the `$FRCN_ROOT/data` folder with `fast_rcnn_models`. See `data/README.md` for details.\n\n### Demo\n\n*After successfully completing [basic installation](#installation-sufficient-for-the-demo)*, you'll be ready to run the demo.\n\n**Python**\n\nTo run the demo\n```Shell\ncd $FRCN_ROOT\n./tools/demo.py\n```\nThe demo performs detection using a VGG16 network trained for detection on PASCAL VOC 2007. The object proposals are pre-computed in order to reduce installation requirements.\n\n**Note:** If the demo crashes Caffe because your GPU doesn't have enough memory, try running the demo with a small network, e.g., `./tools/demo.py --net caffenet` or with `--net vgg_cnn_m_1024`. Or run in CPU mode `./tools/demo.py --cpu`. Type `./tools/demo.py -h` for usage.\n\n**MATLAB**\n\nThere's also a *basic* MATLAB demo, though it's missing some minor bells and whistles compared to the Python version.\n```Shell\ncd $FRCN_ROOT/matlab\nmatlab # wait for matlab to start...\n\n# At the matlab prompt, run the script:\n>> fast_rcnn_demo\n```\n\nFast R-CNN training is implemented in Python only, but test-time detection functionality also exists in MATLAB.\nSee `matlab/fast_rcnn_demo.m` and `matlab/fast_rcnn_im_detect.m` for details.\n\n**Computing object proposals**\n\nThe demo uses pre-computed selective search proposals computed with [this code](https://github.com/rbgirshick/rcnn/blob/master/selective_search/selective_search_boxes.m).\nIf you'd like to compute proposals on your own images, there are many options.\nHere are some pointers; if you run into trouble using these resources please direct questions to the respective authors.\n\n1. Selective Search: [original matlab code](http://disi.unitn.it/~uijlings/MyHomepage/index.php#page=projects1), [python wrapper](https://github.com/sergeyk/selective_search_ijcv_with_python)\n2. EdgeBoxes: [matlab code](https://github.com/pdollar/edges)\n3. GOP and LPO: [python code](http://www.philkr.net/)\n4. MCG: [matlab code](http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/)\n5. RIGOR: [matlab code](http://cpl.cc.gatech.edu/projects/RIGOR/)\n\nApologies if I've left your method off this list. Feel free to contact me and ask for it to be included.\n\n### Beyond the demo: installation for training and testing models\n1. Download the training, validation, test data and VOCdevkit\n\n\t```Shell\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar\n\t```\n\t\n2. Extract all of these tars into one directory named `VOCdevkit`\n\n\t```Shell\n\ttar xvf VOCtrainval_06-Nov-2007.tar\n\ttar xvf VOCtest_06-Nov-2007.tar\n\ttar xvf VOCdevkit_08-Jun-2007.tar\n\t```\n\n3. It should have this basic structure\n\n\t```Shell\n  \t$VOCdevkit/                           # development kit\n  \t$VOCdevkit/VOCcode/                   # VOC utility code\n  \t$VOCdevkit/VOC2007                    # image sets, annotations, etc.\n  \t# ... and several other directories ...\n  \t```\n  \t\n4. Create symlinks for the PASCAL VOC dataset\n\n\t```Shell\n    cd $FRCN_ROOT/data\n    ln -s $VOCdevkit VOCdevkit2007\n    ```\n    Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.\n5. [Optional] follow similar steps to get PASCAL VOC 2010 and 2012\n6. Follow the next sections to download pre-computed object proposals and pre-trained ImageNet models\n\n### Download pre-computed Selective Search object proposals\n\nPre-computed selective search boxes can also be downloaded for VOC2007 and VOC2012.\n\n```Shell\ncd $FRCN_ROOT\n./data/scripts/fetch_selective_search_data.sh\n```\n\nThis will populate the `$FRCN_ROOT/data` folder with `selective_selective_data`.\n\n### Download pre-trained ImageNet models\n\nPre-trained ImageNet models can be downloaded for the three networks described in the paper: CaffeNet (model **S**), VGG_CNN_M_1024 (model **M**), and VGG16 (model **L**).\n\n```Shell\ncd $FRCN_ROOT\n./data/scripts/fetch_imagenet_models.sh\n```\nThese models are all available in the [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo), but are provided here for your convenience.\n\n### Usage\n\n**Train** a Fast R-CNN detector. For example, train a VGG16 network on VOC 2007 trainval:\n\n```Shell\n./tools/train_net.py --gpu 0 --solver models/VGG16/solver.prototxt \\\n\t--weights data/imagenet_models/VGG16.v2.caffemodel\n```\n\nIf you see this error\n\n```\nEnvironmentError: MATLAB command 'matlab' not found. Please add 'matlab' to your PATH.\n```\n\nthen you need to make sure the `matlab` binary is in your `$PATH`. MATLAB is currently required for PASCAL VOC evaluation.\n\n**Test** a Fast R-CNN detector. For example, test the VGG 16 network on VOC 2007 test:\n\n```Shell\n./tools/test_net.py --gpu 1 --def models/VGG16/test.prototxt \\\n\t--net output/default/voc_2007_trainval/vgg16_fast_rcnn_iter_40000.caffemodel\n```\n\nTest output is written underneath `$FRCN_ROOT/output`.\n\n**Compress** a Fast R-CNN model using truncated SVD on the fully-connected layers:\n\n```Shell\n./tools/compress_net.py --def models/VGG16/test.prototxt \\\n\t--def-svd models/VGG16/compressed/test.prototxt \\\n    --net output/default/voc_2007_trainval/vgg16_fast_rcnn_iter_40000.caffemodel\n# Test the model you just compressed\n./tools/test_net.py --gpu 0 --def models/VGG16/compressed/test.prototxt \\\n\t--net output/default/voc_2007_trainval/vgg16_fast_rcnn_iter_40000_svd_fc6_1024_fc7_256.caffemodel\n```\n\n### Experiment scripts\nScripts to reproduce the experiments in the paper (*up to stochastic variation*) are provided in `$FRCN_ROOT/experiments/scripts`. Log files for experiments are located in `experiments/logs`.\n\n**Note:** Until recently (commit a566e39), the RNG seed for Caffe was not fixed during training. Now it's fixed, unless `train_net.py` is called with the `--rand` flag.\nResults generated before this commit will have some stochastic variation.\n\n### Extra downloads\n\n- [Experiment logs](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/fast_rcnn_experiments.tgz)\n- PASCAL VOC test set detections\n    - [voc_2007_test_results_fast_rcnn_caffenet_trained_on_2007_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2007_test_results_fast_rcnn_caffenet_trained_on_2007_trainval.tgz)\n    - [voc_2007_test_results_fast_rcnn_vgg16_trained_on_2007_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2007_test_results_fast_rcnn_vgg16_trained_on_2007_trainval.tgz)\n    - [voc_2007_test_results_fast_rcnn_vgg_cnn_m_1024_trained_on_2007_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2007_test_results_fast_rcnn_vgg_cnn_m_1024_trained_on_2007_trainval.tgz)\n    - [voc_2012_test_results_fast_rcnn_vgg16_trained_on_2007_trainvaltest_2012_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2012_test_results_fast_rcnn_vgg16_trained_on_2007_trainvaltest_2012_trainval.tgz)\n    - [voc_2012_test_results_fast_rcnn_vgg16_trained_on_2012_trainval.tgz](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc_2012_test_results_fast_rcnn_vgg16_trained_on_2012_trainval.tgz)\n- [Fast R-CNN VGG16 model](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/voc12_submission.tgz) trained on VOC07 train,val,test union with VOC12 train,val\n", 
  "id": 56145846
}