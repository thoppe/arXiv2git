{
  "read_at": 1462554900, 
  "description": "an attempt to use arXiv:1409.7495 in data from https://www.kaggle.com/c/flavours-of-physics", 
  "README.md": "![transfer learning](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Knowledge_transfer.svg/312px-Knowledge_transfer.svg.png)\n\n# transfer learning\n\nan attempt to use arXiv:1409.7495 in data from https://www.kaggle.com/c/flavours-of-physics\n\n## transfer-learning / domain adaptation / gradient reversal layer\n\n\nThe authors of [arXiv:1409.7495](http://arxiv.org/abs/1409.7495) show their\nidea of how to train a machine learning classifier on some one domain of data\n(studio photos / simulated events in HEP) and apply it to another domain of\ndata (smartphone photos / real data in HEP). The framework is\n[Caffe](http://caffe.berkeleyvision.org/) with their fork on\n[github](https://github.com/ddtm/caffe/tree/grl).\n\n## flavours of physics\n\nfor obvious reasons I have access to simulated Ds-ph(uu)p events, simulated\nbackground events to Ds-ph(uu)p (i.e. the simulated events used in the training\nof the classifier for t-uuu events in\n[arXiv:1409.8548](http://arxiv.org/abs/1409.8548), but instead of applying the\nt-uuu selection, I use the Ds-ph(uu)p selection). Furthermore, I have a mix of\nreal events with the Ds-ph(uu)p selection (with some real events, some\nbackground events, and I hardly know which are which).\n\n## pack it together\n\nI want to do the following\n\n - train a TMVA classifier (here I know what I'm doing) purely on MC (signal\n   and background) and select in data some events and make a nice invariant\n   mass plot\n\n - train Caffe with only MC events (to see how much performance I gain / lose\n   when using a toolkit I don't know), make an invariant mass plot with the\n   same number of events (see how much cleaner the S/B gets).\n\n - train Caffe with GRL (i.e. labelled MC events and unlabelled data events).\n   Make an invariant mass plot with the same number of events (see how much\n   cleaner the S/B gets). In comparison to the other Caffe network, I will see\n   how much the transferlearning gains in performance.\n\n\n# license\n\nThe project code is licensed under the [MIT license](LICENSE).\n\nThe project logo is from\n[wikipedia](https://commons.wikimedia.org/wiki/File:Knowledge_transfer.svgy)\nand licensed under [CC0\n1.0](https://creativecommons.org/publicdomain/zero/1.0/deed.en).\n", 
  "id": 53138423
}