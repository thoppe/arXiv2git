{
  "read_at": 1462546062, 
  "description": "A parser for arxiv.org astro-ph that will find a list of papers matching keywords and either e-mail it or post it to Slack", 
  "README.md": "# about lazy-astroph.py\n\nThis is a simple script to get the latest papers from astro-ph/arxiv,\nsearch their abstracts and titles for keywords, and report the\nresults.  Reports are done either through e-mail or by posting to\nslack channels using web-hooks.  This way if we forget to read\nastro-ph for a bit, we can atleast get notified of the papers deemed\nimportant to us (and discuss them on slack).\n\n## usage\n\n```\n./lazy-astroph.py [-m e-mail-address] [-w slack-webhook-file] inputs\n```\n\nwhere `inputs` is a file of (case-insensitive) keywords, one per\nline.  Note, ending a keyword with \"-\" will make sure that keyword\nis uniquely matched, and not embedded in another keyword.  Adding\na clause \"NOT:\" to a keyword line followed by common-separated\nterms will result in a match only if the terms following NOT are\nnot found\n\nE.g.,\n\n```\nsupernova               NOT: dark energy, interstellar medium, ISM\nnova-\nxrb\n```\n\nwill return the matching papers containing \"supernova\", so long as\nthey don't also contain \"dark energy\", \"interstellar medium\", or\n\"ISM\".  It will also return papers that contain \"nova\" distinct from\n\"supernova\" (since `\"nova\" in \"supernova\"` is `True` in python).\nAnd it will return those papers containing xrb.\n\nSlack channels are indicated by a line beginning with \"#\", with\nan optional \"requires=N\", where N is the number of keywords\nwe must match before posting a paper to a slack channel.\n\nYou need to create a webhook via slack.  Put the URL into a file\n(just the URL, nothing else) and then pass the name of that\nfile into `lazy-astroph.py` using the `-w` parameter.\n\n\n## automating\n\nTo have this run nightly, add a line to your crontab.  Assuming that\nyou've put the `lazy-astroph.py` script and an `inputs` file in your\n~/bin/, then do something like:\n\n```\ncrontab -e\n```\n\nadd a new line with:\n\n```\n00 04 * * * /home/username/bin/lazy-astroph.py -m me@something.edu /home/username/bin/inputs\n```\n\nreplacing the e-mail with your e-mail and `username` with your username.\n\n\n# arXiv appearance dates\n\narticles appear according to the following schedule:\n\n  ```\n  submitted                    appear\n\n  Th 20:00 -> F  19:59           M\n  F  20:00 -> M  19:59           Tu\n  M  20:00 -> Tu 19:59           W\n  Tu 20:00 -> W  19:59           Th\n  W  20:00 -> Th 19:59           F\n  ```\n  \n  but note that holidays can throw this off by a day or so.\n\nA possible solution is to store in a config file the id of the last\npaper parsed and then start each day by requesting 1000 papers leading\nup to today and go back only until we hit the previously parsed paper.\n\n\n# inspiration\n\n* The basic feedparser mechanism of interacting with the arxiv API\ncame from this example:\n\n   https://github.com/zonca/python-parse-arxiv/blob/master/python_arXiv_parsing_example.py\n\n* The instructions on how to search by date range came from the arxiv API google group:\n\n   https://groups.google.com/forum/#!msg/arxiv-api/I95YLIPesSE/3MZ83Pq_cugJ\n\n   https://groups.google.com/forum/#!searchin/arxiv-api/lastupdateddate/arxiv-api/GkTlg6tikps/C-E5noLbu94J\n\n   \n", 
  "id": 38973582
}