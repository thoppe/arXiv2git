{
  "README": "Neurohex uses Deep Q-learning with a convolutional neural network to learn to play the game of hex through self-play. It is written in python using theano and some lasagne.\n\nmentor.py contains a script which preforms supervised learning over a prescored dataset in order to give the network a decent initialization before q_learning.\n\nq_learn.py contains a script which trains a network by deep Q-learning through self play.\n\nThe directory playerAgents contains program.py which is an executable hex agent that makes use of a trained network which is also included. The included network is inspired by the arcitecture of the value network of Google DeepMind's alphaGo. It was trained by first mentoring a version of a common hex heuristic based on electircal resistance over a dataset generated by a strong hexplayer called wolve (see https://sourceforge.net/projects/benzene/) and then training by selfplay. program.py communicates using the gtp-protocol (https://www.lysator.liu.se/~gunnar/gtp/) and can be played against using an interface like hexgui (https://github.com/ryanbhayward/hexgui).\n\nTo use the code it is nessesary to install numpy and theano.\n\nA paper on Neurohex can be found here: http://arxiv.org/abs/1604.07097\n", 
  "read_at": 1462556482, 
  "description": "", 
  "id": 44132722
}