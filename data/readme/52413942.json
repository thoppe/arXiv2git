{
  "read_at": 1462557683, 
  "description": "A loss function based on the distances between anchor, positive and negative embeddings used in FaceNet", 
  "README.md": "# Triplet Criterion On-the-fly\n\nA loss function based on the distances between anchor, positive and negative embeddings used in \n\"FaceNet: A Unified Embedding for Face Recognition and Clustering\" http://arxiv.org/abs/1503.03832 .\nThe module finds positive and negative embeddings within a current mini-batch on-the-fly,\nso it does not require additional space to save embeddings.\nThis is basically a simpler version of https://github.com/Atcold/torch-TripletEmbedding .\n\n\n## Install\n\nInstall this module via luarocks\n\n```\nluarocks install https://raw.githubusercontent.com/jhjin/triplet-criterion/master/rocks/triplet-scm-1.rockspec\n```\n\n\n## Usage\n\nThe loss function can be used in the same way as other criterions except few parameters as follows.\n\n```lua\nrequire('triplet')\nlocal loss = nn.TripletCriterion(samples, blocks, norm, margin) \n```\n\n+ `samples` : the number of faces sampled from each identity in a batch\n+ `blocks` : the number of identities in a batch (`samples` x `blocks` < `batchSize`)\n+ `norm` : Lp-norm for distances between embeddings (default 2)\n+ `margin` : a hypersphere margin between anchor-positive and anchor-negative pairs (default 0.2)\n\nIn a mini-batch, samples from the same identity should be prepared in a consecutive ordering by thier batch index.\nIn the case of 2 `samples` and 3 `blocks` with a `batchSize` of 8, for example, the batch should be prepared in\n\n| Batch index | Identity                |\n|-------------|-------------------------|\n| 1           | Person A                |\n| 2           | Person A                |\n| 3           | Person B                |\n| 4           | Person B                |\n| 5           | Person C                |\n| 6           | Person C                |\n| 7           | Person randomly sampled |\n| 8           | Person randomly sampled |\n\nFrom the example, anchor and positive embeddings are selected from\nthe first `samples` x `blocks` region (batch index 1~6)\nwhile negative embeddings are selected from\nthe rest (`batchSize` - `samples` x `blocks`) of the region (batch index 7,8).\n\n\n## Training\n\nA large size of batch is preferred in order to let the training converge to a higher score/accuracy.\n", 
  "id": 52413942
}