{
  "README": "PolyChord v 1.4\nWill Handley, Mike Hobson & Anthony Lasenby\nwh260@mrao.cam.ac.uk\narXiv:1502.01856\narXiv:1506.00171\nReleased June 2015\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nPolyChord Licence\n=================\n\nUsers are required to accept the licence agreement given in LICENCE\nfile. PolyChord is free for academic usage\n\nUsers are also required to cite the PolyChord papers: \narXiv:1502.01856\narXiv:1506.00171\nin their publications.\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nMPI Support\n===========\n\nThe code is MPI compatible. To disable the MPI parallelization, \nset MPI=0 in ./Makefile\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nAdditional Libraries  \n====================\n\nPolyChord requires no additional libraries to run in linear mode\nTo run with MPI it requires the openMPI library\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nCompilers\n=========\n\nPolyChord compiles with both gfortran and intel compilers. \n\nCompiler type is chosen in the Makefile with the COMPILER_TYPE flag;\nset\nCOMPILER_TYPE = gnu\nfor gfortran compilers (free)\n\nset\nCOMPILER_TYPE = intel\nfor intel compilers (proprietary, much faster)\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nRunning PolyChord\n=================\n\nExamples\n--------\nFirst, try a couple of quick examples:\n\n1) 20 dimensional Gaussian\n\nrun the commands:\n$  make gaussian\n$  ./bin/gaussian ini/gaussian.ini\n\n2) Rastrigin\n\nrun the commands:\n$ make rastrigin\n$ ./bin/rastrigin ini/rastrigin.ini\n\nThis runs the rastrigin 'bunch of grapes' loglikelihood.\n\nExamples currently provided are:\ngaussian twin_gaussian random_gaussian half_gaussian rastrigin himmelblau rosenbrock eggbox\n\nIn general, binary executables are stored in the directory ./bin, and ini files are\nstored in the directory ./ini.\n\n\n\n\nTo run your own likelihood, it should either be written in fortran, C++, or be callable\nfrom C++ or fortran.\n\nFortran likelihoods\n-------------------\nYou should place your likelihood code in the function loglikelihood,\ncontained in ./likelihoods/my_likelihood.f90. Any setup required (such as reading \nin input files) should be conducted in the function loglikelihood_setup,\nfound in ./likelihoods/my_likelihood.f90.\nIn most cases, this will likely just be a call to your own pre-written library.\n\nYour code can be compiled and run with the commands:\n$  make my_likelihood\n$  ./bin/my_likelihood ini/my_likelihood.ini\nwhere the input file ini/my_likelihood should be modified accordingly\n\nExamples can be found in ./likelihoods/examples\n\nC++ likelihoods\n---------------\nYou should place your likelihood code in the function cpp_loglikelihood,\ncontained in ./likelihoods/my_cpp_likelihood.cpp. Any setup required (such as reading \nin input files) should be conducted in the function cpp_loglikelihood_setup,\nfound in ./likelihoods/my_cpp_likelihood.f90.\nIn most cases, this will likely just be a call to your own pre-written library.\n\nYour code can be compiled and run with the commands:\n$  make my_cpp_likelihood\n$  ./bin/my_cpp_likelihood ini/my_cpp_likelihood.ini\nwhere the input file ini/my_likelihood should be modified accordingly\n\nIf you have an additional suggestions to make the c++ wrapper more easy to use, \nplease email Will (wh260@mrao.cam.ac.uk).\n\n\n\nManual Setup\n------------\nIn some cases, it is desirable to have a more automated setup than that\nprovided by the input files. The general process for this can be found in \n./polychord.F90 in section (1cii)\n\n\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nOutput files \n=============\nPolyChord produces several output files depending on which settings are chosen\n\n\n[root].stats\n------------\nRun time statistics\n\n[root].resume\n--------------------------------------\nFiles for resuming a stopped run. Semi-human readable.\nThis is produced if settings%write_resume=.true.\nThis is used if settings%read_resume=.true.\n\n[root].txt\n----------\nFile containing weighted posterior samples. Compatable with the format required by\ngetdist package which is part of the CosmoMC package. Contains npars+ndims+2 columns:\n\nweight -2*loglike <params> <derived params>\n\nRefer to the following website in order to download or get more information about getdist:\nhttp://cosmologist.info/cosmomc/readme.html#Analysing\n\nIf settings%cluster_posteriors=.true. there are additional cluster files in\nclusters/[root]_<integer>.txt \n\n[root]_equal_weights.txt\n------------------------\nAs above, but the posterior points are equally weighted. This is better for 'eyeballing'\nthe posterior, and provides a natural ~4 fold compression of the .txt file. \n\n\n[root]_phys_live.txt\n--------------------\nLive points in the physical space. This is produced if\nsettings%write_phys_live=.true.\nThis file contains npars+ndims+1 columns, indicating the physical parameters,\nderived parameters and the log-likelihood. This is useful for monitoring a run\nas it progresses. \n\n[root].paramnames\n------------\nParameter names file for compatibility with getdist\n\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nVisualization of PolyChord Output:\n\n[root].txt file created by PolyChord is compatable with the format required by\ngetdist package which is part of the CosmoMC package. Refer to the following\nwebsite in order to download or get more information about getdist:\nhttp://cosmologist.info/cosmomc/readme.html#Analysing\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCommon Problems & FAQs:\n\n\n1. PolyChord crashes after segmentation fault.\n\nTry increasing the stack size:\nLinux:    ulimit -s unlimited \nOSX:      ulimit -s hard \n& resume your job.\nThe slice sampling & clustering steps use a recursive procedure. The default memory\nallocated to recursive procedures is embarassingly small (to guard against memory\nleaks).\n\n\n2. Output files ([root].txt & [root]_equal_weights.dat) files have very few (of order tens) points.\n\nThese files only become populated as the algorithm approaches the peak(s) of the\nposterior. Wait for the run to be closer to finishing.\n\n\n3. MPI doesn't help\n\nCurrently, the MPI parallelisation will only increase speed for 'slow' likelihoods, \ni.e. likelihoods where the slice sampling step is the dominant computational cost \n(compared to the organisation of live points and clustering steps). \n", 
  "read_at": 1462552079, 
  "description": "A slice sampling nested sampling algorithm", 
  "id": 31064867
}