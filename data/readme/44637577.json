{
  "read_at": 1462556000, 
  "description": "Code to synthesise textures using convolutional neural networks as described in Gatys et al. 2015 (http://arxiv.org/abs/1505.07376)", 
  "README.md": "# DeepTextures\nCode to synthesise textures using convolutional neural networks as described in the paper \"Texture Synthesis Using Convolutional Neural Networks\" (Gatys et al., NIPS 2015) (http://arxiv.org/abs/1505.07376).\nMore examples of synthesised textures can be found at http://bethgelab.org/deeptextures/.\n\nThe IPythonNotebook Example.ipynb contains the code to synthesise the pebble texture shown in Figure 3A (177k parameters) of the revised version of the paper. In the notebook I additionally match the pixel histograms in each colorchannel of the synthesised and original texture, which is not done in the figures in the paper.\n#Prerequisites\n* To run the code you need a recent version of the [Caffe](https://github.com/BVLC/caffe) deep learning framework and its dependencies (tested with master branch at commit 20c474fe40fe43dee68545dc80809f30ccdbf99b).\n* The images in the paper were generated using a normalised version of the [19-layer VGG-Network](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)\ndescribed in the work by [Simonyan and Zisserman](http://arxiv.org/abs/1409.1556). The weights in the normalised network are scaled\nsuch that the mean activation of each filter over images and positions is equal to 1.\n**The normalised network can be downloaded [here](http://bethgelab.org/media/uploads/deeptextures/vgg_normalised.caffemodel) and has to be copied into the Models/ folder.**\n\n# Disclaimer\nThis software is published for academic and non-commercial use only. \n", 
  "id": 44637577
}