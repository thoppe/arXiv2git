{
  "read_at": 1462552124, 
  "description": "", 
  "README.md": "# SICS-cite\r\n\r\nThis is a thesis project done at [SICS](https://www.sics.se/). The overall goal of the project is to implement and evaluate a set of algorithms for citation analysis.\r\n\r\n## Dependencies\r\nThe following python modules are used in this project:\r\n* NetworkX\r\n* graph-tool\r\n* pandas (only used for Logistic regression and correlation coefficients)\r\n* Statsmodels (only used for Logistic regression)\r\n\r\n## Directories\r\n\r\n* algorithms - Tools and algorithms used. *Note:* Additional library algorithms are used in the *metrics* directory.\r\n* datasets - Contains rawdata, data, and parse files that create GraphML files from the rawdata. The data files are not available through GitHub due to space limitations.\r\n* metrics - Parsing, calculation, and evaluation of metrics. \r\n* arxivdownload - an arXiv crawler and parser, slow, not tested much\r\n* boost - Some very basic tests using the C++ `boost` library\r\n\r\nThe *algorithms* directory is dependent on the python graph package `NetworkX`. The *metrics* directory uses the python graph package `graph-tool` for all graph processing and `pandas` and `Statsmodels` for statistical analysis.\r\n\r\n## Algorithms\r\nBelow is a list of algorithms used, along with source/package information:\r\n\r\n* **The Backbone algorithm** as described in *'Tracing the Evolution of Physics on the Backbone of Citation Networks'*\r\nby S. Gualdi, C. H. Yeung, Y.-C. Zhang - Found in `algorithms/backbone.py`, implemented with NetworkX.\r\n* **Co-citation graph generation** - Found in `algorithms/co_citation.py` (graph-tool) and in `algorithms/graphutils.py` (`#build_co_citation_graph` (NetworkX)).\r\n* **Indegree** and **betweenness** centralities - Done using graph-tool (indegree is a property for all graph-tool graphs)\r\n* **PageRank** and **HITS** - Done using graph-tool in `metrics/` and using NetworkX in the test file `algorithms/pr_avg_age.py`\r\n* **Burstiness** - Done separately using the [Sci2](https://sci2.cns.iu.edu/) software. Saved as csv files.\r\n\r\n## Workflow\r\nThe approximate workflow is as follows:\r\n\r\n1. Collect raw citation data\r\n2. Build GraphML files using the parse scripts available in each dataset's directory. (Currently available for AAN and APS).\r\n3. Build co-citation graphs using `algorithms/co_citation.py` and backbone graphs using `algorithms/backbone.py`\r\n4. Generate ranked lists for each metric in the `metrics` directory.\r\n5. Evaluate the ranked lists using `metrics/find_fellows.py`.\r\n\r\n### Notes\r\nThe *algorithms* directory have been tested on both FreeBSD 9.3 and Windows 8.\r\nThe *metrics* directory have been tested on Arch Linux 4.0.2-1. The main problem is to get graph-tool up and running, which requires boost.\r\nAll OS's mentioned are x86-64 versions.\r\n\r\nThe test files related to fellows are not very modular, with parsing, checking and plotting done in one file.\r\n", 
  "id": 30461605
}