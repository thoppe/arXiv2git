{
  "read_at": 1462553011, 
  "description": "", 
  "README.md": "#Birdsong Recognition\n\nThis is a source code for the manuscript \"Automatic recognition of element classes and boundaries in the birdsong with variable sequences\" by Takuya Koumura and Kazuo Okanoya (http://arxiv.org/abs/1601.06248).\n\nThis program performs automatic recognition of birdsong and parameter training for the recognizer using given ground truth. The source code includes three algorithms for automatic recognition: \"BD -> LC -> GS\", \"LC -> BD & GS\", and \"Lc & GS -> BD & GS\", each of which is implemented in the classes [main.BdLcGs](birdsong-recognition/src/main/BdLcGs.java), [main.LcBdGs](birdsong-recognition/src/main/LcBdGs.java), and [main.LcGsBdGs](birdsong-recognition/src/main/LcGsBdGs.java). A viewer for an output sequence is also provided in another class, [main.Viewer](birdsong-recognition/src/main/Viewer.java). Please read the manuscript for the detailed description of these three algorithms.\n\nThis program has been tested on 64 bit windows 7 with a graphics processor GTX 980 or 970.\n\n##Test data\n\nTest data for running the program are available at http://marler.c.u-tokyo.ac.jp/files/koumura-okanoya-2016-songs/. It contains annotated songs and expected validation errors in eleven birds. The annotations of all songs are provided in Annotation.xml. Expected validation errors are the ones that would be obtained by running the program with the prefixed hyper parameters in the source code. They are provided for each of three algorithms and in ExpectedError/ErrorBdLcGs.xml, ExpectedError/ErrorLcBdGs.xml, and ExpectedError/ErrorLcGsBdGs.xml. Note that the results will be non-deterministic if backward algorithm is FAST_NON_DETERMINISTIC. Please read the manuscript for the definition of the validation errors.\n\nUsers who would like to perform the computation with their own data must prepare data with the same format as the provided test data. Sound data must be 16 bit linear PCM wave format with any sampling rate. Annotations of the songs must be given in XML format following the schema [xsd/AnnotationSchema.xsd](xsd/AnnotationSchema.xsd). Alternatively, users may modify the source code to load data with arbitrary format.\n\n##Differences from the manuscript\n\n+ Learning rate for parameter updating of the neural network are fixed in the manuscript, but are adaptively determined using Adam method in this source code.\n+ All the hyper parameters are prefixed in the source code. In the manuscript, some of them are optimized by cross-validation within training data.\n+ In the manuscript, in training with the LC & GS -> BD & GS arrangement, first the network with the same structure as the LC -> BD & GS arrangement is trained, and then additional fully-connected layer was inserted before training the whole network. In this source code, the whole network whose parameters were initialized randomly was trained from the beginning.\n\n##Prerequisites\nUsers must prepare following libraries and processors.\n+ Cuda 7.0 (or later) and a Cuda compatible graphics processor.\n+ Cudnn ver. 3.\n+ JCuda (http://www.jcuda.org/).\n+ JDK 8.\n\nAlso, users must compile [cuda-kernels/kernel.cu](cuda-kernels/kernel.cu) into PTX file. The path to the PTX file must be set in the main methods.\n\n##Libraries\nOther libraries used in this program are as follows (listed in [pom.xml](birdsong-recognition/pom.xml)).\n+ Java native access.\nhttps://github.com/java-native-access/jna\n+ JNAerator.\nhttps://github.com/nativelibs4java/JNAerator\n+ Commons Math.\nhttps://commons.apache.org/proper/commons-math/\n+ Xerces.\nhttps://xerces.apache.org/\n+ Matrix toolkits java.\nhttps://github.com/fommil/matrix-toolkits-java\n\nAlthough this program does not include it as a library, https://github.com/tbennun/cudnn-training has been very helpful for writing the program.\n\n##License\nThis program is distributed under the term of GNU public license ver. 3. The copy of the license is in  [LICENSE](LICENSE).\n\n##Grants\nThis project is supported by...\n+ Grant-in-Aid for Scientific Research (A) (#26240019), MEXT/JSPS, Japan, to KO.\n+ Grant-in-Aid for JSPS Fellows, MEXT/JSPS, Japan (#15J09948) to TK.\n\n-\nCopyright &copy; 2016 Takuya KOUMURA\n", 
  "id": 48950087
}