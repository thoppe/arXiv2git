{
  "read_at": 1462554964, 
  "description": "From Pixels to Sentiment: Fine-tuning CNNs for Visual Sentiment Prediction", 
  "README.md": "# From Pixels to Sentiment: Fine-tuning CNNs for Visual Sentiment Prediction\n\n| ![Victor Campos][VictorCampos-photo]  | ![Brendan Jou][BrendanJou-photo] |  ![Xavier Giro-i-Nieto][XavierGiro-photo]  | \n|:-:|:-:|:-:|:-:|:-:|\n| Victor Campos | [Brendan Jou](http://www.ee.columbia.edu/~bjou/) |  [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro) |\n\n\n[VictorCampos-photo]: ./figures/authors/VictorCampos.jpg \"Victor Campos\"\n[BrendanJou-photo]: ./figures/authors/BrendanJou.png \"Brendan Jou\"\n[XavierGiro-photo]: ./figures/authors/XavierGiro.jpg \"Xavier Giro-i-Nieto\"\n\n\n\nA joint collaboration between:\n\n|  ![logo-upc] | ![logo-etsetb] | ![logo-gpi] | ![logo-columbia] | ![logo-dvmmlab] |\n|:-:|:-:|:-:|:-:|:-:|\n| [Universitat Politecnica de Catalunya (UPC)](http://www.upc.edu/?set_language=en)   | [UPC ETSETB TelecomBCN](https://www.etsetb.upc.edu/en/)  | [UPC Image Processing Group](https://imatge.upc.edu/web/) | [Columbia University](https://www.columbia.edu/ ) | [Digital Video and Multimedia Lab (DVMM)](www.ee.columbia.edu/dvmm)  |\n\n[logo-upc]: ./figures/logos/upc.jpg \"Universitat Politecnica de Catalunya\"\n[logo-etsetb]: ./figures/logos/etsetb.png \"ETSETB TelecomBCN\"\n[logo-gpi]: ./figures/logos/gpi.png \"UPC Image Processing Group\"\n[logo-columbia]: ./figures/logos/columbia.png \"Columbia University\"\n[logo-dvmmlab]: ./figures/logos/dvmm.gif \"Digital Video and Multimedia Lab\"\n\n\n## Abstract\nVisual media have become a crucial part of our social lives. The throughput of generated multimedia content, together with its richness for conveying sentiments and feelings, highlights the need of automated visual sentiment analysis tools. We explore how Convolutional Neural Networks (CNNs), a computational learning paradigm that has shown outstanding performance in several vision tasks, can be applied to the task of visual sentiment prediction by fine-tuning a state-of-the-art CNN. We analyze its architecture, studying several performance boosting techniques, which led to a network tuned to achieve a 6.1% absolute accuracy improvement over the previous state-of-the-art on a dataset of images from a popular social media platform. Finally, we present visualizations of local patterns that the network associates to each image's sentiment.\n\n\n## Publication\n\nOur [preprint](http://arxiv.org/abs/1604.03489) is publicly available on arXiv. You can also find it indexed [on gitxiv](http://gitxiv.com/posts/ruqRgXdPTHJ77LDEb/from-pixels-to-sentiment-fine-tuning-cnns-for-visual).\n\n\nPlease cite with the following Bibtex code:\n\n````\n@article{campos2016from,\n  title={From Pixels to Sentiment: Fine-tuning CNNs for Visual Sentiment Prediction},\n  author={Campos, Victor and Jou, Brendan and Giro-i-Nieto, Xavier},\n  journal={arXiv preprint arXiv:1604.03489},\n  year={2016}\n}\n```\n\nYou may also want to refer to our publication with the more human-friendly APA style:\n\n*(not published yet)*\n\n\n## Sentiment Maps\n\n![Sentiment maps](./figures/SentimentMaps.png)\n\n## Models\n\nThe weights for the best CNN model can be downloaded from [here](https://imatge.upc.edu/web/sites/default/files/projects/affective/public_html/2017-imavis/twitter_finetuned_test4_iter_180.caffemodel) (217 MB). These same weights, modified to fit the fully convolutional architecture used to generate the sentiment maps, can be downloaded from [here](https://imatge.upc.edu/web/sites/default/files/projects/affective/public_html/2017-imavis/twitter_finetuned_test4_iter_180_conv.caffemodel) (217 MB).\n\nThe deep network was developed over [Caffe](http://caffe.berkeleyvision.org/) by [Berkeley Vision and Learning Center (BVLC)](http://bvlc.eecs.berkeley.edu/). You will need to follow [these instructions](http://caffe.berkeleyvision.org/installation.html) to install Caffe.\n\n\n## Acknowledgments\n\nWe would like to especially thank Albert Gil Moreno and Josep Pujal from our technical support team at the Image Processing Group at  UPC.\n\n| ![AlbertGil-photo]  | ![JosepPujal-photo]  |\n|:-:|:-:|\n| [Albert Gil](https://imatge.upc.edu/web/people/albert-gil-moreno)  |  [Josep Pujal](https://imatge.upc.edu/web/people/josep-pujal) |\n\n[AlbertGil-photo]: ./figures/authors/AlbertGil.jpg \"Albert Gil\"\n[JosepPujal-photo]: ./figures/authors/JosepPujal.jpg \"Josep Pujal\"\n\n|   |   |\n|:--|:-:|\n|  We gratefully acknowledge the support of [NVIDIA Corporation](http://www.nvidia.com/content/global/global.php) with the donation of the GeForce GTX [Titan Z](http://www.nvidia.com/gtx-700-graphics-cards/gtx-titan-z/) and [Titan X](http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-titan-x) used in this work. |  ![logo-nvidia] |\n|  The Image Processing Group at the UPC is a [SGR14 Consolidated Research Group](https://imatge.upc.edu/web/projects/sgr14-image-and-video-processing-group) recognized and sponsored by the Catalan Government (Generalitat de Catalunya) through its [AGAUR](http://agaur.gencat.cat/en/inici/index.html) office. |  ![logo-catalonia] |\n|  This work has been developed in the framework of the project [BigGraph TEC2013-43935-R](https://imatge.upc.edu/web/projects/biggraph-heterogeneous-information-and-graph-signal-processing-big-data-era-application), funded by the Spanish Ministerio de Economia y Competitividad and the European Regional Development Fund (ERDF).  | ![logo-spain] | \n\n[logo-nvidia]: ./figures/logos/nvidia.jpg \"Logo of NVidia\"\n[logo-catalonia]: ./figures/logos/generalitat.jpg \"Logo of Catalan government\"\n[logo-spain]: ./figures/logos/MEyC.png \"Logo of Spanish government\"\n\n\n\n## Contact\n\nIf you have any general doubt about our work or code which may be of interest for other researchers, please use the [public issues section](https://github.com/imatge-upc/sentiment-2016-imavis/issues) on this github repo. Alternatively, drop us an e-mail at <mailto:xavier.giro@upc.edu>.\n", 
  "id": 54727764
}