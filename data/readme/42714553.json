{
  "read_at": 1462548703, 
  "description": "caffe for Similarity Learning", 
  "README.md": "# caffe-sl\n\n`caffe`-based implementation of the Deep Similarity Learning algorithm used in the [MM 2014 paper](http://dl.acm.org/citation.cfm?id=2654948).\nOther similarity learning algorithms are still under development.\n\n\n## Example\n\n`caffe-sl` is fully compatible with `caffe`, please follow the instructions from the project site of [`caffe`](http://caffe.berkeleyvision.org/) to build `caffe-sl` before you start.\n\n```!bash\n# get the MNIST dataset\n./data/mnist/get_data.sh\n# extract images and generate triplets\n./examples/mnist_sl/create_mnist.sh\n# training\n./examples/mnist_sl/train_lenet_naive.sh \n```\n\n\n## Notes\n\n### 1. Input data\n\n`caffe-sl` loads data with `TripletImageDataLayer`, which works with a triplet list file contains image paths:\n\n```!bash\ncaffe-sl $ head examples/mnist_sl/data/train.tri \n040846.png      051449.png      041185.png\n024899.png      033969.png      039096.png\n000520.png      022406.png      006979.png\n025207.png      020904.png      020818.png\n054660.png      040836.png      023925.png\n009412.png      035528.png      003730.png\n033029.png      011219.png      017586.png\n053240.png      033959.png      007701.png\n021132.png      042217.png      015489.png\n021732.png      028399.png      031010.png\n...\n```\n\nThe first column consists of query images, the second column consists of positive images, and the third column consists of negative images.\n\n### 2. Loss layer\n\nThe example use cosine similarity.\nThe output of the last feature layer is normalized and then feed to the NaiveTripletLossLayer.\nThe NaiveTripletLossLayer splits the features into three parts: query, positive, and negative features and compute hinge loss on triplet:\n\n```\nl(qry, pos, neg) = max{0, margin - S(qry, pos) + S(qry, neg)}\n```\n\n<!--\n## Citation\n\nPlease cite the following paper if you use this code:\n\n```\n@inproceedings{wan2014deep,\n  title={Deep learning for content-based image retrieval: A comprehensive study},\n  author={Wan, Ji and Wang, Dayong and Hoi, Steven Chu Hong and Wu, Pengcheng and Zhu, Jianke and Zhang, Yongdong and Li, Jintao},\n  booktitle={Proceedings of the ACM International Conference on Multimedia},\n  pages={157--166},\n  year={2014},\n  organization={ACM}\n}\n```\n-->\n\n## New Layers\n\n### finished\n\n- `TripletImageDataLayer`     load image data in triplet manner\n- `TripletBinaryDataLayer`    load binary data in triplet manner\n- `BinaryDataLayer`           similar to ImageDataLayer\n\n- `L2NormLayer`               l2-normalization\n- `DotProductSimilarityLayer` element-wise dot-product similarity\n- `EuclideanSimilarityLayer`  element-wise euclidean similarity\n\n- `BatchTripletLossLayer`     triplet based similarity learning in batch mode\n- `NaiveTripletLossLayer`     triplet based similarity learning in list mode\n- `PairwiseRankingLossLayer`  pair wise learning to rank\n- `RankAccuracyLayer`         ranking accuracy\n\n\n### unfinished\n\n- `HDMLLossUpperBoundLayer`   Hamming distance metric learning\n\n\n------------------------------------------------\n\n# Caffe\n\n[![Build Status](https://travis-ci.org/BVLC/caffe.svg?branch=master)](https://travis-ci.org/BVLC/caffe)\n[![License](https://img.shields.io/badge/license-BSD-blue.svg)](LICENSE)\n\nCaffe is a deep learning framework made with expression, speed, and modularity in mind.\nIt is developed by the Berkeley Vision and Learning Center ([BVLC](http://bvlc.eecs.berkeley.edu)) and community contributors.\n\nCheck out the [project site](http://caffe.berkeleyvision.org) for all the details like\n\n- [DIY Deep Learning for Vision with Caffe](https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.p)\n- [Tutorial Documentation](http://caffe.berkeleyvision.org/tutorial/)\n- [BVLC reference models](http://caffe.berkeleyvision.org/model_zoo.html) and the [community model zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)\n- [Installation instructions](http://caffe.berkeleyvision.org/installation.html)\n\nand step-by-step examples.\n\n[![Join the chat at https://gitter.im/BVLC/caffe](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/BVLC/caffe?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nPlease join the [caffe-users group](https://groups.google.com/forum/#!forum/caffe-users) or [gitter chat](https://gitter.im/BVLC/caffe) to ask questions and talk about methods and models.\nFramework development discussions and thorough bug reports are collected on [Issues](https://github.com/BVLC/caffe/issues).\n\nHappy brewing!\n\n## License and Citation\n\nCaffe is released under the [BSD 2-Clause license](https://github.com/BVLC/caffe/blob/master/LICENSE).\nThe BVLC reference models are released for unrestricted use.\n\nPlease cite Caffe in your publications if it helps your research:\n\n    @article{jia2014caffe,\n      Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n      Journal = {arXiv preprint arXiv:1408.5093},\n      Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n      Year = {2014}\n    }\n", 
  "id": 42714553
}