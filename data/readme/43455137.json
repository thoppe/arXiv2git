{
  "read_at": 1462548712, 
  "description": "This repository contains the source code for the semantic image segmentation method described in the ICCV 2015 paper: Conditional Random Fields as Recurrent Neural Networks. http://crfasrnn.torr.vision/", 
  "README.md": "# CRF-RNN for Semantic Image Segmentation\n![sample](sample.png)\n\n<b>Live demo:</b> [http://crfasrnn.torr.vision](http://crfasrnn.torr.vision)\n<b>update:</b> This version of code is integrated with the latest caffe future version.\n\nThis package contains code for the \"CRF-RNN\" semantic image segmentation method, published in the ICCV 2015 paper [Conditional Random Fields as Recurrent Neural Networks](http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf). This paper was initially described in an [arXiv tech report](http://arxiv.org/abs/1502.03240). Our software is built on top of the [Caffe](http://caffe.berkeleyvision.org/) deep learning library. The current version was developed by:\n\n[Sadeep Jayasumana](http://www.robots.ox.ac.uk/~sadeep/),\n[Shuai Zheng](http://kylezheng.org/),\n[Bernardino Romera Paredes](http://romera-paredes.com/), and\n[Zhizhong Su](suzhizhong@baidu.com).\n\nSupervisor: [Philip Torr](http://www.robots.ox.ac.uk/~tvg/)\n\nOur work allows computers to recognize objects in images, what is distinctive about our work is that we also recover the 2D outline of the object.\n\nCurrently we have trained this model to recognize 20 classes. This software allows you to test our algorithm on your own images - have a try and see if you can fool it, if you get some good examples you can send them to us.\n\nWhy are we doing this? This work is part of a project to build augmented reality glasses for the partially sighted. Please read about it here: [smart-specs](http://www.va-st.com/smart-specs/). \n\nFor demo and more information about CRF-RNN please visit the project website <http://crfasrnn.torr.vision>.\n\nIf you use this code/model for your research, please consider citing the following paper:\n```\n@inproceedings{crfasrnn_ICCV2015,\n    author = {Shuai Zheng and Sadeep Jayasumana and Bernardino Romera-Paredes and Vibhav Vineet and Zhizhong Su and Dalong Du and Chang Huang and Philip H. S. Torr},\n    title  = {Conditional Random Fields as Recurrent Neural Networks},\n    booktitle = {International Conference on Computer Vision (ICCV)},\n    year   = {2015}\n}\n```\n\n\n#Installation Guide\nFirst, you should clone the project by doing as below.\n```\ngit clone --recursive https://github.com/torrvision/crfasrnn.git\n```\n\nYou need to compile the modified Caffe library in this repository. Instructions for Ubuntu 14.04 are included below. You can also consult the generic [Caffe installation guide](http://caffe.berkeleyvision.org/installation.html).\n\n\n###1.1 Install dependencies\n#####General dependencies\n```\nsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler\nsudo apt-get install --no-install-recommends libboost-all-dev\n```\n\n#####CUDA \nInstall CUDA correct driver and its SDK. Download CUDA SDK from Nvidia website. \n\nIn Ubuntu 14.04. You need to make sure the required tools are installed. You might need to blacklist the required modules so that they do not interfere with the driver installation. You also need to uninstall your default Nvidia Driver first.\n```\nsudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa libglu1-mesa-dev\n``` \nopen /etc/modprobe.d/blacklist.conf and add:\n```\nblacklist amd76x_edac\nblacklist vga16fb\nblacklist nouveau\nblacklist rivafb\nblacklist nvidiafb\nblacklist rivatv\n```\n```\nsudo apt-get remove --purge nvidia*\n```\n\nWhen you restart your PC, before loging in, try \"Ctrl+Alt+F1\" switch to a text-based login. Try:\n```\nsudo service lightdm stop\nchmod +x cuda*.run\nsudo ./cuda*.run\n```\n\n#####BLAS\nInstall ATLAS or OpenBLAS or MKL.\n\n#####Python \nInstall Anaconda Python distribution or install the default Python distribution with numpy/scipy/...\n\n#####MATLAB (optional)\nInstall MATLAB using a standard distribution.\n\n###1.2 Build the custom Caffe version\nSet the path correctly in the Makefile.config. You can copy the Makefile.config.example to Makefile.config, as most common parts are filled already. You need to change it according to your environment.\n\nAfter this, in Ubuntu 14.04, try:\n```\nmake\n```\n\nIf there are no error messages, you can then compile and install the python and matlab wrappers:\n```\nmake matcaffe\n```\n\n```\nmake pycaffe\n```\n\nThat's it! Enjoy our software!\n\n\n###1.3 Run the demo\nMatlab and Python scripts for running the demo are available in the matlab-scripts and python-scripts directories, respectively. You can choose either of them. Note that you should change the paths in the scripts according your environment.\n\n####For Python fans:\nFirst you need to download the model. In Linux, this is:\n```\nsh download_trained_model.sh\n```\nAtlernatively, you can also get the model by directly clicking the link in python-scripts/README.md.\n\nGet into the python-scripts folder, and then type:\n```\npython crfasrnn_demo.py\n```\nYou will get an output.png image.\n\nTo use your own images, just replace \"input.jpg\" in the crfasrnn_demo.py file.\n\n####For Matlab fans:\nFirst you need to download the model. In Linux, this is:\n```\nsh download_trained_model.sh\n```\nAtlernatively, you can also get the model by directly clicking the link in matlab-scripts/README.md.\n\nGet into the matlab-scripts folder, load your matlab, then run the crfrnn_demo.m.\n\nTo use your own images, just replace \"input.jpg\" in the crfrnn_demo.m file.\n\nYou can also find part of our model in [MatConvNet](http://www.vlfeat.org/matconvnet/pretrained/).\n\n####Explanation about the CRF-RNN layer:\nIf you would like to try out the CRF-RNN model we trained, you should keep the layer name as it is \"inference1\", so that the code will load the parameters from caffemodel. Otherwise, it will use the parameters set by the users in the deploy.prototxt file.\n\nYou should find out that the end-to-end trained CRF-RNN model does better than the alternatives. If you set the CRF-RNN layer name to \"inference2\", you should observe lower performance since the parameters for both CNN and CRF are not jointly optimized.\n\n\n####For training purpose:\nIf you would like to train the CRF-RNN model on other dataset, please follow the piecewise steps described in our paper. You should first train a strong pixel-wise CNN model. After this, you could plug in our CRF-RNN layer into those model by adding the layer to the prototxt. Then you should be able to train the CNN and CRF-RNN layer end-to-end.\n\nNotice that the current deploy.prototxt file we provided is tailed for PASCAL VOC Challenge. This dataset contains 21 class labels including background. You should change the num_output in the corresponding layer if you would like to finetune our model for other dataset. Also, the deconvolution layer in current code does not allow initialize the parameters through prototxt. If you change the num_output there, you should manually re-initialize the parameters in caffemodel file.\n\nSee the examples/segmentationcrfasrnn.\n\n####why predictions are all black?\nThis could because you set different names for classifier in prototxt, causing the weights are not properly load. This is could also because you change the number of outputs in deconvolution layer in prototxt but you didnot initialize the deconvolution layer properly. \n\n####MultiStageMeanfield seg fault?\nThis error message occurs when you didnot place the spatial.par and bilateral.par in the script path.\n\n####Python training script from third parties\nWe would like to thank Martinkersner Masahiro Imai to provide python training scripts for crf-rnn. \n\n1. [martinkersner python scripts for Train-CRF-RNN](https://github.com/martinkersner/train-CRF-RNN)\n2. [MasazI python scripts for crfasrnn-training](https://github.com/MasazI/crfasrnn-training)\n\n####Merge with the upstream caffe\nThis is possible to integrate the crfrnn layer into upstream caffe. However, due to the change of crop layers, the caffemodel we provided might require extra training to provide the same accuracy. mtourne Kindly provided a version that merged the code with upstream caffe. \n\n1. [mtourne upstream version with CRFRNN](https://github.com/mtourne/crfasrnn)\n\n####GPU version of CRF-RNN\nhyenal kindly provided a purely GPU version of CRF-RNN. This would lead to considerable faster training and testing for CRF-RNN.\n\n1. [hyenal's GPU crf-rnn](https://github.com/hyenal/crfasrnn)\n\nLet us know if we miss any other works from third parties.\n\n# LICENSE\nCRF-RNN feature in Caffe is implemented for the paper:\nShuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip H. S. Torr.\nConditional Random Fields as Recurrent Neural Networks. IEEE ICCV 2015.\n\nShuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, and Philip H. S. Torr are with University of Oxford.\nVibhav Vineet did this work when he was with the University of Oxford, he is now with the Stanford University.\nZhizhong Su, Dalong Du, Chang Huang are with the Baidu Institute of Deep Learning (IDL).\n\nCRF-RNN uses the Permutohedral lattice library, the DenseCRF library and the Caffe future version.\n\nPermutohedral lattice library (BSD license) is from Andrew Adams, Jongmin Baek, Abe Davis. Fast High-Dimensional Filtering Using the\nPermutohedral Lattice. Eurographics 2010.\nDenseCRF library from Philipp Krahenbuhl and Vladlen Koltun. Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials.\nNIPS 2011.\n\nFor more information about CRF-RNN please vist the project website http://crfasrnn.torr.vision.\n", 
  "id": 43455137
}