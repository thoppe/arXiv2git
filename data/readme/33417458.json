{
  "README": "The purpose of this code is to collect data and instantiate a Crux-ified\nversion of MongoDB on PlanetLab. At a high level, the Crux protocol is a \nmeans of preserving locality in communication in a large distributed\nnetwork by instantiating smaller copies of the distributed system on\nsubsets of the larger network.\n\nFor more information about Crux, please refer to the original paper by\nNowlan, Faleiro, and Ford at http://arxiv.org/abs/1405.0637\n\nPlease note that a couple major assumptions are made about the structure\nof the Crux network and about communication. They are as follows.\n 1. That communication A -> B takes the same time as messages from B -> A\n 2. That the triangle inequality holds in all messaging, that is:\n    \t (A -> B -> C) >= (A -> C)\n 3. Rings are inclusive. See the original Crux paper on\n    http://arxiv.org/pdf/1405.0637v1.pdf for more detail.\n 4. Given a landmark node running multiple rings, if there are no new nodes\n    that would join ring i+1 that do not appear in some ring <= i, then we\n    do not instantiate an i+1 ring, and continue onto i+2.\n\nFollowing are the sequence of commands needed to collect timing data,\nconfigure network setup, and deploy the Mongo databases on remote PlanetLab \nhosts.\n\n============================================================================\n======================= Initial network creation ===========================\n============================================================================\n\n# Initially collect hostname information for all nodes on planetlab slice\n#  using the get_slice_nodes.py script. Takes in an output folder and the\n#  username of the planetlab account. Will prompt for a password on call.\n\npython get_slice_nodes.py nodes.txt christine.hong@yale.edu; \n\n# After collecting all nodes, run the following script to remove any nodes\n#  which are dead/unreachable. The list of live nodes will be saved in a new\n#  text file called 'aliveNodes.txt', which should be either renamed to\n#  nodes.txt or explicitly passed in as the node list in future calls.\n\npython removeDeadNodes.py -nodes nodes.txt;\nmv aliveNodes.txt nodes.txt;\t # rename aliveNodes to nodes\n\n# To assign landmark values/rank to all nodes, run the landmark.py script\n#  on the nodes file. The -b flag represents the probability of upgrading\n#  the rank of a node. This script creates new file 'rank.txt'.\n#\n#  NOTE: rank information will not be used until bunches are constructed\n#    after the collection of timing data.\n\npython landmark.py -file nodes.txt -b 4;\n\n# Construct a text file containing all pairs of planetlab nodes in the\n#  network. This will be used to determine who pings who for timing\n#  data collection. Output is a file 'pairs.txt'.\n\npython makeHostPairList.py -nodes nodes.txt\n\n\n============================================================================\n======================== Timing Data Collection ============================\n============================================================================\n\n# Before doing anything else, it may be helpful to remove any old files that\n#  remain on planetlab from prior testing. To do this, simply run the script\n\npython cleanPL.py -nodes nodes.txt;\n\n# All timing data must be collected between the nodes in the network, so we\n#  move all necessary files to planetlab using the filesToPlanetLab.py\n#  script. The -item flag specifies files to move, and may be used to specify\n#  a directory to copy. For simplicity, simply move 'pairs.txt' into the \n#  directory named plStuff and copy plStuff over to planetlab nodes specified\n#  by the -nodes flag.\n\nmv pairs.txt plStuff/\npython filesToPlanetLab.py -item plStuff -nodes nodes.txt\n\n# Once all files are transferred over, run the pingAndBunch.py script to\n#  ssh into each node in nodes.txt and execute timing collection. Upon\n#  calling this script, everything will sleep until all ping data is collected.\n#  Creates 'pings.txt' in the plStuff folder on all planetlab nodes.\n#\n# Timing data is collected via the pingNodePairs.sh shell script in plStuff,\n#  which requires the 'pairs.txt' file created above.\n#\n# WARN: running this script will open up ssh subprocesses for each node given\n#   in nodes.txt. Please do not run multiple times simultaneously and wait to\n#   continue until all processes have terminated.\n\npython pingAndBunch.py -nodes nodes.txt\n\n# Once all ping data is collected remotely, run the recoverPings python script\n#  to collect all the ping data locally and compile it into one local 'pings.txt'.\n#\n# NOTE: recoverPings.py creates a new local directory 'pl_pings' where all ping\n#   data will be stored during processing. Once execution finishes, all the data\n#   collected is removed by the script and all that is left is 'pl_pings/pings.txt'\n\npython recoverPings.py -nodes nodes.txt\n\n================================================================================\n=============================== Ring Construction ==============================\n================================================================================\n\n#\tBUNCHES:\n# After all timing data is collected, we use the ping times and the ranks\n#  calculated in setup to determine a bunch for each node in the network.\n#  A node's bunch consists of all other nodes with which the given node will\n#  interact with. At this stage we do not determine which rings to join, we are\n#  simply determining which nodes will have a ring that we communicate with.\n#\n# The bunches will be saved in a local directory called bunches, and each bunch\n#  is saved in a text file specified as '<node_name>_bunch.txt'. The bunches\n#  directory will be cleaned then recreated during execution by the script.\n#\n# Bunches are saved as text file in the <node> <ping time> format, one per line\n#  like below:\n#\n#\tN1  23\n#\tN2  48\n#\tN5  129\n#\tetc.\n\npython createBunches.py -nodes nodes.txt -ping plStuff/pings.txt -rank rank.txt;\n\n#      CLUSTERS:\n# Bunches are then used to create the cluster for each node. A cluster is in\n#  some ways the opposite of a bunch: the bunch is all nodes that a node will\n#  interact with, whereas a cluster consists of the nodes which will interact\n#  with the host node's rings.\n#\n# All cluster data will be stored in a directory called 'clusters' which is\n#  created by the script after removing all old cluster data. Clusters for each\n#  node are saved with the names '<node_name>_cluster.txt'.\n# The files are formatted as a list of <node> <ping time> pairs, one on each line\n#  in increasing order of ping time. E.g,\n#\n#\tA  13.5\n#\tB  29.3\n#\tC  107.2\n#\tetc.\n\npython configure_clusters.py -nodes nodes.txt;\n\n#create ring list for every cluster -> all rings saved locally into a ring folder\npython rings.py --min 2 --max 20\n\n================================================================================\n============================== Trading System ==================================\n================================================================================\n\n# We can run our basic Crux-ified MongoDB trading system by calling:\n\npython trader.py ports.txt rings.txt instructions.txt binpath\n\n# on each participant node, where binpath is the bin directory of MongoDB. Note\n# that all of the necessary config files must be formed for given node A: \n\n# \tports.txt, containing a line for each ring centered on A, specifying\n# \tthe port which the instance of MongoDB for that ring should use;\n\n# \trings.txt, containing a line for each ring that A is involved in, consisting\n# \tof the hostname and port (whitespace-delineated) on which that ring is\n# \trunning;\n\n#\tand instructions.txt, containing the actual transaction instructions for each\n# \tnode to carry out (more below).\n\n# Given these specifications, the trading program will initialize N instances of\n# MongoDB, where N is the number of lines/ports in ports.txt, and it will\n# also create N data folders. It will then wait for input before running\n# the commands in instructions.txt (to ensure synchronicity).\n\n\n# INSTRUCTIONS:\n# We interact with our trading algorithm through a simple API, using commands\n# specified in instructions.txt.  This is obviously best suited for a test\n# environment; in practical deployments it would be a simple measure to\n# use real-time input instead of a set of instructions.\n\n# The API is specified here:\n\n \tpost [BUY/SELL] [ITEM]\n\n# \tPosts a BUY or SELL request for item ITEM to all rings in rings.txt, using\n# \tthe Crux algorithm (starting with the smallest rings and expanding outward\n# \tto preserve locality).\n\n \tfind [ITEM]\n\n# \tSearches for a request containing item ITEM using the Crux algorithm on\n# \trings in rings.txt.  To preserve locality, when the item is found in a \n# \tgiven ring, it is immediately returned and the search is halted.\n\n\n", 
  "read_at": 1462511532, 
  "description": "Yale Senior Project: Practical Application of Crux Algorithm ( http://arxiv.org/pdf/1405.0637v1.pdf)", 
  "id": 33417458
}