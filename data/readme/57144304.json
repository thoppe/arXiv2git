{
  "read_at": 1462548472, 
  "description": "", 
  "README.md": "SME\n===\nThe architecture of this package has been designed by **Xavier Glorot** (https://github.com/glorotxa), with some contributions from **Antoine Bordes** (https://www.hds.utc.fr/~bordesan).\n\n**Update (Nov 13):** the code for Translating Embeddings (see https://everest.hds.utc.fr/doku.php?id=en:transe) has been included along with a new version for Freebase (FB15k).\n\n1. Overview\n-----------------------------------------------------------------\n\nThis package proposes scripts using Theano to perform training and evaluation on several datasets of the models: \n- **Structured Embeddings** (SE) defined in (Bordes et al., AAAI 2011);\n- **Semantic Matching Energy** (SME_lin & SME_bil) defined in (Bordes et al., MLJ 2013);\n- **Translating Embeddings** (TransE) defined in (Bordes et al., NIPS 2013).\n- **TATEC** defined in (Garcia-Duran et al., ECML14, arxiv15).\n\n\nPlease refer to the following pages for more details and references:  \n- https://everest.hds.utc.fr/doku.php?id=en:smemlj12\n- https://everest.hds.utc.fr/doku.php?id=en:transe\n- https://everest.hds.utc.fr/doku.php?id=en:2and3ways\n\nContent of the package:\n- model.py : contains the classes and functions to create the different models and Theano functions (training, evaluation...).\n- {dataset}_exp.py : contains an experiment function to train all the different models on a given dataset.\n- The data/ folder contains the data files for the learning scripts.\n- in the {dataset}/ folders:\n\t* {dataset}_parse.py : parses and creates data files for the training script of a given dataset.\n\t* {dataset}_evaluation.py : contains evaluation functions for a given dataset.\n\t* {dataset}\\_{model_name}.py : runs the best hyperparameters experiment for a given dataset and a given model.\n\t* {dataset}\\_{model_name}.out : output we obtained on our machines for a given dataset and a given model using the script above.\n\t* {dataset}_test.py : perform quick runs for small models of all types to test the scripts.\n\nThe datasets currently available are:\n * **Multi-relational benchmarks** (Kinhsips, UMLS & Nations -- Tensor folder) to be downloaded from https://everest.hds.utc.fr/doku.php?id=en:smemlj12\n * **WordNet** (WN folder) to be downloaded from https://everest.hds.utc.fr/doku.php?id=en:smemlj12\n * **Freebase** (FB folder) used in (Bordes et al., AAAI 2011) to be downloaded from https://everest.hds.utc.fr/doku.php?id=en:smemlj12\n * **Freebase15k** (FB15k folder)  used in (Bordes et al., NIPS 2013) to be downloaded from https://everest.hds.utc.fr/doku.php?id=en:transe\n * **Synthethic family database** (Family folder) user is (Garcia-Duran et al. arxiv15a) to be downloaded from https://everest.hds.utc.fr/doku.php?id=en:2and3ways\n\n\n\n2. 3rd Party Libraries\n-----------------------------------------------------------------\n\nYou need to install Theano to use those scripts. It also requires: Python >= 2.4, Numpy >=1.5.0, Scipy>=0.8.\nThe experiment scripts are compatible with Jobman but this library is not mandatory.\n\n\n3. Installation\n-----------------------------------------------------------------\n\nPut the script folder in your PYTHONPATH.\n\n\n4. Data Files Creation\n-----------------------------------------------------------------\n\nPut the absolute path of the downloaded dataset (from: https://everest.hds.utc.fr/doku.php?id=en:smemlj12 or  https://everest.hds.utc.fr/doku.php?id=en:transe) at the beginning of the {dataset}_parse.py script and run it (the SME folder has to be your current directory). Note: Running Tensor_parse.py generates data for both Kinhsips, UMLS & Nations.\n\n5. Training and Evaluating a Model\n-----------------------------------------------------------------\n\nSimply run the corresponding {dataset}_{model_name}.py file (the SME/{dataset}/ folder has to be your current directory) to launch a training. When it's over, running {dataset}_evaluation.py with the path to the best_valid_model.pkl of the learned model runs the evaluation on the test set\n\n6. Citing\n-----------------------------------------------------------------\n\nIf you use this code, you could provide the link to the github page: https://github.com/glorotxa/SME . Also, depending on the model used, you should cite either the paper on **Structured Embeddings** (Bordes et al., AAAI 2011), on **Semantic Matching Energy** (Bordes et al., MLJ 2013) or on **Translating Embeddings** (Bordes et al., NIPS 2013).\n\n7. References\n-----------------------------------------------------------------\n- (Garcia-Duran et al., arxiv 15) *Combining Two And Three-Way Embeddings Models for Link Prediction in Knowledge Bases* Alberto Garcia-Duran, Antoine Bordes, Nicolas Usunier and Yves Grandvalet. http://arxiv.org/abs/1506.00999\n- (Bordes et al., NIPS 2013) *Translating Embeddings for Modeling Multi-relational Data* (2013). Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston and Oksana Yakhnenko. In Proceedings of Neural Information Processing Systems (NIPS 26), Lake Taho, NV, USA. Dec. 2013.\n- (Bordes et al., MLJ 2013) *A Semantic Matching Energy Function for Learning with Multi-relational Data* (2013). Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. in Machine Learning. Springer, DOI: 10.1007/s10994-013-5363-6, May 2013\n- (Bordes et al., AAAI 2011) *Learning Structured Embeddings of Knowledge Bases* (2011). Antoine Bordes, Jason Weston, Ronan Collobert and Yoshua Bengio. in Proceedings of the 25th Conference on Artificial Intelligence (AAAI), AAAI Press.\n\n", 
  "id": 57144304
}