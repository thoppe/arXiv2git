{
  "read_at": 1462554905, 
  "description": "Code for the tracker described in the CVPR16 paper \"Staple: Complementary Learners for Real-Time Tracking\"", 
  "README.md": "# Staple tracker\nCode of the paper **Staple: Complementary Learners for Real-Time Tracking**, by Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik and Philip Torr (University of Oxford) - to appear in CVPR 2016.\n\n###Contacts\nFor questions about the code or the paper, feel free contact us.\nYou can find more info at the project page: http://robots.ox.ac.uk/~luca/staple.html\n\nPlease cite\n```\n@article{bertinetto2015staple,\n  title={Staple: Complementary Learners for Real-Time Tracking},\n  author={Bertinetto, Luca and Valmadre, Jack and Golodetz, Stuart and Miksik, Ondrej and Torr, Philip},\n  journal={arXiv preprint arXiv:1512.01355},\n  year={2015}\n}\n```\n\n###Prerequisites\n - The code is mostly in MATLAB, except the workhorse of `fhog.m`, which is written in C and comes from Piotr Dollar toolbox http://vision.ucsd.edu/~pdollar/toolbox\n - gradientMex and mexResize have been compiled and tested for Ubuntu and Windows 8 (64 bit). You can easily recompile the sources in case of need.\n - To use the webcam mode (`runTracker_webcam`), install MATLAB's webcam support from http://mathworks.com/hardware-support/matlab-webcam.html\n\n###Modes\n* `runTracker(sequence, start_frame)` runs the tracker on `sequence` from `start_frame` onwards.\n* `runTracker_webcam` starts an interactive webcam demo.\n* `runTracker_VOT` and `run_Staple` run the tracker within the benchmarks VOT and OTB respectively.\n\n###Format\nFor `runTracker(sequence, start_frame)`, make sure the directory tree looks like the following:\n\n    - staple/\n        - runTracker.m\n        - thisTracker.m\n        - ... \n\n    - Sequences/\n        - ball/\n        - bicycle/\n        - (any other sequence with the specified format)\n\nEach sequence folder should have the following structure\n- `<sequence_name>`/\n    - imgs/\n        - 00000000.jpg (must be 8digit, any img format allowed)\n        - 00000001.jpg\n        - ...\n    - groundtruth.txt\n    - `<sequence_name>`_frames.txt\n\n* `<sequence_name>`_frames.txt contains the interval of frames to track\n* groundtruth.txt contains the per frame annotation. The ground truth bounding box can be expressed as a polygon, i.e. `<x1>,<y1>,<x2>,<y2>,<x3>,<y3>,<x4>,<y4>`, or as an axis-aligned bounding box, i.e.`<top-x>,<top-y>,<width>,<height>`\n\n###F.A.Q.\n> How can I reproduce the exact same results of the paper?\n\nCheckout the code at the commit tagged `cvpr16_results`, other commits and future versions might perform differently.\nAs it is stated in the paper, the performance have been obtained using the last commit of the [VOT toolkit](https://github.com/votchallenge/vot-toolkit) available at the time of the paper submission (`d3b2b1d`).\n\n", 
  "id": 55072558
}