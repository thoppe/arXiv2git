{
  "read_at": 1462550065, 
  "description": "math hierarchical temporal memory", 
  "README.md": "# math hierarchical temporal memory (mHTM)\r\n\r\n## Introduction\r\nmath HTM (mHTM) is a Python build of hierarchical temporal memory (HTM). This build specifically utilizes the [cortical learning algorithms (CLA)] (http://numenta.com/assets/pdf/whitepapers/hierarchical-temporal-memory-cortical-learning-algorithm-0.2.1-en.pdf). A mathematical framework was developed for HTM. This library is built off that framework. The framework is currently only for the spatial pooler (SP); however, it is by no means limited to expand. This implementation was specifically designed to be a completely accurate representation of HTM. Additionally, care was taken to ensure that efficient computations are occurring.\r\n\r\nWe have recently submitted a paper to IEEE TNNLS explaining this work. A preprint is available on [arXiv] (http://arxiv.org/abs/1601.06116).\r\n\r\nTo aid in tying HTM into the machine learning community, this implementation was built to be compatible with [Scikit-Learn] (http://scikit-learn.org/stable/). If you are familiar with Scikit-Learn, this API should feel natural. Additionally, because the Scikit-Learn interface is used, the SP in this implementation may be used in many of the pre-existing Scikit-Learn tools, namely those utilizing [cross-validation (CV)](http://scikit-learn.org/stable/modules/cross_validation.html). A custom [parameter generator] (http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.ParameterSampler.html) was constructed, explicitly for that purpose.\r\n\r\nThe implementation of the SP is single-threaded; however, multiple forms of parallelizations for cross-validation and parameter optimization exist. For a local machine, simply using one of Scikit-Learn's CV functions supporting parallelization should suffice. For a cluster environment, code is provided to create and launch jobs.\r\n\r\nThis package is platform independent and should run on any system containing the prerequisites. If you are using a cluster, the cluster must be running SLURM, and as such must be a valid Linux distribution.\r\n\r\n## Prerequisites\r\n### Required\r\nThese prerequisites are needed for working with the base installation:\r\n\r\n* [Python 2.7.X](https://www.python.org/downloads/release/python-279/) (all other versions are untested)\r\n\r\n* [Numpy] (http://www.numpy.org/)\r\n\r\n* [matplotlib] (http://matplotlib.org/)\r\n\r\n* [Scipy] (http://www.scipy.org/)\r\n\r\n* [Scikit-Learn] (http://scikit-learn.org/stable/)\r\n\r\n* [Bottleneck] (http://berkeleyanalytics.com/bottleneck)\r\n\r\n### Optional\r\nThese prerequisites are needed by some of the experimental code or for other development purposes:\r\n\r\n* [Joblib] (https://pythonhosted.org/joblib/index.html)\r\n\r\n* [Epydoc] (http://sourceforge.net/projects/epydoc/files)\r\n\r\n* [graphviz] (http://www.graphviz.org/Download..php)\r\n\r\n## Installation\r\n1. Install all prerequisites\r\n\r\n    1. If you have [pip] (https://pip.pypa.io/en/latest/installing.html)\r\n\r\n            pip install numpy matplotlib scipy scikit-learn bottleneck\r\n\t\r\n    2. If you are on Windows\r\n  \r\n        You may download the the (unofficial) precompiled versions available from [UCI] (http://www.lfd.uci.edu/~gohlke/pythonlibs). Simply download the appropriate Python wheel and install it using pip, i.e. `pip install my_file.whl`, where `my_file` is the name of your `whl` file.\r\n\r\n2. Download this repo and execute `python setup.py install`\r\n\r\n## Usage\r\nThe API is fully documented and available in the \"docs\" folder. Simply open \"index.html\" in your favorite web browser. For convience, click [here] (http://techtorials.me/mHTM/) to browse the docs.\r\n\r\nAs a starting point, examples have been prepared for working with MNIST. The dataset is additionally, included. Refer to \"mnist_simple.py\" in \"src/examples\" for a basic introduction into the API. In that same folder, refer to \"mnist_parallel\" for examples for using parallelizations locally or an cluster.\r\n\r\nThe \"dev\" folder contains the latest code regarding new experiments. This content is subject to change at any point and is not guaranteed to work; however, it can also be used as a basis for exploring this library.\r\n\r\n## Citing this Work\r\nWhile this code is completely free of charge, it is highly appreciated that all\r\nuses of this code are cited (both in publications as well as within any modified code). Once the IEEE TNNLS paper is approved please cite that work. For now, please cite the preprint:\r\n\r\nJ. Mnatzaganian, E. Fokou&eacute;, and D. Kudithipudi, \"A Mathematical Formalization of Hierarchical Temporal Memory Cortical Learning Algorithm's Spatial Pooler,\" arXiv preprint arXiv:1601.06116, 2016.\r\n\r\n## Bug Reports and Support\r\nNo official support is provided; however, support may be provided. To ensure all feedback is within the same location, please use the Wiki for asking general questions and create issues if any bugs are found.\r\n\r\n## Author\r\nThe original author of this code was James Mnatzaganian. For contact info, as well as other details, see his corresponding [website](http://techtorials.me).\r\n\r\nThis work was created at RIT's [NanoComputing Research Laboratory] (http://www.rit.edu/kgcoe/nanolab/).\r\n\r\n## Legal\r\nThis code is licensed under the [MIT license](http://opensource.org/licenses/mit-license.php), with one caveat. Numenta owns patents on specific items. While this code was written without using any of Numenta's code, it is possible that those patent laws still apply. Before using this code, commercially, it is recommended to seek legal advice.", 
  "id": 48449012
}