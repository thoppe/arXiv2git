{
  "read_at": 1462555127, 
  "description": "Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual Sentiment Prediction", 
  "README.md": "# Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual Sentiment Prediction\n\n\n| ![Victor Campos][VictorCampos-photo]  | ![Amaia Salvador][AmaiaSalvador-photo]  |  ![Xavier Giro-i-Nieto][XavierGiro-photo]  | ![Brendan Jou][BrendanJou-photo] |\n|:-:|:-:|:-:|:-:|:-:|\n| Victor Campos | [Amaia Salvador](https://imatge.upc.edu/web/people/amaia-salvador) |   [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro)   | [Brendan Jou](http://www.ee.columbia.edu/~bjou/) |\n\n\n[VictorCampos-photo]: ./figures/authors/VictorCampos.jpg \"Victor Campos\"\n[AmaiaSalvador-photo]: ./figures/authors/AmaiaSalvador.jpg \"Amaia Salvador\"\n[XavierGiro-photo]: ./figures/authors/XavierGiro.jpg \"Xavier Giro-i-Nieto\"\n[BrendanJou-photo]: ./figures/authors/BrendanJou.png \"Brendan Jou\"\n\n\n\nA joint collaboration between:\n\n|  ![logo-upc] | ![logo-etsetb] | ![logo-gpi] | ![logo-columbia] | ![logo-dvmmlab] |\n|:-:|:-:|:-:|:-:|:-:|\n| [Universitat Politecnica de Catalunya (UPC)](http://www.upc.edu/?set_language=en)   | [UPC ETSETB TelecomBCN](https://www.etsetb.upc.edu/en/)  | [UPC Image Processing Group](https://imatge.upc.edu/web/) | [Columbia University](https://www.columbia.edu/ ) | [Digital Video and Multimedia Lab (DVMM)](www.ee.columbia.edu/dvmm)  |\n\n[logo-upc]: ./figures/logos/upc.jpg \"Universitat Politecnica de Catalunya\"\n[logo-etsetb]: ./figures/logos/etsetb.png \"ETSETB TelecomBCN\"\n[logo-gpi]: ./figures/logos/gpi.png \"UPC Image Processing Group\"\n[logo-columbia]: ./figures/logos/columbia.png \"Columbia University\"\n[logo-dvmmlab]: ./figures/logos/dvmm.gif \"Digital Video and Multimedia Lab\"\n\n\n## Abstract\nVisual media are powerful means of expressing emotions and sentiments. The constant generation of new content in social networks highlights the need of automated visual sentiment analysis tools. While Convolutional Neural Networks (CNNs) have established a new state-of-the-art in several vision problems, their application to the task of sentiment analysis is mostly unexplored and there are few studies regarding how to design CNNs for this purpose. In this work, we study the suitability of fine-tuning a CNN for visual sentiment prediction as well as explore performance boosting techniques within this deep learning setting. Finally, we provide a deep-dive analysis into a benchmark, state-of-the-art network architecture to gain insight about how to design patterns for CNNs on the task of visual sentiment prediction.\n\n\n## Publication\n\nPlease cite with the following Bibtex code:\n\n````\n@inproceedings{campos2015diving,\n  title={Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual Sentiment Prediction},\n  author={Campos, Victor and Salvador, Amaia and Giro-i-Nieto, Xavier and Jou, Brendan},\n  booktitle={Proceedings of the 1st International Workshop on Affect \\& Sentiment in Multimedia},\n  pages={57--62},\n  year={2015},\n  organization={ACM}\n}\n```\n\nYou may also want to refer to our publication with the more human-friendly APA style:\n\n*Campos, V., Salvador, A., Giro-i-Nieto, X., & Jou, B. (2015, October). [Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual Sentiment Prediction](http://dl.acm.org/citation.cfm?id=2813530). In Proceedings of the 1st International Workshop on Affect & Sentiment in Multimedia (pp. 57-62). ACM.*\n\nA [preprint](http://arxiv.org/abs/1508.05056) of the paper is publicly available on arXiv.\nMore details can be found in [our slides](http://www.slideshare.net/xavigiro/diving-deep-into-sentiment-understanding-finetuned-cnns-for-visual-sentiment-prediction) at ASM 2015, and the related [bachelor thesis report and video](https://imatge.upc.edu/web/publications/layer-wise-cnn-surgery-visual-sentiment-prediction) by Victor Campos at ETSETB TelecomBCN in July 2015.\n\n## Slides\n\n<iframe src=\"//www.slideshare.net/slideshow/embed_code/key/83vW3d0dYwJkSv\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;\" allowfullscreen> </iframe> <div style=\"margin-bottom:5px\"> <strong> <a href=\"//www.slideshare.net/xavigiro/diving-deep-into-sentiment-understanding-finetuned-cnns-for-visual-sentiment-prediction\" title=\"Diving deep into sentiment: Understanding fine-tuned CNNs for visual sentiment prediction\" target=\"_blank\">Diving deep into sentiment: Understanding fine-tuned CNNs for visual sentiment prediction</a> </strong> from <strong><a target=\"_blank\" href=\"//www.slideshare.net/xavigiro\">Xavier Giro</a></strong> </div>\n\n## Models\n\nThe weights for the best CNN model can be downloaded from [here](https://imatge.upc.edu/web/sites/default/files/projects/affective/public_html/2015-asm/twitter_finetuned_test4_iter_180.caffemodel) (217 MB).\n\nThe deep network was developed over [Caffe](http://caffe.berkeleyvision.org/) by [Berkeley Vision and Learning Center (BVLC)](http://bvlc.eecs.berkeley.edu/). You will need to follow [these instructions](http://caffe.berkeleyvision.org/installation.html) to install Caffe.\n\n\n## Acknowledgments\n\nWe would like to especially thank Albert Gil Moreno and Josep Pujal from our technical support team at the Image Processing Group at  UPC.\n\n| ![AlbertGil-photo]  | ![JosepPujal-photo]  |\n|:-:|:-:|\n| [Albert Gil](https://imatge.upc.edu/web/people/albert-gil-moreno)  |  [Josep Pujal](https://imatge.upc.edu/web/people/josep-pujal) |\n\n[AlbertGil-photo]: ./figures/authors/AlbertGil.jpg \"Albert Gil\"\n[JosepPujal-photo]: ./figures/authors/JosepPujal.jpg \"Josep Pujal\"\n\n|   |   |\n|:--|:-:|\n|  We gratefully acknowledge the support of [NVIDIA Corporation](http://www.nvidia.com/content/global/global.php) with the donation of the GeForce GTX [Titan Z](http://www.nvidia.com/gtx-700-graphics-cards/gtx-titan-z/) and [Titan X](http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-titan-x) used in this work. |  ![logo-nvidia] |\n|  The Image Processing Group at the UPC is a [SGR14 Consolidated Research Group](https://imatge.upc.edu/web/projects/sgr14-image-and-video-processing-group) recognized and sponsored by the Catalan Government (Generalitat de Catalunya) through its [AGAUR](http://agaur.gencat.cat/en/inici/index.html) office. |  ![logo-catalonia] |\n|  This work has been developed in the framework of the project [BigGraph TEC2013-43935-R](https://imatge.upc.edu/web/projects/biggraph-heterogeneous-information-and-graph-signal-processing-big-data-era-application), funded by the Spanish Ministerio de Economia y Competitividad and the European Regional Development Fund (ERDF).  | ![logo-spain] | \n\n[logo-nvidia]: ./figures/logos/nvidia.jpg \"Logo of NVidia\"\n[logo-catalonia]: ./figures/logos/generalitat.jpg \"Logo of Catalan government\"\n[logo-spain]: ./figures/logos/MEyC.png \"Logo of Spanish government\"\n\n\n\n## Contact\n\nIf you have any general doubt about our work or code which may be of interest for other researchers, please use the [public issues section](https://github.com/imatge-upc/sentiment-2015-asm/issues) on this github repo. Alternatively, drop us an e-mail at <mailto:xavier.giro@upc.edu>.\n\n\n\n\n<!---\nJavascript code to enable Google Analytics\n-->\n\n<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-7678045-6', 'auto');\n  ga('send', 'pageview');\n\n</script>\n", 
  "id": 53411608
}