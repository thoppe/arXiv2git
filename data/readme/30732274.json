{
  "read_at": 1462551957, 
  "description": "Implementation of the [Locally Scale-Invariant Convolutional Neural Network](http://www.umiacs.umd.edu/~kanazawa/papers/sicnn_workshop2014.pdf)", 
  "README.md": "Locally Scale-Invariant ConvNet Caffe Implementation\n=============\n\nThis packages implements the scale-invariant ConvNet used in our [NIPS\n2014 Deep Learning & Representation Workshop paper](http://www.umiacs.umd.edu/~kanazawa/papers/sicnn_workshop2014.pdf).\n\nIt's based on [BVLC's Caffe](http://caffe.berkeleyvision.org), final merge\nwith BVLC/master was on [Oct 20th 2014](https://github.com/BVLC/caffe/commit/c18d22eb92488f02c0256a3fe4ac20a8ad827596).\n\nInstallation\n---\nRequires all of Caffe's prerequisite packages. Compile as you would\ncompile Caffe i.e. have the right Makefile.config and\n```\nmake all\nmake test\nmake runtest\n```\n\nChanges to BVLC/Caffe\n---\nThe major additions are:\n\n1. `util/transformation.(hpp/cpp/cu)`\n   Misc functions needed to apply image transformation using NN\n   or bilinear interpolation.\n2. `ticonv_layer.cpp`\n   `TIConvolutionLayer` a wrapper around `UpsamplingLayer`,\n   `tiedconv_layer` and `DownpoolLayer`. This is what you can use\n   instead of convolution layer to use SI-Conv layer.\n3. `up_layer.cpp`\n   Contains `UpsamplingLayer` which applies user specified interpolations to the\n   bottom blob. i.e. TransformationLayer.\n4. `downpool_layer.cpp`\n   Contains `DownpoolLayer`, which is almost the same as `UpsamplingLayer`, but after applying transformations, crops\n   the inputs into a canonical shape and does max-pooling over all transformations. \n5. `tiedconv_layer.cpp`\n   Convolutional layer that can apply convolution to multiple inputs\n   using the same weight. Very close to current (Jan 2015) Caffe's\n   `ConvolutionalLayer` except that the input size can vary.\n6. `util/imshow.(hpp/cpp)`\n   (not necessary), used for debugging images in C++ using openCV\n   behaves like matlab's imshow and montage.\n7. And all the misc changes needed to adapt the changes into the rest of the\n   code.\n\nAll major changes are implemented in both CPU and GPU with tests.\n\nTechnical Note: since CUDA's `atomicAdd`, required in backprop fo transformation\nlayer isn't available for doubles, this code only runs for `float`\ninstantiation of Caffe (which shouldn't be a problem since default\nCaffe runs in `float`). But because of that, all explicit instantiation\nfor `doubles` are commented out.\n\n\nHow to use SI-Conv Layer instead of Conv Layer\n---\nIn your protofiles, replace the type of the layer from `CONVOLUTION` to\n`TICONV` and add transformations that you want to apply to this\nlayer. Note that `TICONV` layer assumes that the first transformation is always\nidentity and is the canonical size.\n\nExample:\n\nA Convolution Layer:\n\n\t layers {\n\t   name: \"conv1\"\n\t   type: CONVOLUTION\n\t   bottom: \"data\"\n\t   top: \"conv1\"\n\t   blobs_lr: 1.\n\t   blobs_lr: 2.\n\t   weight_decay: 1.\n\t   weight_decay: 0.\n\t   convolution_param {\n\t\t num_output: 36\n\t\t kernel_size: 7\n\t\t stride: 1\n\t\t weight_filler {\n\t\t   type: \"gaussian\"\n\t\t   std: 0.01\n\t\t }\n\t\t bias_filler {\n\t\t   type: \"constant\"\n\t\t }\n\t   }\n\t }\n\nA Scale-Invariant Convolution Layer:\n\n\t layers {\n\t   name: \"conv1\"\n\t   type: CONVOLUTION\n\t   bottom: \"data\"\n\t   top: \"conv1\"\n\t   blobs_lr: 1.\n\t   blobs_lr: 2.\n\t   weight_decay: 1.\n\t   weight_decay: 0.\n\t   convolution_param {\n\t\t num_output: 36\n\t\t kernel_size: 7\n\t\t stride: 1\n\t\t weight_filler {\n\t\t   type: \"gaussian\"\n\t\t   std: 0.01\n\t\t }\n\t\t bias_filler {\n\t\t   type: \"constant\"\n\t\t }\t\t \n\t   }\n\t   transformations {}\n\t   transformations { scale: 0.63 }\n\t   transformations { scale: 0.7937 }\n\t   transformations { scale: 1.2599 }\n\t   transformations { scale: 1.5874 }\n\t   transformations { scale: 2 }\n\t }\n\nTransformations parameter accepts parameters:\n- `scale`: scale-factor\n- `rotation`: rotation in degrees\n- `border`: border option similar to matlab {0=crop (default), 1=clamp, 2=reflect} \n- `interp`: interpolation option {0=Nearest Neighbor, 1=Bilinear\n  (default)}\nSo it can handle transformations other than scale as well.\nSample protos can be found in `models/sicnn/protos`.\n\nReplicating the results on paper\n---\nGet the MNIST-Scale train/test folds in hdf5 format (mean subtracted) from\n[here](http://angjookanazawa.com/sicnn/mnist-sc-table1.tar.gz)\nand unzip it in `data/mnist` or from this directory:\n\n```\ncd data/mnist\nwget http://angjookanazawa.com/sicnn/mnist-sc-table1.tar.gz\ntar vxzf mnist-sc-table1.tar.gz\n```\n\n`models/sicnn` has sample prototxt for vanila convnet, hierarchical\nconvnet of Farabet et al [1] and si-convnet used in ther paper for\nsplit 1. From this directory each one can be run with:\n\n```\n./train_all.sh cnn\n./train_all.sh farabet\n./train_all.sh sicnn\n```\n\nNote: There was a minor bug in the transformation code which further\nimproved SI-ConvNet mean error on the 6 train/test fold from 3.13%\nto 2.93%. The performance on the other two models stayed the same.\nOn this split 1, this SI-ConvNet should get something like 2.91% error.\n\nCiting\n---\nIf you find any part of this code useful, please consider\nciting:\n\n\t@misc{kanazawa14,\n\tauthor    = {Angjoo Kanazawa and Abhishek Sharma and David W. Jacobs},\n\ttitle     = {Locally Scale-Invariant Convolutional Neural Networks},\n\tyear      = {2014},\n\turl       = {http://arxiv.org/abs/1412.5104},\n\tEprint = {arXiv:1412.5104}\n\t}\n\nas well as the Caffe Library.\n\n\t@misc{Jia13caffe,\n\t\tAuthor = {Yangqing Jia},\n\t\tTitle = { {Caffe}: An Open Source Convolutional Architecture\n\t\tfor Fast Feature Embedding},\n\t\tYear = {2013},\n\t\tHowpublished = {\\url{http://caffe.berkeleyvision.org/}}\n\t}\n\nQuestions, comments, bug report\n---\nPlease direct any questions, comment, bug report etc to\nkanazawa[at]umiacs[dot]umd[dot]edu.\n\n[1] Clement Farabet, Camille Couprie, Laurent Najman and Yann LeCun,\n\"Learning Hierarchical Features for Scene Labeling\", IEEE PAMI 2013.\n", 
  "id": 30732274
}