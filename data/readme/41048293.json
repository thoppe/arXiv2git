{
  "read_at": 1462545848, 
  "description": "Galvanize Project Fall 2015", 
  "README.md": "# Project\nGalvanize Project Fall 2015\n\nThis document is a work-in-progress.  Please ask if you have questions\n\nThe Arxiv is an academic pre-print respository hosted by Cornell University (www.arxiv.org). \nThe goal of this project is to build a paper recommender using the arxiv as the dataset. \nThe app is currently live at www.arxivexplorer.com.  Please keep trying if the page is down.  The app is running on AWS and thus needs to be restarted a few times per week.  I will try to refresh it as often as possible.\n\nThere are two algorithms integrated into the app. \nThe first is a classification algorithm that predicts the subject classification \n(Number Theory, Algebraic Geometry, etc) of a given paper based on the text.\nThe algorithm is currently only trained on mathematics papers. \nIn the future I would like to extend it to other subjects. The second algorithm is a \nrecommendation algorithm, which is currently trained on Number Theory papers. Given a paper, \nthe recommender finds the five most similar number theory papers posted on the arxiv in 2015 \n(through August). In the future I would like the train the recommender on more subjects.\n\nFor the predictions, the data was the text of each paper, and the targets were the given labels.  The data was first\ntransformed using tfidf, using one- and two-grams and 10000 top features.  Then classification was done\nusing Logistic Regression and a One vs. All approach.  This was warranted because there are\n32 separate mathematics sub-categories.  I tested several different models through cross-validation before\nsettling on logistic regression.  The ROC curves for each sub-category can be seen on the app and in the \nCreate_ROC_and_Heatmaps notebook.  In the end I have an accuracy of about 54%, which is pretty good in such a large\nmulti-class problem.\n\nThe recommender also uses tfidf, but only 150 features.  10000 dimensional space is too large for a recommender because\nno vectors are actually close to one another in a dimension so high.  One- and two-grams were also used here.  \nThen the distance between each article is computed (I used cosine similarity, \nbut other distance metrics could be explored), and similar papers are recommended.\n\nBoth of the tfidf models use a custom set of math-specific stop words.  There is also code for latent feature\nextraction via NMF and LDA.  That is an avenue I am very excited to explore more fully, but it is\nnot currently integrated into the app.  I think that looking\nat how the features change in time will be very interesting.  More data will need to be collected to fully explore\nthat.\n\nAll the relevant functions live in math_scraping_and_recommending_functions.py, \nand the data collection pipeline can be found in the Math_data_collection notebook.  Details about the classification\n model are in models.py\n", 
  "id": 41048293
}