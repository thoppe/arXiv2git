{
  "read_at": 1462826587, 
  "description": "Mixed Incremental Cross-Entropy REINFORCE ICLR 2016", 
  "README.md": "# MIXER - Sequence Level Training with Recurrent Neural Networks\nhttp://arxiv.org/abs/1511.06732\n\nThis is a self contained software accompanying the paper titled: Sequence Level\nTraining with Recurrent Neural Networks: http://arxiv.org/abs/1511.06732.\nThe code allows you to reproduce our result on the machine translation task.\n\nThe code implements MIXER; it runs both training and evaluation.\n\n## Preparing the training data\nrun prepareData.sh\n\n## Examples\nHere are some examples of how to use the code.\n\n* To run an LSTM with the default parameter setting used to generate MIXER's entry for machine translation (see table in fig.5 of http://arxiv.org/abs/1511.06732), type\n```\nth -i main.lua\n```\n\n* To run an LSTM with following\nhyper-parameters:\n** hidden units: 128\n** minibatch size: 64\n** learning rate: 0.1\n** number of time steps we unfold: 15\ntype\n```\nth -i main.lua -nhid 128 -bsz 64 -lr 0.1 -bptt 15\n```\n\nTo list all the options available, you need to type\n```\nth main.lua --help\n```\n\n## Requirements\nThe software is written in Lua. It requires the following packages:\n* Torch 7\n* nngraph\n* cutorch\n* cunn\nIt runs on standard Linux box with GPU.\n\n## Installing\nDownload the files in an appropriate directory and run the code from there. See below.\n\n\n## How it works\nThe top level file is called main.lua. In order to run the code\nyou need to run the file using torch. For example:\n```\nth -i main.lua -<option1_name> option1_val -<option2_name> option2_val ...\n```\n\n## Structure of the code.\n* main.lua this is the scripts that launches training and testing. The user can pass options to set various hyper-parameters, such as learning rate, number of hidden units, etc.\n* Trainer.lua  this is a simple class that loops over the dataset a certain number of epochs to train the model, that loops over the validation/test set to evaluate and that backups.\n* model_factory.lua  this is a function which returns the network operating at a single time step.\n* Mixer.lua  this is the class which implements the unrolled recurrent network, cloning as many steps as necessary whatever is returned by model_factory. It implements the basic the basic fprop/bprop through the recurrent model.\n* ReinforceSampler.lua  class that is used to sample from a tensor storing log-probabilities.\n* ReinforceCriterion.lua  criterion which is used to compute reward once the end of sequence is reached.\n* ClassNLLCriterionWeighted.lua  wrapper around ClassNLLCriterion which multiplies the output of ClassNLLCriterion by a scalar to weigh the loss.\n* LinearNoBackpropInput.lua  just like Linear but without computing derivatives w.r.t. input.\n* DataSource.lua  data provider that takes as input a tokenized dataset in binary format and returnes mini-batches.\n* reward_factory.lua  class that is used to compute BLEU and ROUGE scores (both at the sentence and corpus level).\n* util.lua  auxiliary functions.\n\n## License\n\"MIXER\"'s software is BSD-licensed.\nWe also provide an additional patent grant.\n\n\n## Other Details\nSee the CONTRIBUTING file for how to help out.\n", 
  "id": 56177401
}