{
  "read_at": 1462548466, 
  "description": "A convolutional neural network for handwritten kanji recognition, written using Keras.", 
  "README.md": "# CNN-for-handwritten-kanji\n\n#####Requirements:  \n - Python 2.7\n - Keras 1.0 with Tensorflow (I used version 0.7) or Theano (I used version 0.8)\n - scipy, numpy\n - hdf5 linux package, and h5py package for python\n\n######Note:  \nYou can install hdf5 and h5py as follows:  \n - sudo apt-get install libhdf5-serial-dev  \n - sudo pip install h5py  \n\n\n#####Performance\nBelow is the performance on validation set when using 40000-10000 training-validation split.  \n\n- 97.4% with no preprocessing and no data augmentation, achieved by \"model.py\".\n- 98.5% with elastic deformations as a dataset augmentation method (increasing dataset ten times), achieved by \"model_for_augmented_dataset.py\".\n- 97.2% with no preprocessing and no data augmentation, achieved by \"model30x30.py\". This version rescales the input images to 30 by 30 pixels as opposed to 32 by 32 pixels in all the other models.\n\n\n\n#####If you want to use a pretrained model to classify your own images:\n\n######To use the model which was trained on the non-augmented original dataset (97.4% accuracy):  \nDownload the pretrained model weights file from here:  \nhttps://drive.google.com/open?id=0B-B1607WQeSSRmEtRC1xQW5ZdlU  \nand save it as \"model_weights.h5\" in some folder.\n\nDownload the model architecture file from here:  \nhttps://drive.google.com/open?id=0B-B1607WQeSSdWR4M3dXNzN5dGs  \nand save it as \"model_architecture.json\" in the same folder.\n\n\n######To use the model which was trained on the augmented dataset (98.5% accuracy):  \nDownload the pretrained model weights file from here:  \nhttps://drive.google.com/open?id=0B-B1607WQeSSaXdJUzlFRy01TkU  \nand rename and save it as \"model_weights.h5\" in some folder.\n\nDownload the model architecture file from here:  \nhttps://drive.google.com/open?id=0B-B1607WQeSSUUVKVkdacmFiOTQ  \nand rename and save it as \"model_architecture.json\" in the same folder.\n\n\nPlace the file \"classify.py\" from this repository into the same folder as the above two files.  \n\nNow you can run the pretrained model on your own images as follows:  \n - python classify.py path_to_image1.png path_to_image2.png ...  \n\nYou can use absolute or relative paths.\n\nThe output will be as folows:  \n\npath_to_image1.png kanji_label_1  \npath_to_image2.png kanji_label_2  \n...\n\n\n#####If you want to train the model: \n\nAt first, run  \n - python create_dataset.py path_to_folder  \n\nHere path_to_folder is the folder which contains the folders with images.\nThis will produce a file named \"characters_dataset\" which will contain the train/validation/test datasets and labels in numpy arrays.\n\n######For the case of the model on the non-augmented original dataset:\n\nPlace the \"model.py\" file in the folder where you have the newly created dataset, and run:  \n - python model.py \n\nThis will produce two files: \"model_architecture.json\" and \"model_weights.h5\" which contain the model architecture and weights. \nThen, you can use these files with \"classify.py\" to make predictions.\n\n######For the case of the model on the augmented dataset:\n\nPlace the file \"create_augmented_dataset.py\" in the same folder as the newly created dataset and run the following command:  \n - python create_augmented_dataset.py\n\nNow place the \"model_for_augmented_dataset.py\" file in the folder where you have the newly created augmented dataset, and run: \n - python model_for_augmented_dataset.py \n\nThis will produce two files: \"augmented_model_architecture.json\" and \"augmented_model_weights.h5\" which contain the model architecture and weights.  \n\nThen, you can use these files with \"classify.py\" to make predictions, but keep in mind that \"classify.py\" expects the model weights to be in the file \"model_weights.h5\" and model architecture to be in the file \"model_architecture.json\", so you need to rename the files to suit it.\n\n----\n\nThe folder \"logs\" contains the training logs of the \"model.py\", \"model30x30.py\" and \"model_for_augmented_dataset.py\" models. \n\nThe file named \"create_augmented_dataset.py\" operates on the file \"characters_dataset\" (which must be created first using the \"create_dataset.py\" script) and creates an augmented dataset, called \"characters_dataset_elastic\". It uses elastic distortions (See http://arxiv.org/pdf/1003.0358.pdf for description of the method) to transform the training data and generate very natural looking characters. The newly generated augmented dataset contains ten times as many examples as the original one. Using this dataset with the \"model_for_augmented_dataset.py\" model, I was able to achieve 98.5% accuracy on the validation set (see also http://arxiv.org/pdf/1003.0358.pdf).  \n\nI had to write the elastic distortion function from scratch, as I was unable to find efficient implementation of elastic transformations in any python library. You can see some of the transformed character images in the folder \"Dataset-Augmentation\". \n", 
  "id": 56790069
}