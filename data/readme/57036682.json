{
  "read_at": 1462547846, 
  "description": "", 
  "README.md": "# convnets-keras\n\nThis repo is regrouping some of of the most used CNN, pre-trained on the ImageNet Dataset, all of them implemented in Keras framework : \n- AlexNet : https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n- VGG16 and VGG19 : http://arxiv.org/pdf/1409.1556.pdf\n\n\nWe also propose a heatmap option, which allow to detect the location of an object from a given synset.\n\n<img src=https://raw.githubusercontent.com/heuritech/convnets-keras/master/examples/cars.jpg width=\"400px\">\n\nHere, we detect all the objects linked to the synsets cars, and we produce a heatmap : \n\n<img src=https://raw.githubusercontent.com/heuritech/convnets-keras/master/examples/heatmap.png width=\"400px\">\n\n## Install\nThe only dependencies are h5py, Theano and Keras. Run the following commands\n```\npip install --user cython h5py\npip install --user git+https://github.com/Theano/Theano.git\npip install --user git+https://github.com/fchollet/keras.git\n```\n## Get the weights of the pre-trained networks\nThe weights can be found here : \n* <a href=\"http://files.heuritech.com/weights/alexnet_weights.h5\">AlexNet weights</a>\n* <a href=\"http://files.heuritech.com/weights/vgg16_weights.h5\">VGG16 weights</a>\n* <a href=\"http://files.heuritech.com/weights/vgg19_weights.h5\">VGG19 weights</a>\n\n\n\n## How to use the convnets\n**BEWARE** !! : Since the networks have been trained in different settings, the preprocessing is different for the differents networks : \n* For the AlexNet, the images (for the mode without the heatmap) have to be of shape (227,227). It is recommended to resize the images with a size of (256,256), and then do a crop of size (227,227). The colors are in RGB order.\n```python\nim = preprocess_image_batch(['examples/dog.jpg'],img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel = convnet('alexnet',weights_path=\"weights/alexnet_weights.h5\", heatmap=False)\nmodel.compile(optimizer=sgd, loss='mse')\n\nout = model.predict(im)\n```\n\n* For the VGG, the images (for the mode without the heatmap) have to be of shape (224,224). It is recommended to resize the images with a size of (256,256), and then do a crop of size (224,224). The colors are in BGR order.\n```python\nim = preprocess_image_batch(['examples/dog.jpg'],img_size=(256,256), crop_size=(224,224), color_mode=\"bgr\")\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n## For the VGG16, use this command\nmodel = convnet('vgg_16',weights_path=\"weights/vgg16_weights.h5\", heatmap=False)\n## For the VGG19, use this one instead\n# model = convnet('vgg_19',weights_path=\"weights/vgg19_weights.h5\", heatmap=False)\nmodel.compile(optimizer=sgd, loss='mse')\n\nout = model.predict(im)\n\n```\n\n\n## Performances on ImageNet\nThe errors are tested on ImageNet validation set.\nThe prediction time is computed on a GeForce GTX TITAN X, with a Theano backend, and a batch size of 64.\n\nAlexNet has lower results than the two VGGs, but it is much more lighter and faster, so it can easily be run on a small GPU (like on AWS), or even on a CPU.\n```\nNetworks                            | AlexNet     |     VGG16   |     VGG19   |\n-------------------------------------------------------------------------------\nTop 1 Error                         |   42,94%    |   32,93%    |   32,77%    |\nTop 5 error                         |   20,09%    |   12,39%    |   12,17%    |\nTop 10 error                        |   13,84%    |    7,77%    |    7,80%    |\nNumber of params                    |     61M     |     138M    |     144M    |\nPrediction time, batch of 64 (GPU)  |   0.4101s   |   0.9645s   |   1.0370s   |\nPrediction time, single image (CPU) |   0.6773s   |   1.3353s   |   1.5722s   |\n```\n\n## How to use the heatmap\nThe heatmap are produced by converting the model into a fully convolutionize model. The fully connected layers are transformed into convolution layers (by using the same weights), so we are able to compute the output of the network on each sub-frame of size (227,227) (or (224,224)) of a bigger picture. This produces a heatmap for each label of the classifier.\n\nUsing the heatmap is almost the same thing than directly classify. We suppose that we want the heatmap of the all the synsets linked with dogs, which are all the children in Wordnet of the synset \"n02084071\" (see next section to know how to find how we can get all the labels linked with a given synset) : \n```python\nim = preprocess_image_batch(['examples/dog.jpg'], color_mode=\"bgr\")\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel = convnet('alexnet',weights_path=\"weights/alexnet_weights.h5\", heatmap=True)\nmodel.compile(optimizer=sgd, loss='mse')\n\nout = model.predict(im)\n\ns = \"n02084071\"\nids = synset_to_dfs_ids(s)\nheatmap = out[0,ids].sum(axis=0)\n\n# Then, we can get the image\nimport matplotlib.pyplot as plt\nplt.imsave(\"heatmap_dog.png\",heatmap)\n```\n<img src=https://raw.githubusercontent.com/heuritech/convnets-keras/master/examples/dog.jpg width=\"400px\">\n\n<img src=https://raw.githubusercontent.com/heuritech/convnets-keras/master/examples/heatmap_dog.png width=\"400px\">\n\n## Useful functions for ImageNet\nWe propose a few utils function to link the index returned by the networks, and the synsets of ImageNet.\n\n#### Converting synsets to ids\nIt can be usefull to use the ids of ImageNet (which can be found on <a href =\"http://image-net.org/explore\"> this page </a>, if you want to know the meaning of the classification.\nWe have two functions : `id_to_synset` and `synset_to_id`\n* `id_to_synset` is taking an id of the output of the networks, and returning the WordNet synset\n```python\n>>> id_to_synset(243)\n'n03793489'\n```\n* `synset_to_id is doing the inverse operation\n\n#### Getting all the children of a synset \nIf you want to detect all cars, you might need to have a classification of higher level than the one given by the wordnets of ImageNet. Indeed, a lot of different synsets are present for different kinds of cars.\nWe can then choose a synset in the tree, and select all the ids of its children : \n```python\n>>>synset_to_dfs_ids(\"n04576211\")\n[670, 870, 880, 444, 671, 565, 705, 428, 791, 561, 757, 829, 866, 847, 547, 820, 408, 573, 575, 803, 407, 436, 468, 511, 609, 627, 656, 661, 751, 817, 665, 555, 569, 717, 864, 867, 675, 734, 656, 586, 847, 802, 660, 603, 612, 690]\n```\n\n## Credits\n* For the AlexNet network, we have adapted the weights that can be found here : \nTaylor, Graham; Ding, Weiguang, 2015-03, <i>\"Theano-based large-scale visual recognition with multiple GPUs\"</i>, <a href=\"http://hdl.handle.net/10864/10911\">hdl:10864/10911</a> University of Guelph Research Data Repository \n\n* For the VGG networks, we have adapted the code released by baraldilorenzo here : https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\nWe changed it to have the \"heatmap\" option, and we modified the weights in the same way.\n", 
  "id": 57036682
}