{
  "read_at": 1462547391, 
  "description": "Protein secondary structure detection based on unsupervised word segmentation", 
  "readme.txt": "We use the unsupervised word segmentation method to analyze the protein sequence.\r\nWe find the segmented protein words sequence is similar to protein secondary structure.\r\n\r\nDirectory:\r\nori_data: contain the original data and preprocess code.\r\npaper_experiment: experiment for paper, it contains this sub directory:\r\n\tsoft_count: protein sequence soft-counting segment test\r\n\tevaluation: evaluate the protein sequences segment results\r\n\tdna_segment: dna sequence segment test\r\nsrc: some other unsupervised segment method codes, not mentioned in our paper (python)\r\nour paper: http://arxiv.org/abs/1404.6866\r\n\r\nProtein Structure Data source:\r\nFrom this page:\r\nhttp://www.rcsb.org/pdb/static.do?p=download/http/index.html\r\nWe download:\r\nhttp://www.rcsb.org/pdb/files/ss.txt.gz\r\nWe have pre downloaded this data in ori_data directory as   ss.zip  , so you need   unzip   this file first. Its the DSSP secondary sstructure.\r\n\r\nPreliminary software:\r\n1 cd-hits, we use this tools to delete the similar sequence. It could be found in https://github.com/weizhongli/cdhit, after installing it, please copy file   cd-hit   to   ori_data   of this project.(these has been a cd-hit in this directory, only test in centos 64 Linux systems)\r\n2 python 2.7. Our codes are mainly python codes.\r\n\r\n\r\n\r\nExperiment for paper (You could simply run ./run_experiment.sh to process all experiments, the detailed operation are shown as follows):\r\n\r\nWe mainly use the DSSP secondary structure data. To process other forms of structure assignment data, you could refer to this operation.\r\n\r\n1 preprocess, mainly filter the similar sequence (in ori_data directory)\r\n#get fasta format file\r\nunzip ss.zip\r\n./get_fasta_file.py ss.txt > ss.fasta\r\n\r\n#delete similar sequence\r\n./cd-hit -i ss.fasta -o  ss.fasta.uniq -c 0.6 -n 4 -M 20000\r\n#get pid\r\ngrep '>' ss.fasta.uniq > ss.fasta.uniq.pid\r\n\r\n#get final experimental data\r\n./get_experiment_data.py ss.fasta.uniq.pid ss.txt > ss_06.dat\r\n\r\n#get protein sequence\r\nawk 'NR%3==1 {print $0}' ss_06.dat> ss_06.dat.pr\r\n\r\n#Then copy the file   ss_06.dat   to directory  paper_experiment/evaluation\r\n#Copy the file ss_06.dat.pr to directory paper_experiment/hdp and paper_experiment/soft_count\r\n\r\nYou can run   ./pre_process.sh   to do all the things above.\r\n\r\n\r\n2 run segmentation experiment (in   \"paper_experiment   directory)\r\n\r\n2.1 run soft-counting segment (In directory paper_experiment/soft_counting:)\r\n\r\nRun ./run_soft_count_experiment.sh ss_06.dat.pr\r\nWe can get the segment result ss_06.dat.pr.soft_count_seg. Then copy this file to directory   paper_experiment/evaluation\r\n\r\n2.2 evaluation the segment result (In directory paper_experiment/evaluation:)\r\nFirst, we need use the secondary structure to build the gold-standard segmentation\r\n./build_standard_seg.sh ss_06.dat\r\nThen we get these files:\r\nss_06.dat.structure_seg  # structure segmentation\r\nss_06.dat.structure_length_limit_seg  # set the maximal word length limitation for secondary structure, another gold standard segmentation\r\nss_06.dat.structure_dict_length9 #structure word vocabulary with frequency\r\n\r\nThen we could compare these two standard segmentation with unsupervised word segmentation, run:\r\n./ evaluate_segment.py ss_06.dat.structure_length_limit_seg ss_06.dat.pr.soft_count_seg.words\r\n\r\nWe also need copy the vocabulary file ss_06.dat.structure_dict_length9 to  directory   paper_experiment/ dna_segment\r\n\r\nYou could also run \"description length\" test for segmented sequence, for example\r\n./get_description_length.py ss_06.dat.structure_seg\r\n\r\n\r\nyour could run ./run_protein_segment_experiment.sh   to do all the things above(2.1 and 2.2)\r\n\r\n\r\n3 segment dna sequence(in   \"paper_experiment/dna_segment\")\r\nYou need install Biopython first(latest Biopython (1.63 or latter). You can download from http://biopython.org/wiki/Main_Page.)\r\nThen You should copy the file Translate.py in this directory to the directory where Biopython install. Normally, its /usr/local/lib/python2.7/site-packages/Bio. It contain the back translate function, but this function is deleted in new version.\r\nRun:\r\n./run_dna_segment_experiment.sh\r\n\r\n\r\n******************************************other notes************************************************\r\nWe also prepare English corpus in ori_data/english/english.txt and ori_data/english/english.txt.nospace, you can also run test above for English text. english.txt is standard segmentation and then run soft unsupervised segmentation method for english.txt.nospace\r\n\r\n\r\nOur test shows using large data sets get the similar unsupervised segmentation results.\r\nBut if you need more protein sequence, you can download the data from swiss:\r\n\r\nhttp://www.uniprot.org/downloads\r\n\r\nUniProtKB/Swiss-Prot\r\nftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\r\n\r\nUniProtKB/TrEMBL\r\nftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_trembl.fasta.gz\r\n\r\nTo process these protein data, you may need a 16G memory machine , or run test in Hadoop. Most of our codes could run in Hadoop.\r\n\r\n\r\n\r\nSome other unsupervised segmentation methods.\r\nVoting-expert: https://code.google.com/p/voting-experts/\r\n\r\nRegularized compression method to unsupervised word segmentation:\r\nhttps://github.com/rueycheng/kinkaseki\r\n\r\n\r\nHDP, an unsupervised segment methods, it  s normally regarded as the best unsupervised segment method.\r\nIt could be found in http://homepages.inf.ed.ac.uk/sgwater/resources.html\r\n\r\nIn our directory paper_experiment/hdp:\r\nRun ./segment ss_06.dat.pr -w0 -o ss_06.dat.pr.hdp_seg\r\nIt may take several hours to get the results. We can get the segment result ss_06.dat.pr.hdp_seg.words.\r\nThen copy this file to directory   paper_experiment/evaluation to evaluate its results.\r\n\r\n\r\n\r\n", 
  "id": 20592513
}